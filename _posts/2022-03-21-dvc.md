---
permalink: /dvc/ 
title: "Github para Data Science Pt. 2"
subheadline: "Combinando Git con DVC"
teaser: "Automatizando un Pipeline de Machine Learning"
# layout: page-fullwidth
usemathjax: true
category: ml
header: no
image:
    thumb: dvc/dvc.png
tags:
- python
- tutorial
- ML
published: true
---

![picture of me]({{ site.urlimg }}dvc/dvc.png){: .left .show-for-large-up .hide-for-print width="250"}
![picture of me]({{ site.urlimg }}dvc/dvc.png){: .center .hide-for-large-up width="500"}

Al parecer muchos encontraron que es una excelente idea aprender GIT para llevar un proceso ordenado de desarrollo en Ciencia de Datos. Pero tambi√©n es cierto, que cuando se ide√≥ GIT, la Ciencia de Datos como disciplina no estaba en el radar, y menos el proceso de entrenamiento de un Modelo. Hoy en d√≠a el `MLOps` est√° m√°s de moda que nunca<!--more--> y todav√≠a no es claro un framework √∫nico en el cu√°l se pueda llevar un verdadero control del proceso de modelamiento.

Para solucionar el problema de c√≥mo logramos el control de un desarrollo de Machine Learning se cre√≥ DVC. DVC significa "Data Version Control" y no puede ser un peor nombre, porque si bien se dise√±√≥ como una alternativa para poder llevar control de versiones de la data en realidad es una aplicaci√≥n que es mucho m√°s que s√≥lo eso.

## DVC

DVC nace de la necesidad de solucionar uno de los grandes problemas de GIT/Github que es el almacenamiento de grandes archivos (que son pan de cada d√≠a en Ciencia de Datos). La idea es que DVC permita reproducir archivos generados sin la necesidad de tener que re-ejecutar un c√≥digo (esto porque esto podr√≠a tomar mucho tiempo).
Pero luego DVC comienza a evolucionar y creo que la gran ventaja que tiene es que permite generar Pipelines Reproducibles (de ML o cualquier otro proceso complejo de datos) y evitar ejecutar etapas cuando no es necesario.

Mientras realiza eso, DVC permite generar `light-commits` para experimentos, trackear par√°metros, guardar m√©tricas, incluso generar plots para poder monitorear el proceso de ML primeramente, pero es extendible para cualquier proceso de Datos.

<q>DVC es un software agn√≥stico de Clouds, OS, ML frameworks, etc. Adem√°s es open source por lo que realmente vale la pena incorporarlo en los procesos de desarrollo de Ciencia de Datos porque casi no tiene boilerplate ni overhead asociado.</q>

Adem√°s [iterative.ai](https://iterative.ai/) ha seguido desarrollando herramientas para Ciencia de Datos, entre ellas procesos de CI/CD (el cual ya estoy aprendiendo para traer en otro tutorial) de modo de permitir un desarrollo √°gil (me refiero en el sentido de r√°pido, no haciendo tonteras como Scrum) y en el que pueda incluso estar involucrada gente no t√©cnica.

## Modelo de ML con Data de la NBA

La NBA est√° muy buena estos d√≠as, y encontr√© un dataset del a√±o pasado con todas las estad√≠sticas de los jugadores. Propongo utilizar este dataset para utilizar las estad√≠sticas para predecir la posici√≥n en la que juega un jugador. Este es un modelo muy sencillo multiclase, y m√°s que el desarrollo del modelo lo que nos importa ac√° es como poder operacionalizar un proceso de desarrollo del modelo. 

A√∫n as√≠, la data se ve como esto:

![picture of me]({{ site.urlimg }}dvc/data.png){: .center}


El Pipeline de Modelamiento lo vamos a descomponer en 4 partes: Creaci√≥n del Dataset, Creaci√≥n/Eliminaci√≥n de Features, Entrenamiento y Evaluaci√≥n.

El c√≥digo va as√≠:

```python
from pathlib import Path

class Config:
    RANDOM_SEED = 123
    ASSETS_PATH = Path('./assets')
    FILE_PATH = ASSETS_PATH / 'original_data' / 'nba_stats.csv'
    DATASET_PATH = ASSETS_PATH / 'data' 
    FEATURES_PATH = ASSETS_PATH / 'features'
    MODELS_PATH = ASSETS_PATH / 'models'
    METRICS_PATH = ASSETS_PATH / 'metrics.json'
```
{: title="Clase de Configuraci√≥n para definir Constantes."}

Vamos b√°sicamente a definir una semilla aleatoria para garantizar reproducibilidad y definir distintas carpetas para guardar los archivos crudos, el dataset spliteado, features, modelos y m√©tricas.

Luego, voy a descargar el dataset desde Google Drive. Para ello uso la librer√≠a `gdown`. La descarga se va a realizar luego de crear las carpetas assets y data.


```python
import gdown
import pandas as pd
from sklearn.model_selection import train_test_split

Config.FILE_PATH.parent.mkdir(parents=True, exist_ok=True)
Config.DATASET_PATH.mkdir(parents=True, exist_ok=True)

gdown.download(
    'https://drive.google.com/uc?id=1rwnNapcxlPM_DrYwBPSEC9uWVyEy70D1',
    str(Config.FILE_PATH)
)

nba_df = pd.read_csv(Config.FILE_PATH, encoding='latin-1', sep = ';')
train_df, test_df = train_test_split(nba_df, test_size=0.25, random_state=Config.RANDOM_SEED)

train_df.to_csv(Config.DATASET_PATH / 'train.csv', index = None)
test_df.to_csv(Config.DATASET_PATH / 'test.csv', index = None)
```
{: title="Creaci√≥n y Split del Dataset."}

{% include alert info='Como se puede ver voy a ir almacenando todos los resultados de cada etapa. Pensando en que normalmente los procesos de ML incluyen data grande y pesada la idea es poder liberar memoria cuando se pueda, adem√°s de utilizarlos como checkpoints en caso de que algun proceso posterior falle.'%}

```python
Config.FEATURES_PATH.mkdir(parents=True, exist_ok=True)
train_df = pd.read_csv(Config.DATASET_PATH / 'train.csv')
test_df = pd.read_csv(Config.DATASET_PATH / 'test.csv')

def featurize(df):
    df.query('Tm != "TOT"', inplace = True)
    X = df.drop(columns = ['Rk','Player', 'Tm', 'Pos'])
    y = df.Pos
    return X,y 

X_train, y_train = featurize(train_df)
X_test, y_test = featurize(test_df)

X_train.to_csv(Config.FEATURES_PATH / 'train_features.csv', index = None)
X_test.to_csv(Config.FEATURES_PATH / 'test_features.csv', index = None)
y_train.to_csv(Config.FEATURES_PATH / 'train_labels.csv', index = None)
y_test.to_csv(Config.FEATURES_PATH / 'test_labels.csv', index = None)
```
{: title="Transformaci√≥n del Dataset en Features y Labels"}

Al chequear el Dataset not√© de que hab√≠an jugadores con un equipo llamado TOT. Esto significa que estuvieron en m√°s de un equipo, lo cual implica que algunos jugadores tengan asignada m√°s de una posici√≥n. Por lo tanto, este proceso se encargar√° de eliminar esos registros por simplicidad adem√°s de eliminar un ranking, el nombre del jugador, el equipo y la posici√≥n. Esto porque s√≥lo nos interesa utilizar estad√≠sticas para predecir la posicion de un jugador.

```python
from sklearn.linear_model import LogisticRegression
import joblib

Config.MODELS_PATH.mkdir(parents=True, exist_ok=True)

X_train = pd.read_csv(Config.FEATURES_PATH / 'train_features.csv')
y_train = pd.read_csv(Config.FEATURES_PATH / 'train_labels.csv')

model = LogisticRegression(max_iter=10000, random_state=Config.RANDOM_SEED)
model.fit(X_train, y_train.to_numpy().ravel())

joblib.dump(model, Config.MODELS_PATH / 'model.joblib')
```
{: title="Entrenamiento de una Regresi√≥n Lineal."}

El entrenamiento es muy sencillo, s√≥lo entrenaremos una regresi√≥n log√≠stica, ya que formularemos el problema como un problema de clasificaci√≥n multiclase. El modelo va a ser serializado en formato `joblib` (si les interesa saber por qu√© no pickle puedan mirar [ac√°](https://scikit-learn.org/stable/modules/model_persistence.html)).

```python
import json
from sklearn.metrics import accuracy_score, recall_score

model = joblib.load(Config.MODELS_PATH / 'model.joblib')

X_test = pd.read_csv(Config.FEATURES_PATH / 'test_features.csv')
y_test = pd.read_csv(Config.FEATURES_PATH / 'test_labels.csv')

y_pred = model.predict(X_test)

output = dict( test_accuracy = accuracy_score(y_test, y_pred),
    test_recall = recall_score(y_test, y_pred, average='macro'))

with open(Config.METRICS_PATH, 'w') as outfile:
    json.dump(output, outfile)
```
{: title="Evaluaci√≥n en Datos no vistos."}

Finalmente me interesa poder evaluar el comportamiento del modelo para poder determinar c√≥mo le va. Esto lo hacemos con el modelo ya entrenado, pero evaluando sus predicciones en data no vista del test set.

{% include alert success='Hasta ac√° es el proceso normal que se utiliza para entrenar un modelo. Obviamente, est√° un poco simplificado, ya que no estamos considerando estrategias de validaci√≥n m√°s avanzadas o tuning de hiperpar√°metros, pero creo que se entiende la idea.'%}

Normalmente todo este proceso lo colocamos dentro de un Jupyter Notebook que suele ser la fuente de varias malas pr√°cticas para experimentar. Si te sientes identificado con alguna es normal, todos lo hemos hecho alguna vez:

* Copiar y pegar el c√≥digo abajo y modificar la Regresi√≥n Log√≠stica con otro modelo.
* Tener varios modelos comentados e ir descomentando dependiendo del que nos vaya dejando mejores resultados.
* Borrar de frent√≥n un pedazo de c√≥digo que no result√≥ y reemplazarlo por el que ahora nos parece funcionar√° mejor.

### ¬øC√≥mo lo solucionamos?

Una opci√≥n es usar [hydra]({{ site.baseurl }}/hydra/). Tengo varios tutoriales que de hecho pueden revisar. Si bien Hydra es una muy buena herramienta, siento que tiene varios inconvenientes:

* Si bien lleva registros de los runs, s√≥lo los puedes guardar de manera local. Es posible utilizar callbacks para almacenar en plataformas como S3, pero todo ese trabajo debes implementarlo por tu cuenta.
* Almacena los runs exitosos y los fallidos, por lo que cuando est√°s reci√©n testeando puede guardar muchos logs de errores que no aportan mucho.
* Hydra es una librer√≠a de bajo nivel, por lo que cualquier idea que tengas hay que implementarla por cuenta propia.
* Tiene poco boilerplate, pero tiene. Eso quiere decir que el proceso de experimentaci√≥n est√° dentro del c√≥digo, lo cual enreda un poco el debugging cuando nos interesa el proceso del c√≥digo y no el esqueleto de experimentaci√≥n.

{% include alert warning='Con esto no quiero bajo ning√∫n motivo decir que Hydra no es una buena herramienta. De hecho tengo varios proyectos en producci√≥n hechos en Hydra y voy a seguir recomend√°ndola.'%}

DVC abstrae todo eso. No hay que intervenir nuestro c√≥digo con ning√∫n c√≥digo boilerplate para llevar registro. Y eso es maravilloso. Adem√°s permite separar el proceso en distintas etapas conectadas en forma de DAG (como Airflow, Metaflow, etc.) pero sin agregar c√≥digo extra, sino que generando un archivo de configuraci√≥n. Finalmente permite parametrizar el proceso desde un archivo YAML tal y como Hydra pero sin utilizar `Omeconf` ni decoradores extras. 

Por fa, d√≠ganme que no suena prometedor.

## Transformando nuestro proyecto en DVC.

Si bien tenemos que aplicar cambios, la verdad es que no son tantos. Como DVC est√° pensando en utilizar buenas pr√°cticas de dise√±o de software lo primero ser√° transformar nuestro Jupyter Notebook en un grupo de Scripts modularizados:

![picture of me]({{ site.urlimg }}dvc/tree.png){: .center}

Cada uno de los archivos contendr√° cada una de las etapas descritas anteriormente. Adem√°s el archivo `config.py` contendr√° la clase de Configuraci√≥n que definimos inicialmente.

Adem√°s definiremos un archivo llamado params.yaml, el cual se ve como sigue:

```yaml
base:
  random_seed: 123

data:
  file_name: nba_stats.csv

features:
  remove: [Rk, Player, Tm, Pos]

train:
  C: 1
  max_iter: 10000
  model_name: model.joblib
```
{: title="params.yaml"}

Este archivo contiene par√°metros para distintas etapas del proceso:

* **base**: Contiene la semilla aleatoria.
* **data**: El nombre del archivo original. A veces esto podr√≠a variar porque hay distintas versiones que incluyen informaci√≥n actualizada a un cierto periodo, etc.
* **features**: En este caso particular contiene una lista de features a eliminar.
* **train**: Contiene hiperpar√°metros espec√≠ficos de la Regresi√≥n Log√≠stica y el nombre del modelo a serializar.

Luego nuestros scripts quedar√°n de la siguiente manera:

```python
from pathlib import Path
import yaml

# importaci√≥n de los par√°metros desde el archivo params.yaml
with open('params.yaml') as file:
    params = yaml.safe_load(file)

class Config:
    RANDOM_SEED = params['base']['random_seed']
    ASSETS_PATH = Path('./assets')
    FILE_PATH = ASSETS_PATH / 'original_data' / params['data']['file_name']
    DATASET_PATH = ASSETS_PATH / 'data' 
    FEATURES_PATH = ASSETS_PATH / 'features'
    MODELS_PATH = ASSETS_PATH / 'models'
    METRICS_PATH = ASSETS_PATH / 'metrics.json'
```
{: title="config.py"}

Ac√° llamamos desde `params.yaml` el random seed y el nombre del archivo a importar.

```python
import gdown
import pandas as pd
from sklearn.model_selection import train_test_split
from config import Config

Config.FILE_PATH.parent.mkdir(parents=True, exist_ok=True)
Config.DATASET_PATH.mkdir(parents=True, exist_ok=True)

gdown.download(
    'https://drive.google.com/uc?id=1rwnNapcxlPM_DrYwBPSEC9uWVyEy70D1',
    str(Config.FILE_PATH)
)

nba_df = pd.read_csv(Config.FILE_PATH, encoding='latin-1', sep = ';')

train_df, test_df = train_test_split(nba_df, test_size=0.25, random_state=Config.RANDOM_SEED)

train_df.to_csv(Config.DATASET_PATH / 'train.csv', index = None)
test_df.to_csv(Config.DATASET_PATH / 'test.csv', index = None)
```
{: title="01-get_data.py"}

En este archivo llamamos los nombres de features a eliminar.

```python
import pandas as pd
from config import Config
import yaml

#importamos s√≥lo los par√°metros relevantes para features
with open('params.yaml') as file:
    params = yaml.safe_load(file)['features']

Config.FEATURES_PATH.mkdir(parents=True, exist_ok=True)

train_df = pd.read_csv(Config.DATASET_PATH / 'train.csv')
test_df = pd.read_csv(Config.DATASET_PATH / 'test.csv')

def featurize(df):
    df.query('Tm != "TOT"', inplace = True)
    X = df.drop(columns = params['remove'])
    y = df.Pos
    
    return X,y 

X_train, y_train = featurize(train_df)
X_test, y_test = featurize(test_df)

X_train.to_csv(Config.FEATURES_PATH / 'train_features.csv', index = None)
X_test.to_csv(Config.FEATURES_PATH / 'test_features.csv', indeexp_show= None)
y_train.to_csv(Config.FEATURES_PATH / 'train_labels.csv', index = None)
y_test.to_csv(Config.FEATURES_PATH / 'test_labels.csv', index = None)
```
{: title="02-create_features.py"}

Entrenamos el Modelo.
```python
import joblib
import pandas as pd
from sklearn.linear_model import LogisticRegression
from config import Config
import yaml

with open('params.yaml') as file:
    params = yaml.safe_load(file)['train']

Config.MODELS_PATH.mkdir(parents=True, exist_ok=True)
X_train = pd.read_csv(Config.FEATURES_PATH / 'train_features.csv')
y_train = pd.read_csv(Config.FEATURES_PATH / 'train_labels.csv')

model = LogisticRegression(C = params['C'], max_iter=params['max_iter'], random_state=Config.RANDOM_SEED)
model.fit(X_train, y_train.to_numpy().ravel())
joblib.dump(model, Config.MODELS_PATH / params['model_name'])
```
{: title="03-train_model.py"}

Finalmente evaluamos la performance del modelo.
```python
import json
import joblib
import pandas as pd
from sklearn.metrics import accuracy_score, recall_score
from config import Config

X_test = pd.read_csv(Config.FEATURES_PATH / 'test_features.csv')
y_test = pd.read_csv(Config.FEATURES_PATH / 'test_labels.csv')

model = joblib.load(Config.MODELS_PATH / 'model.joblib')
y_pred = model.predict(X_test)

output = dict( test_accuracy = accuracy_score(y_test, y_pred),
    test_recall = recall_score(y_test, y_pred, average='macro'))

with open(Config.METRICS_PATH, 'w') as outfile:
    json.dump(output, outfile)
```
{: title="04-evaluate_model.py"}

{% include alert success='Como se puede ver los cambios hechos al c√≥digo son m√≠nimos, y s√≥lo se ingresaron los par√°metros. De hecho, partes como evaluate_model.py casi no tienen c√≥digo adicional. En estricto rigor, no agregamos nada que tenga que ver con el trackeo del proceso de experimentaci√≥n.'%}

## DVC entra en juego!!

Entonces, ya que tenemos un primer bosquejo de nuestro c√≥digo crearemos un repo de git e inicializaremos DVC (esto se puede hacer en cualquier momento, lo hago ac√° s√≥lo por seguir el flujo del tutorial):

```shell
$ git init
$ dvc init
```
    Initialized empty Git repository in /home/alfonso/Documents/dvc_tutorial/src/.git/
    Initialized DVC repository.

    You can now commit the changes to git.

{% include alert alert='Aseg√∫rate de trabajar en Repos. `dvc init` s√≥lo funciona en una carpeta que ya es un repo de GIT o lanzar√° un error.'%}


Luego DVC permite la posibilidad de respaldar y llevar registro de la data tanto en local como en storage remotos. Lo m√°s com√∫n, especialmente para poder compartir la data es utilizar storage remotos. A modo de explicar esto, utilizaremos Google Drive, pero DVC puede usarse en S3, Azure Blob, entre otros.

```shell
$ dvc remote add -d storage gdrive://1uvjM-tDGP577uB_DVxO8uoyHxeyZA3zO
```
    Setting 'storage' as a default remote.

donde `1uvjM-tDGP577uB_DVxO8uoyHxeyZA3zO` corresponde al id de una de sus carpetas de Google Drive, en este caso mi carpeta se llama remote y es donde almacen√© el archivo original que estamos usando. Como pueden ver el id se encuentra al final del link en la parte superior.

![picture of me]({{ site.urlimg }}dvc/remote.png){: .center}

{% include alert tip='Cuando sincronizan Google Drive con su computador por primera vez les aparecer√° un mensaje con instrucciones para garantizar que son ustedes. S√≠ganlas al pie de la letra y no tendran problemas. Adicionalmente, no intenten usar este id si es que intentan reproducir el tutorial, ya que no tienen acceso a mis credenciales de Google, usen su propia cuenta üòá.'%}

Como dijimos en el tutorial pasado Github no fue dise√±ado para llevar registro de archivos de gran tama√±o por lo que si DVC se va a encargar de eso m√°s vale asegurarse que GIT ignore estos archivos mediante nuestro `.gitignore`:

```shell
.vscode
__pycache__
assets/data
assets/features
assets/models
assets/original_data
```
{: title=".gitignore"}


De esta manera ignoramos la basura que podamos tener en nuestro Repo como los archivos de configuraci√≥n de VSCode, cache, y las carpetas que almacenar√°n datos.


Luego entonces podemos armar el Pipeline. No es casualidad que los scripts tengan un orden asociado, y eso lo podemos replicar en DVC mediante el comando run.
El comando puede ser un poco complicado de escribir en la l√≠nea de comando, por lo que decid√≠ escribirlo en un archivo `sh`:

```bash
rm -f dvc.yaml 

dvc run --no-exec -n get_data \
-d src/01-get_data.py \
-p base,data \
-o assets/data \
python src/01-get_data.py

dvc run --no-exec -n featurize \
-d src/02-create_features.py \
-d assets/data \
-p features \
-o assets/features \
python src/02-create_features.py

dvc run --no-exec -n train \
-d assets/features \
-d src/03-train_model.py \
-p base,train \
-o assets/models \
python src/03-train_model.py

dvc run --no-exec -n evaluate \
-d assets/features \
-d assets/models \
-d src/04-evaluate_model.py \
-M assets/metrics.json \
python src/04-evaluate_model.py
```
{: title="config_dvc.sh"}

`dvc run` es el comando que permite crear una dependencia y a la vez ejecutar el Pipeline. Normalmente prefiero acompa√±arlo del flag `--no-exec` para realizar la ejecuci√≥n despu√©s. El Script hace lo siguiente:

* La primera l√≠nea elimina el archivo `dvc.yaml` en caso de existir. Este archivo es donde se generar√° esta configuraci√≥n.
* `-n` es el nombre de las etapas: *get_data*, *featurize*, *train* y *evaluate*.
* `-d` son las dependencias. Esto me cost√≥ entenderlo, pero b√°sicamente dice si es que DVC identifica que alguna de las dependencias cambi√≥ volver√° a ejecutar esta etapa (esto quedar√° m√°s claro con el ejemplo).
* `-o` corresponde a los outputs. Todos los outputs ser√°n trackeados por DVC y tendr√°n un respaldo en el storage definido.
* `-p` son los par√°metros, en caso de que cambien DVC volver√° a ejecutar el Pipeline, igual que con las dependencias.
* `-M` corresponde a m√©tricas que se alamacenan en json y se usar√°n para comparar experimentos.
* Finalmente, se coloca el comando que ejecutar√° dicha etapa.

Por ejemplo, tomemos una etapa cualquiera, la tercera:

* Su nombre es `train`.
* Si es que algo en la carpeta `assets/features` o si el script `src/03-train_model.py` cambia esta etapa se volver√° a ejecutar.
* Si es que alguno de los par√°metros `base` o `train` var√≠a tambi√©n se volver√° a ejecutar.
* Los outputs del modelo se almacenar√°n en la carpeta `assets/models`.
* Esta etapa se lanza pidi√©ndole a DVC que ejecute el comando `python src/03-train_model.py`.

Entonces para definir el Pipeline basta con ejecutar el archivo:

```bash
$ bash config_dvc.sh
```
Under the hood, esta configuraci√≥n no hace m√°s que organizar el archivo `dvc.yaml`, el cual tiene toda la informaci√≥n descrita pero en formato legible:

```yaml
stages:
  get_data:
    cmd: python src/01-get_data.py
    deps:
    - src/01-get_data.py
    params:
    - base
    - data
    outs:
    - assets/data
  featurize:
    cmd: python src/02-create_features.py
    deps:
    - assets/data
    - src/02-create_features.py
    params:
    - features
    outs:
    - assets/features
  train:
    cmd: python src/03-train_model.py
    deps:
    - assets/features
    - src/03-train_model.py
    params:
    - base
    - train
    outs:
    - assets/models
  evaluate:
    cmd: python src/04-evaluate_model.py
    deps:
    - assets/features
    - assets/models
    - src/04-evaluate_model.py
    metrics:
    - assets/metrics.json:
        cache: false
```
{: title="dvc.yaml"}

{% include alert tip='Si por alguna raz√≥n no se sienten c√≥modos utilizando archivos sh o la consola, primero que todo hay que empezar a acostumbrarse. Pero si de todas maneras prefieren crear de manera directa el `dvc.yaml` pueden hacerlo agregando o quitando partes que les interesen.'%}

Al hacer esto entonces DVC ha sido configurado y en este punto ser√≠a una buena pr√°ctica hacer un commit:

```shell
$ git add .
$ git commit -m 'Configurando DVC'
```
DVC incluso permite ver el Pipeline como un DAG, el cual podemos visualizar haciendo lo siguiente:

```shell
$ dvc dag
```

            +----------+      
            | get_data |      
            +----------+      
                *           
                *           
                *           
            +-----------+     
            | featurize |     
            +-----------+     
            **        **     
        **            *    
        *               **  
    +-------+               * 
    | train |             **  
    +-------+            *    
            **        **     
            **    **       
                *  *         
            +----------+      
            | evaluate |      
            +----------+ 


DVC reconoce las distintas etapas y sus dependencias y lo muestra de manera gr√°fica. Entendiendo que el DAG est√° correctamente construido podemos ejecutar el proceso:

```shell
$ dvc repro
```
`dvc repro` implica reproducir el proceso. Recordemos que el objetivo principal de DVC es la reproducibilidad.

    Running stage 'get_data':                                             
    > python src/01-get_data.py
    Downloading...
    From: https://drive.google.com/uc?id=1rwnNapcxlPM_DrYwBPSEC9uWVyEy70D1
    To: /home/alfonso/Documents/dvc_tutorial/assets/original_data/nba_stats.csv
    100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99.2k/99.2k [00:00<00:00, 6.02MB/s]
    Generating lock file 'dvc.lock'                                                                                                                                                             
    Updating lock file 'dvc.lock'                                                                                                                                                               
                                                                                                                                                                                                
    Running stage 'featurize':
    > python src/02-create_features.py
    Updating lock file 'dvc.lock'                                                                                                                                                               
                                                                                                                                                                                                
    Running stage 'train':
    > python src/03-train_model.py
    Updating lock file 'dvc.lock'                                                                                                                                                               
                                                                                                                                                                                                
    Running stage 'evaluate':
    > python src/04-evaluate_model.py
    Updating lock file 'dvc.lock'                                                                                                                                                               

    To track the changes with git, run:

        git add dvc.lock

    To enable auto staging, run:

            dvc config core.autostage true
    Use `dvc push` to send your updates to remote storage.

Cada una de las etapas se ejecut√≥ como corresponde, y DVC recomienda varias cosas para guardar cambios, las cuales las iremos revisando una a una. Algunos aspectos importantes de DVC:

Primero, si quiero revisar c√≥mo le fue a mi ejecuci√≥n:

```shell
$ dvc metrics show
```
    Path                 test_accuracy    test_recall                     
    assets/metrics.json  0.43931          0.45895

Inmediatamente nos muestra las m√©tricas que nosotros determinamos como relevantes para el problema.

¬øQu√© pasa si no estoy seguro si ejecut√© todo o no? Ejecutemos el proceso de nuevo:

```shell
$ dvc repro
```

    Stage 'get_data' didn't change, skipping                              
    Stage 'featurize' didn't change, skipping
    Stage 'train' didn't change, skipping
    Stage 'evaluate' didn't change, skipping
    Data and pipelines are up to date.

DVC entiende que ninguna de las dependencias ha cambiado. Por lo tanto, no ejecuta el proceso de nuevo, entendiendo que obtendr√≠amos el mismo resultado. Esto es particularmente √∫til, ya que DVC nos permitir√° ejecutar la menor cantidad de procesos para llevar a cabo nuestro proceso evitando tiempo de esperas innecesarios o costos computacionales en la nube.

Guardemos nuestro progreso entonces haciendo un commit.

```shell
$ git add .
$ git commit -m 'LR Baseline'
```

¬øQu√© suceder√≠a si ahora quiero experimentar? Bueno para eso DVC posee comandos dedicados a dicha tarea. Probemos como le ir√≠a al modelo si es que C es 10 y 0.1

```shell
$ dvc exp run --set-param train.C=10
$ dvc exp run --set-param train.C=0.1
```
    Stage 'get_data' didn't change skipping
    Stage 'featurize' didn't change, skipping
    Running stage 'train':
    > python src/03-train_model.py
    Updating lock file 'dvc.lock'
                       
    Running stage 'evaluate':
    > python src/04-evaluate_model.py
    Updating lock file 'dvc.lock' 

DVC entiende que modificar ese par√°metro s√≥lo tiene impacto en las etapas `train` y `evaluate`, por lo tanto no vuelve a ejecutar las primeras etapas (esto lo deduce de las dependencias dadas, por lo que hay que poner mucho √©nfasis en configurar el Pipeline correctamente).

Luego podemos ver los resultados de la experimentaci√≥n:

```shell
$ dvc exp show
``` 
DVC mostrar√° una tabla bien bonita con todos los experimentos, par√°metros, hora de ejecuci√≥n y m√©tricas de resultado. `workspace` implica el √∫ltimo experimento ejecutado, en nuestro caso con C=0.1. `master` corresponde al √∫ltimo commit realizado que en este caso es nuestro Baseline.

![picture of me]({{ site.urlimg }}dvc/exp_show.png){: .center}

Ahora, supongamos que nos interesa optimizar nuestro modelo para tener mejor Accuraccy, entonces el `exp-f60e7` es el que nos interesa. Para poder promoverlo como el experimento que queremos dejar usamos:

```shell
$ dvc exp apply exp-f60e7
```                                                                                                                                                                      
    Changes for experiment 'exp-f60e7' have been applied to your current workspace.

De hecho podemos comparar nuestra mejora:

```shell
$ dvc metrics diff
```
    Path                 Metric         HEAD     workspace    Change      
    assets/metrics.json  test_accuracy  0.43931  0.44509      0.00578
    assets/metrics.json  test_recall    0.45895  0.46103      0.00208


Este comando nos indica que nuestro experimento actual (workspace) es mejor en 0.00578 en accuracy y 0.00208 en recall.

`dvc exp apply` se va a encargar de modificar nuestros archivos de tal modo que `dvc repro` nos entregue el mismo resultado obtenido en la experimentaci√≥n, es decir, DVC es capaz de modificar c√≥digo, par√°metros o data con tal de hacer el experimento reproducible.

Luego de esto podemos realizar el commit necesario para guardar los cambios:

```shell
$ git add .
$ git commit -m 'Mejorando la Regresion Logistica'
```

Finalmente podemos ver nuestras m√©tricas actuales:

```shell
$ dvc metrics show
```
    Path                 test_accuracy    test_recall                     
    assets/metrics.json  0.44509          0.46103

Un √∫ltimo aspecto importante es que todos los archivos en el output est√°n siendo trackeados por DVC, pero debe llevarse el respaldo en el storage remoto utilizando `dvc push`. `dvc push` se encargar√° de tener un registro de los archivos. Esto porque DVC supone que los procesos de ML trabajan con archivos muy grandes y procesos de entrenamiento largos. Por lo tanto, si alguien quisiera clonar mi repo y ver mis resultados y la data asociada podr√≠a utilizar `dvc pull` para obtener los archivos de salida sin la necesidad de ejecutar todo el Pipeline de nuevo, que como dijimos puede tomar mucho tiempo debido a la naturaleza de los problemas que se est√°n resolviendo.

![picture of me]({{ site.urlimg }}dvc/backup.png){: .center}

Si vamos a Google Drive podemos ver que todos los archivos tienen un respaldo con datos ininteligibles para nosotros, pero que DVC puede r√°pidamente interpretar para regenerar esos archivos. Es importante destacar que todos los archivos est√°n en alg√∫n formato binario, que al menos yo no entiendo como poder leer sin pasar por DVC. Imagino que la raz√≥n de esto es para evitar que personas no autorizadas puedan mirar la data.

Finalmente podemos dejar respaldo en nuestro Github generando un push.

Este fue el tutorial de DVC, espero lo consideren √∫til y que desde ya puedan comenzar a incorporarlo dentro de su estructura de trabajo. 
Si les interesa seguir este tutorial o reproducirlo pueden encontrar todo el c√≥digo en este [repo](https://github.com/datacubeR/dvc_tutorial).

Obviamente DVC no es el punto final. 
¬øNo ser√≠a espectacular poder tener feedback de los procesos de entrenamiento de manera inmediata y que pudieramos tener el proceso de experimentaci√≥n s√∫per automatizado usando CI/CD? 

Bueno, se viene en el tutorial que sigue...

Nos vemos a la otra,

[**Alfonso**]({{ site.baseurl }}/contact/)











*[boilerplate]: C√≥digo base repetitivo que tiene que agregarse para hacer funcionar un framework, por ejemplo @hydra.main en hydra.
*[overhead]: Procesamiento adicional que se da por una abstracci√≥n. Por ejemplo a pesar de que Numpy corre en C, no es tan r√°pido como C puro debido al overhead de la traducci√≥n a Python.
