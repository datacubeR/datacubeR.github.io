---
title: "Tutorial MlFlow"
subheadline: "¿Cómo utilizar MlFlow local para organizar tus experimentos?"
teaser: "Al menos yo soy un desastre con mi orden, por lo que necesito herramientas que me ayuden."
# layout: page-fullwidth
usemathjax: true
category: ml
header: no
image:
    thumb: mlflow/featured.png
tags:
- python
- sklearn
- ML
---

![picture of me]({{ site.urlimg }}mlflow/featured.png){: .left .show-for-large-up .hide-for-print width="500"}
![picture of me]({{ site.urlimg }}mlflow/featured.png){: .center .hide-for-large-up width="250"}
Me encanta modelar, pero al mismo tiempo demanda lo mejor de mí en términos del orden, yo no soy muy ordenado en la vida real, entonces pedirme que sea ordenado al momento de experimentar con mis modelos es demasiado, por eso MLflow es una super buena alternativa para lograr una estructura al momento de modelar.<!--more-->


## Cómo se usa MlFLow

Crear un modelo se trata de realizar muchos ensayos, básicamente prueba y error. Nunca es posible saber a priori que tipo de modelo, qué procesamiento, que selección de variables o qué hiperparámetros van a ser los que entreguen los mejores resultados. El tema es, ¿cómo organizar los modelos y como saber exactamente qué combinación usar?

Aquí es donde MlFlow entra en juego, ya que entrega una manera de tener todo organizado en una UI decente.
Tengo que decir que nunca he utilizado MlFLow antes y al mismo tiempo nunca he encontrado un buen tutorial que me ayude a entender en detalle como funciona. Así que no me quedó otra que crearme un tutorial para mí mismo.

La idea es probar las distintas funcionalidades que tiene para eventualmente generar un workflow que me permita ser lo más eficiente posible al momento de modelar.

Entonces lo primero:

```shell
$ pip intall mlflow
```

{: title="Instalar MlFlow por consola"}

Luego se puede inicializar la UI en http://localhost:5000 corriendo el siguiente comando:

```shell
$ mlflow ui
```

{: title="Instalar MlFlow por consola"}

![]({{ site.urlimg }}mlflow/mlflow.PNG)

Para aprender cómo usar esta UI vamos a utilizar el dataset de Titanic. Para obtenerlo pueden descargarlo desde [acá](https://www.kaggle.com/c/titanic/data) o si tienen instalada la API de kaggle pueden descargar esto como:

```shell
$ kaggle competitions download -c titanic
```
{: title="Descargar el set de Titanic usando la API de Kaggle"}

{% include alert tip='Tip: Recomiendo encarecidamente descargar la API de Kaggle para jugar con sus respectivos datasets. La verdad es fácil de instalar y de usar, [acá](https://www.kaggle.com/docs/api) las intrucciones de cómo instalarla.'%}

Entonces empecemos con los datos:

```python
import pandas as pd
import numpy as np

df = pd.read_csv('train.csv')
df.head()
```
{: title="Importar datos"}



<div class='table-overflow'>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
      <th>Signing_date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
      <td>1911-05-17</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
      <td>1911-07-23</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
      <td>1911-09-08</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
      <td>1911-06-26</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
      <td>1911-10-25</td>
    </tr>
  </tbody>
</table>
</div>

{% include alert warning='Warnng: Inicialmente sólo se imputarán Nulos y encodearan variables categóricas como número ordinales. Obviamente este approach es sumamente isimplista y no es necesariamente la mejor opción para lograr buenos resultados, pero la idea es enfocarse en cómo funciona MlFlow.'%}

```python
df.isnull().sum()
```


    PassengerId       0
    Survived          0
    Pclass            0
    Name              0
    Sex               0
    Age             177
    SibSp             0
    Parch             0
    Ticket            0
    Fare              0
    Cabin           687
    Embarked          2
    Signing_date      0
    dtype: int64



Se imputará `Age` con su media. Se dropearán `Cabin` y `Signing_date`, E imputará `Embarked` con la moda.

{% include alert alert=' Ojo:`Signing_date` es una variable fake que inventé para otro proyecto y que no viene incluída en el dataset descargado desde Kaggle. Si no lo tienen, sólo omita esta parte.'%}

```python
import category_encoders as ce
mean_age = df.Age.mean()
mode_embarked = df.Embarked.mode()
mean_fare = df.Fare.mean()
```
```python
def make_data_ready(data):
    result = (data.fillna(value = {'Age': mean_age, 'Embarked': mode_embarked, 'Fare': mean_fare})
        .drop(columns = ['Cabin','Signing_date'], errors = 'ignore')
        .set_index('PassengerId')
     )
    
    ord = ce.OrdinalEncoder()
    out = ord.fit_transform(result)
    return out

df = make_data_ready(df)
df.head()
```
{: title="Imputando el Modelo"}




<div class='table-overflow'>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Embarked</th>
    </tr>
    <tr>
      <th>PassengerId</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>7.2500</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>2</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
      <td>71.2833</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>3</td>
      <td>3</td>
      <td>2</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>7.9250</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>1</td>
      <td>4</td>
      <td>2</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>4</td>
      <td>53.1000</td>
      <td>1</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0</td>
      <td>3</td>
      <td>5</td>
      <td>1</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>5</td>
      <td>8.0500</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



```python
from sklearn.model_selection import train_test_split

X_train, X_val, y_train, y_val = train_test_split(df.drop(columns = 'Survived'), 
                                                          df.Survived, 
                                                          test_size = 0.25, 
                                                          random_state = 123)
```
{: title="Data Split"}

## Modelo

Después de pasar un buen par de horas leyendo la [documentación](https://www.mlflow.org/docs/latest/index.html) (algunas cosas terminaron siendo más difíciles de lo que me esperaba) Logré entender como hacer funcionar esto. Entonces la primera recomendación es crear un experimento. Esto se puede hacer en la UI directamente:

![]({{ site.urlimg }}mlflow/create_exp.PNG)

O por comando:

```python
import mlflow
mlflow.set_experiment(experiment_name = 'New Experiment')
```

    INFO: 'New Experiment' does not exist. Creating a new experiment
    

Este comando es bastante útil, porque creará un experimento en caso que no exista, o seteará el experimento como el "Activo" en caso de que ya exista. A pesar de que existe el comando `.create_experiment()` igual prefiero el anterior por su flexibilidad.

Luego la la lógica de MlFlow es super directa. Una vez que que se tiene el experimento hay que iniciar un `Run`, para ello lo mejor es utilizar `mlflow.start_run()` dentro de un context manager. 

{% include alert info='`mlflow` es la API de alto nivel que simplifica toda las cosas pero algunas de sus funcionalidades pueden ser bastante engorrosas cuando es primera vez que uno utiliza esto. Los pro de esta API es que todos los Id serán creados automáticamente, lo cual es bueno para evitar sobreescribir cosas cuando uno no quiere. El contra es que los Id son extremadamente complicados y dificiles de recordar y de acceder. En caso de querer controlar esto habrá que utilizar la API de bajo nivel llamada `mlflow.tracking`'%}

Una vez que esto está claro, la lógica es sencilla, hay que abrir un `Run` y se pueden `loguear` lo siguiente:

   * parameters: Son generalmente Hiperparámetros del modelo o cualquier valor del notebook que se quiera trackear. Normalmente estos valores son dados por el modelador.

   * metrics: Estos son valores que son entregados como resultado del proceso de modelamiento y deben ser medibles.
   * artifacts: Puede ser cualquier archivo que se quiera adjuntar, pueden ser gráficos, imágenes, etc.

   * models: Este es el modelo, normalmente serializado como .pkl (la verdad no he revisado si soporta los .joblib, pero debería). Esta funcionalidad tiene una API distinta para cada libería de modelamiento, por ejemplo si es un modelo de `Scikit-Learn` está `mlflow.sklearn`, si es un `Xgboost`, entonces existe `mlflow.xgboost` y así.
   
Para este ejemplo voy a correr una Regresión Logística.
In this example, I'll run a simple Logistic Regression, in which I will like to save some parameters such as: solver, C, and max_iter. I will open 3 Runs:

```python
from sklearn.linear_model import LogisticRegression
import mlflow
import mlflow.sklearn
```
{: title="Importación librerías"}


```python
C = 1.5, max_iter = 1000, name = 'Run 1'

with mlflow.start_run(run_name = name) as run:
    lr = LogisticRegression(solver = 'lbfgs', random_state = 123, max_iter = max_iter, C = C)
    lr.fit(X_train,y_train)
    acc = lr.score(X_val,y_val)  
    
    mlflow.log_param("run_id", run.info.run_id)
    mlflow.log_param("solver", 'lbfgs')
    mlflow.log_param("max_iter", max_iter)
    mlflow.log_param("C", C)
    mlflow.log_metric("Accuracy", acc)
    mlflow.sklearn.log_model(lr, name)
```
{: title="Entrenando el modelo"}

La idea es correr un modelo similar al de arriba varias veces con distintos valores a loguear.

![picture of me]({{ site.urlimg }}mlflow/exp_results.PNG)

Se corrieron 4 `Runs`. Cada `Run` loguea automáticamente la hora de inicio. Justo al lado aparece un ícono rojo o verde dependiendo si el `Run` corrió sin errores. También es posible darle un Nombre a cada `Run` utilizando el parámetro `run_name`, esto es opcional pero recomendado, para saber de qué se trata el `Run` en cuestión.

{% include alert info='Info:Se puede notar en este caso que el Run 2 está repetido, ya que en este caso se corrió 3 veces y en una de ellos falló. El identificador único de cada Run no es el Name si no el `run_id`'%}

{% include alert alert='Encontré que el `run_id` es particularmene dificil de obtener y definirlo manualmente genera otros prolemas con los que no quiero lidiar. Por eso es sumamente importante que cuando se corra un `Run` se agregue `mlflow.log_param("run_id", run.info.run_id)` para almacenar el run_id. Esto va a ser particularmente útil luego para acceder otras funcionalidades de MlFlow.'%}

Ahora, al clickear en uno de los `Run` se llega a la siguiente vista:

![picture of me]({{ site.urlimg }}mlflow/results_1.PNG)

En esta parte se loguearán los parámetros más la información del: inicio de cada `Run`, duración del `Run`, etc. Lo cual es bastante útil para evitar magic commands como `%%time`.

![picture of me]({{ site.urlimg }}mlflow/results_2.PNG)

Y existe otra parte que muestra las métricas y los artefactos. En nuestro caso sólo se tiene el modelo como un archivo `.pkl`.

Existen otros comandos que son bastante útiles para acceder a los objetos logueados.


The format of this information is super complicated to deal with so I recommmend to convert it into a dictionary like this:


```python
dict(mlflow.get_experiment_by_name('New Experiment'))
```
{: title="Acceder a un Experimento por su Nombre"}


    {'artifact_location': 'file:///C:/Users/fata2810/OneDrive%20-%20Retail%20Financiero%20Scotiabank%20Cencosud/Clases%20Python/mlruns/0',
     'experiment_id': '0',
     'lifecycle_stage': 'active',
     'name': 'New Experiment',
     'tags': {}}

El formato eso sí es super complicado así que mi recomendación es convertirlo a algo más amigable como un diccionario.

Para acceder a otro comandos hay que ingresar a la API de bajo nivel como por ejemplo:


Some other important commands are based in the `mlflow.tracking` API such as `.get_run()` that will provide the info about the runs and `.list_run_infos` that will retrieve basically all the run_ids but in a really ugly way. 

{% include alert warning='Warning: El `experiment_id` es un String, aunque parezca ser un entero.'%}

```python
from mlflow.tracking import MlflowClient

client = MlflowClient()
client.list_run_infos(experiment_id = '0')
```
{: title="Traer info de los run_id de un Experimento"}


    [<RunInfo: artifact_uri='file:///C:/Users/fata2810/OneDrive%20-%20Retail%20Financiero%20Scotiabank%20Cencosud/Clases%20Python/mlruns/0/86ba898ad44049edb55203166cfab227/artifacts', end_time=1594022373954, experiment_id='0', lifecycle_stage='active', run_id='86ba898ad44049edb55203166cfab227', run_uuid='86ba898ad44049edb55203166cfab227', start_time=1594022373922, status='FAILED', user_id='FATA2810'>,
     <RunInfo: artifact_uri='file:///C:/Users/fata2810/OneDrive%20-%20Retail%20Financiero%20Scotiabank%20Cencosud/Clases%20Python/mlruns/0/cf34867bb1ee45bc9755446eba6e073e/artifacts', end_time=1594022347517, experiment_id='0', lifecycle_stage='active', run_id='cf34867bb1ee45bc9755446eba6e073e', run_uuid='cf34867bb1ee45bc9755446eba6e073e', start_time=1594022347331, status='FINISHED', user_id='FATA2810'>,
     <RunInfo: artifact_uri='file:///C:/Users/fata2810/OneDrive%20-%20Retail%20Financiero%20Scotiabank%20Cencosud/Clases%20Python/mlruns/0/d1534e5faf7642faa0f028bdaf68a6bd/artifacts', end_time=1594022336377, experiment_id='0', lifecycle_stage='active', run_id='d1534e5faf7642faa0f028bdaf68a6bd', run_uuid='d1534e5faf7642faa0f028bdaf68a6bd', start_time=1594022336288, status='FINISHED', user_id='FATA2810'>,
     <RunInfo: artifact_uri='file:///C:/Users/fata2810/OneDrive%20-%20Retail%20Financiero%20Scotiabank%20Cencosud/Clases%20Python/mlruns/0/c55159dcfe884e21b8c35f18168fdcde/artifacts', end_time=1594022312153, experiment_id='0', lifecycle_stage='active', run_id='c55159dcfe884e21b8c35f18168fdcde', run_uuid='c55159dcfe884e21b8c35f18168fdcde', start_time=1594022311962, status='FINISHED', user_id='FATA2810'>]


```python
client.get_run(run_id = 'c55159dcfe884e21b8c35f18168fdcde')
```
{: title="Extraer la data del Run utilizando el run_id"}


    <Run: data=<RunData: metrics={'Accuracy': 0.7937219730941704}, params={'C': '1.5',
     'max_iter': '1000',
     'run_id': 'c55159dcfe884e21b8c35f18168fdcde',
     'solver': 'lbfgs'}, tags={'mlflow.log-model.history': '[{"run_id": "c55159dcfe884e21b8c35f18168fdcde", '
                                 '"artifact_path": "Run 1", "utc_time_created": '
                                 '"2020-07-06 07:58:32.125378", "flavors": '
                                 '{"python_function": {"loader_module": '
                                 '"mlflow.sklearn", "python_version": "3.7.7", '
                                 '"data": "model.pkl", "env": "conda.yaml"}, '
                                 '"sklearn": {"pickled_model": "model.pkl", '
                                 '"sklearn_version": "0.22.2.post1", '
                                 '"serialization_format": "cloudpickle"}}}]',
     'mlflow.runName': 'Run 1',
     'mlflow.source.name': 'C:\\Users\\fata2810\\AppData\\Local\\Continuum\\anaconda3\\envs\\MLprojects\\lib\\site-packages\\ipykernel_launcher.py',
     'mlflow.source.type': 'LOCAL',
     'mlflow.user': 'FATA2810'}>, info=<RunInfo: artifact_uri='file:///C:/Users/fata2810/OneDrive%20-%20Retail%20Financiero%20Scotiabank%20Cencosud/Clases%20Python/mlruns/0/c55159dcfe884e21b8c35f18168fdcde/artifacts', end_time=1594022312153, experiment_id='0', lifecycle_stage='active', run_id='c55159dcfe884e21b8c35f18168fdcde', run_uuid='c55159dcfe884e21b8c35f18168fdcde', start_time=1594022311962, status='FINISHED', user_id='FATA2810'>>


A mi parecer el feature más importante de MlFlow es que permite guardar `.pkl`. Creo que esto en particular no está bien explicado y me costó montones hacerlo funcionar, pero aquí va:

Primero hay que importar el submodulo del modelo elegido y luego utilizar `mlflow.sklearn.load_models()` con un URI. Pero <q>¿Qué es un URI?</q> Es como un path y en MlFlow funciona así:

{% include alert text='
runs:/run_id/relative_path_to_models.'%}

En forma simple, extraer un modelo funciona así:

* El run_id se puede obtener utilizando el UI o los comandos que ya se mostraron. El path relativo va a ser la información del segundo argumento de `mlflow.sklearn.log_model(lr, name)`. En este caso `name` creará una carpeta con ese nombre. `name` no es más que el Run Name.

```python
import mlflow.sklearn
model_lr = mlflow.sklearn.load_model(f'runs:/c55159dcfe884e21b8c35f18168fdcde/Run 1') #Run 1 is the name of the first experiment
model_lr
```
{: title="Cargar un modelo utilizando el URI"}

    LogisticRegression(C=1.5, class_weight=None, dual=False, fit_intercept=True,
                       intercept_scaling=1, l1_ratio=None, max_iter=1000,
                       multi_class='auto', n_jobs=None, penalty='l2',
                       random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                       warm_start=False)


{% include alert success='Como se puede ver, ahora el modelo LR está cargado desde MlFlow en el ambiente de Python.'%}

Esta fue una breve intro a MlFLow, mostrando sus funcionalidades básicas. Aunque la herramienta es bastante simple e intuitiva, la verdad me costó bastante entenderla porque no hay muchos tutoriales que expliquen todo en orden y que tengan códigos de ejemplo.

Voy a probar otras funcionalidades y les cuento. Nos Vemos!!

