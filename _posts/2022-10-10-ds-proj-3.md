---
permalink: /project-pt3/ 
title: "쮿agamos un Proyecto desde cero? Parte 3"
subheadline: "Modelo de Estimaci칩n de RUL"
teaser: ""
# layout: page-fullwidth
usemathjax: true
category: ml
header: no
image:
    thumb: rul/lags.png
tags:
- sklearn
- tutorial
- ML
- dl
published: true
---

![picture of me]({{ site.urlimg }}rul/lags.png){: .left .show-for-large-up .hide-for-print width="250"}
![picture of me]({{ site.urlimg }}rul/lags.png){: .center .hide-for-large-up width="500"}

Esta es la tercera patita de c칩mo hacer un proyecto desde cero. Puedes ver [la parte 1 ac치]({{ site.baseurl }}/project-pt1/) y [la parte 2 ac치]({{ site.baseurl }}/project-pt2/). La idea es que, como ya implementamos un modelo baseline y un clipping, ahora podamos ir implementando elementos que permitan poder mejorar el puntaje obtenido. <!--more-->. 

Si es que hiciste la tarea, habr치s notado que algo raro pasa. En la vida real nosotros no podemos ver nuestro Test Set, eso ir치 ocurriendo a medida de que el Motor vaya funcionando. Por lo tanto, nosotros deber칤amos confiar que nuestro esquema de validaci칩n es suficientemente robusto para decirnos que el modelo va a generalizar como corresponde en Test-Time. Pero ac치 no ocurre.

![picture of me]({{ site.urlimg }}rul/resultados_pt2.png){: .center }

Los resultados que debieron haber obtenido muestran que el mejor puntaje de Validaci칩n se obtiene con Clipping de 150 pero no es el que generaliza mejor en Test. En test nuestro modelo act칰a mejor con Clipping de 120. Lo que acaba de pasar es algo muy dificil de detectar (no sabr칤a como hacerlo en tiempo real), nuestro modelo no est치 generalizando de manera apropiada. Y esto puede ser por varias razones:

* Nuestro esquema de Validaci칩n no es confiable.
* Tenemos alg칰n error en nuestro c칩digo.
* No estamos capturando apropiadamente el error.

{% include alert tip='Detectar este tipo de Problemas es quiz치s de las Skills m치s complicadas de desarrollar, y para los que dicen que la Modelaci칩n Competitiva (Kaggle principalmente) no sirve, d칠jenme decirles que esto es precisamente la skill principal a desarrollar en competencias. Poder descubrir a ciegas si el modelo est치 generalizando de manera apropiada o no.'%}

Me gustar칤a pensar que este problema se da por lo siguiente:

![]({{ site.urlimg }}rul/F_vs_t_1.png){: .center }

Nuestro modelo tiene predicciones bajo cero para RUL reales muy peque침os. Lo cual no refleja la realidad. Debemos pensar que el objetivo final del modelo es poder predecir de manera anticipada que nuestro motor fallar치. Por lo tanto, no nos interesan valores negativos dici칠ndonos que la falla ya ocurri칩. Para corregir realizaremos un Post-Procesamiento. Es decir, evitaremos que nuestro modelo prediga RUL menores a uno, de esa manera cuando hayan predicciones con 1 indicar치 que el motor est치 pronto a fallar. Quiero pensar que esto solucionar치 nuestro problema 游땟.

Adicionalmente, intetaremos otro approach. Debido a la naturaleza temporal del problema generaremos variables que nos permitan modelar el problema en el tiempo. Para ello generaremos lags, variables con un desfase en el tiempo. Para ello trataremos de descubrir cu치l es el mejor set de lags, dejando en este caso un RUL_CLIP fijo de 125.

Vamos a implementar esos cambios.

## Archivo de Configuraci칩n params.yaml

```yaml
base:
  random_seed: 42

import:
  train_name: train_FD001.txt
  test_name: test_FD001.txt
  rul_name: RUL_FD001.txt

featurize:
  index_names: [unit_nr, time_cycles]
  setting_names: [setting_1, setting_2, setting_3]
  sensor_names: [s_1, s_2, s_3, s_4, s_5, s_6, s_7, s_8, s_9, s_10, s_11, s_12, s_13,
    s_14, s_15, s_16, s_17, s_18, s_19, s_20, s_21]
  to_keep: [s_2, s_3, s_4, s_6, s_7, s_8, s_9, s_11, s_12, s_13, s_14, s_15, s_17,
    s_20, s_21]
  lags:
  - 1
  - 2
  - 3
  - 4
  - 5
  - 10
  - 20
  - 30
train:
  model_name: model.joblib
  n_split: 5
  rul_clip: 125
  pred_clip: 1
  standardize: true
```
En este nuevo archivo de configuraci칩n tenemos lo siguiente:

* En la etapa featurize mantenemos el par치metro `to_keep`, que nos perrmitir치 determinar con qu칠 sensores queremos quedarnos. 
* Adem치s agregamos los posibles lags que nos gustar칤a calcular. (La raz칩n en utilizar - como separador es que cuando probamos listas como hiperpar치metros DVC al sobreescribir el 칩ptimo lo deja en ese formato).
* En la etapa agregamos dos par치metros nuevos: `standardize` que permitir치 activar o no el StandardScaler, que es buena pr치ctica para modelos lineales y que no ven칤amos realizando. Adem치s fijamos el `rul_clip` a 125 y el `pred_clip` a 1.

## Featurize

En esta etapa utilizaremos ahora la funci칩n `create_features()` cambiar치 de la siguiente forma:

```python

def create_features(df_train, df_test, params):
    
    to_keep = params['to_keep']
    lag_features = []
    for lag in params['lags']:
        
        cols = [col + f'_lag_{lag}' for col in to_keep]
        lag_features.extend(cols)
        df_train[cols] = df_train.groupby('unit_nr')[to_keep].shift(lag)
        df_test[cols] = df_test.groupby('unit_nr')[to_keep].shift(lag)
    
    df_train.dropna(inplace = True)
    df_test.dropna(inplace = True)
    
    # selecting last instance to predict
    df_test = df_test.groupby('unit_nr').last()

    return df_train[to_keep + lag_features], df_test[to_keep + lag_features], df_train.rul
```

Esta funci칩n aceptar치 un set de train y test y crear치 los lags s칩lo para los sensores que vamos a dejar (los que entregan info de acuerdo a `to_keep`). Luego debido a la naturaleza del lag, quedar치n observaciones con nulos, los cual simplemente los eliminaremos. Tambi칠n eliminaremos etiquetas, por lo que devolveremos el Train set y el Test set con las nuevas variables y las etiquetas de entrenamiento que sobrevivan a la eliminaci칩n de nulos.

La definici칩n de features se ve mucho m치s sencilla ahora:

```python
df_train = add_rul(df_train)
train_features, test_features, train_labels = create_features(df_train, 
                                                df_test, 
                                                params = params)
```
Notar que los set ingresados a `create_features()` son el train luego de crear el RUL y el test sin agrupar.

## Train

Cuando entrenamos nuestro modelo ahora tendremos los siguientes cambios:

```python
if params['standardize']:
    model = Pipeline([('scaler', StandardScaler()),
                    ('model', LinearRegression())])
else:
    model = LinearRegression()

#======================================================
# Validation Metrics
#======================================================
folds = KFold(n_splits=params['n_split'], 
                shuffle=True, 
                random_state=Config.RANDOM_SEED)

mae = np.zeros(params['n_split'])
rmse = np.zeros(params['n_split'])
r2 = np.zeros(params['n_split'])

for fold_, (train_idx, val_idx) in enumerate(folds.split(X = train_features, y = train_labels)):
    log.info(f'Training Fold: {fold_}')
    
    X_train, X_val = train_features.iloc[train_idx], train_features.iloc[val_idx]
    y_train, y_val = train_labels.iloc[train_idx], train_labels.iloc[val_idx]
    
    # Training Clipping
    model.fit(X_train, y_train.clip(upper = params['rul_clip']))
    
    # Adding Prediction Clipping (Numpy)
    val_preds = model.predict(X_val).clip(min = params['pred_clip'])
    val_mae = mean_absolute_error(y_val, val_preds)
    val_rmse = mean_squared_error(y_val, val_preds, squared=False)
    val_r2 = r2_score(y_val, val_preds)
    
    mae[fold_] = val_mae
    rmse[fold_] = val_rmse
    r2[fold_] = val_r2
    log.info(f'Validation MAE for Fold {fold_}: {val_mae}')
    log.info(f'Validation RMSE for Fold {fold_}: {val_rmse}')
    log.info(f'Validation R2 for Fold {fold_}: {val_r2}')
```

Agregaremos la opci칩n de un Pipeline de Estandarizaci칩n y adem치s al momento de Predecir aplicaremos Clipping m칤nimo (para evitar los RUL negativos). 

{% include alert info='El resultado de la predicci칩n es un Numpy Array y el clipping en Numpy utiliza min, max en vez de lower, upper. Fue un dolor de cabeza inicialmente, porque no entend칤a por qu칠 me arrojaba error.'%}

## Evaluate

En el caso de nuestro Evaluate, tambi칠n debemos aplicar clipping.

```python
model = joblib.load(Config.MODELS_PATH / 'model.joblib')
# Adding Prediction Clipping (Numpy)
y_pred = model.predict(X_test).clip(min = params['pred_clip'])
```

## Proceso de Experimentaci칩n

DVC es sumamente inteligente, y podemos utilizarlo para hacer nuestra b칰squeda de Hiperpar치metros. DVC autom치ticamente detecta qu칠 etapas se deben reejecutar y cu치les se pueden reutilizar dependiendo de nuestras dependencias definidas en `dvc.yaml` (ejecutando `dvc_config.sh`). 

Para definir nuestra b칰squeda de Hiperpar치metros utilizarmos `exp_config.sh` para probar con distintos lags.

```bash
dvc exp run -S featurize.lags=[1,2,3,4,5]
dvc exp run -S featurize.lags=[1,2,3,4,5,6,7,8,9]
dvc exp run -S featurize.lags=[1,2,3,4,5,10,20,30]
dvc exp run -S featurize.lags=[1,2,3,4,5,10,20]
dvc exp run -S featurize.lags=[1,3,6,9,12,15]
```

Estudiaremos el efecto de los distintos niveles de Lag:

<center>
<a href="https://colab.research.google.com/github/datacubeR/cmapps/blob/time-series/LR_timeseries.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg"></a>
</center>


{% include alert success= 'Ahora les toca poder ejecutar todo este proceso en Colab. 쯄ejoramos nuestros resultados? 쮽ue posible solucionar el problema de Generalizaci칩n? 쯏 si quiero probar otro modelo? Cambia el tipo de Modelo a un Random Forest o a un XGBoost y cu칠ntame c칩mo te dan los resultados.'%}

Habiendo entendido esta parte la verdad es que podr칤as utilizar cualquier modelo de Machine Learning Shallow (los cl치sicos, RF, XGB, LGBM, Catboost, incluso un Multilayer Perceptron) y no habr칤an grandes cambios. Variables extras pueden ir en featurize y el resto del Pipeline sigue igual.

Por eso es tan importante la parte de programaci칩n en Ciencia de Datos. Mucho del gran esfuerzo se hace al principio en el cual tenemos que dedicar mucho tiempo a un Pipeline robusto que nos permita experimentar de manera r치pida y sencilla. 

Consejo/Opini칩n muy personal: 
* Utiliza Jupyter Notebooks cuanto quieras para explorar, visualizar, incluso c칩mo instrucciones de Reproducibilidad como estoy utilizandolo yo ahora.
* Vamos de a poco dejando de usar los Jupyter Notebooks. Lamentablemente este tipo de estructura para el core del c칩digo te fuerza a hacer c칩digos eternos y poco modulares. Uno se olvida de utilizar abstreaer en Clases o Funciones y copia y pega a veces incluso ejecutando en 칩rdenes diferentes.
* Utiliza alguna herramienta de Automatizaci칩n de Pipelines, yo uso DVC, pero est치 MAKE (que estoy empezando a revisar y posiblemente se vuelva un tutorial luego), Airflow (tambi칠n viene luego), y un largo etc.

쯏 habr치 parte 4?

<!-- 
Esta es la parte final del tutorial. Espero que hayan podido aprender con esto algunos de los inconvenientes del modelamiento.
Pueden ver que utilizando s칩lo una Regresi칩n Lineal fue posible solucionar bastante bien nuestro problema. Obviamente esto puede extenderse a mucho m치s utilizando XGBoost, LightGBM o Catboost. -->

[**Alfonso**]({{ site.baseurl }}/contact/)


