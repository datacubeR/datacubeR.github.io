---
permalink: /project-pt2/ 
title: "¿Hagamos un Proyecto desde cero? Parte 2"
subheadline: "Modelo de Estimación de RUL"
teaser: ""
# layout: page-fullwidth
usemathjax: true
category: ml
header: no
image:
    thumb: rul/rul.png
tags:
- sklearn
- pytorch
- tutorial
- ML
- dl
published: false
---

![picture of me]({{ site.urlimg }}rul/rul.png){: .left .show-for-large-up .hide-for-print width="250"}
![picture of me]({{ site.urlimg }}rul/rul.png){: .center .hide-for-large-up width="500"}

Esta es la segunda patita de cómo hacer un proyecto desde cero. Puedes ver [la parte 1 acá]({{ site.baseurl }}/project-pt1/). La idea es que, como ya implementamos un modelo baseline, ahora podamos ir implementando mejoras para poder mejorar el puntaje obtenido. <!--more-->Mucho del trabajo duro ya lo hicimos en la parte 1 por lo que ahora nos enfocaremos en las mejoras.

De acuerdo a nuestro Análisis Exploratorio habíamos visto que existen sensores que no están aportando información. Por lo tanto, una primera cosa a probar sería eliminar de nuestras features aquellos sensores que no aportan información. Por otro lado debido a que estamos utilizando una regresión lineal, podríamos crear interaciones entre variables para ver qué tal le va.

Finalmente si analizamos nuestro True vs Fitted Curve de la parte pasada podemos ver lo siguiente:

![picture of me]({{ site.urlimg }}rul/F_vs_t_1.png){: .center}

A partir de esto podemos inferir lo siguiente: 

* Lo primero es que al parecer a medida que el RUL aumenta nuestros errores se hacen más grandes. Eso normalmente es esperable ya que que no hay evidencia para decir que el motor fallará cuando falta demasiado tiempo para su falla. Debido a la naturaleza del problema a nosotros nos interesa entender cuando queda poco tiempo para la falla y enfocarnos ahi. Una técnica utilizada es usar un clipping. Es decir, yo permite un RUL máximo, todo lo que supere ese RUL máximo lo que bajo a dicho nivel.
<!-- * Pero otra cosa que se puede ver es que el modelo genera predicciones negativas. Lo cual no está bien. El modelo debería siempre ser capaz de predecir un número positivo. Y es más, nunca debería decirme que hoy falló. De ser ese el caso, no me permite tomar medidas para prevenirlo. Por eso aplicaremos un clipping inferior para evitar dicho comportamiento. El primer paso es un preprocesamiento, antes de entrenar. El segundo paso es un postprocesamiento, después de predecir. -->

Implementemos esos cambios y tratemos de buscar el valor de RUL más apropiado.

## Archivo de Configuración params.yaml

```yaml
base:
  random_seed: 42

import:
  train_name: train_FD001.txt
  test_name: test_FD001.txt
  rul_name: RUL_FD001.txt

featurize:
  index_names: [unit_nr, time_cycles]
  setting_names: [setting_1, setting_2, setting_3]
  sensor_names: [s_1, s_2, s_3, s_4, s_5, s_6, s_7, s_8, s_9, s_10, s_11, s_12, s_13,
    s_14, s_15, s_16, s_17, s_18, s_19, s_20, s_21]
  to_keep: [s_2, s_3, s_4, s_6, s_7, s_8, s_9, s_11, s_12, s_13, s_14, s_15, s_17,
    s_20, s_21]
train:
  model_name: model.joblib
  n_split: 5
  rul_clip: 50
```
En este nuevo archivo de configuración tenemos lo siguiente:

* En la etapa featurize agregamos el parámetro `to_keep`, que nos perrmitirá determinar con qué sensores queremos quedarnos. Es decir, no consideramos los que no aportan información. La razón por la que hacemos eso es porque `sensor_names` tiene otra función que es darle el nombre a las variables a importar.
* En la etapa train usaremos un clip de 50 inicialmente. Pero de igual manera iremos buscando cuál es el valor óptimo.

## Featurize

En esta etapa utilizaremos ahora la función `create_features()` que nos permitirá crear las interacciones con Scikit-Learn.

```python
def create_features(df_train, df_test, params = None):
    pf = PolynomialFeatures(interaction_only=True)
    
    df_train = pd.DataFrame(pf.fit_transform(df_train), columns = pf.get_feature_names_out())
    df_test = pd.DataFrame(pf.fit_transform(df_test), columns = pf.get_feature_names_out())
    
    return df_train, df_test
```

Esta función aceptará un set de train y test y creará interacciones entre ellas.

Finalmente el la etapa de definición de features se verá así:

```python
to_keep = params['to_keep']
df_train = add_rul(df_train)
train_features = df_train[to_keep]
test_features = df_test.groupby('unit_nr').last()[to_keep]

train_features, test_features = create_features(train_features, test_features)
```
Notar que los set ingresados a `create_features()` son el train luego de crear el RUL y el test, luego de ser agrupado para obtener el último ciclo.

## Train

Cuando entrenamos nuestro modelo ahora lo haremos con el RUL clippeado. Por lo tanto, el KFold CV cambia de la siguiente forma:

```python
for fold_, (train_idx, val_idx) in enumerate(folds.split(X = train_features, y = train_labels)):
    log.info(f'Training Fold: {fold_}')
    
    X_train, X_val = train_features.iloc[train_idx], train_features.iloc[val_idx]
    y_train, y_val = train_labels.iloc[train_idx], train_labels.iloc[val_idx]
    
    model.fit(X_train, y_train.clip(upper = params['rul_clip']))
    val_preds = model.predict(X_val)
    val_mae = mean_absolute_error(y_val, val_preds)
    val_rmse = mean_squared_error(y_val, val_preds, squared=False)
    val_r2 = r2_score(y_val, val_preds)
    
    mae[fold_] = val_mae
    rmse[fold_] = val_rmse
    r2[fold_] = val_r2
    log.info(f'Validation MAE for Fold {fold_}: {val_mae}')
    log.info(f'Validation RMSE for Fold {fold_}: {val_rmse}')
    log.info(f'Validation R2 for Fold {fold_}: {val_r2}')
```

Notar que al momento del fit, ahora `y_train` irá con el clip indicado en mis parámetros.

## Evaluate

En el caso de nuestro Evaluate, no tendremos ningún cambio, ya que realizaremos el mismo proceso.

## Proceso de Experimentación

DVC es sumamente inteligente, y podemos utilizarlo para hacer nuestra búsqueda de Hiperparámetros. DVC automáticamente detecta qué etapas se deben reejecutar y cuáles se pueden reutilizar dependiendo de nuestras dependencias definidas en `dvc.yaml` (ejecutando `dvc_config.sh`). 

Para definir nuestra búsqueda de Hiperparámetros utilizarmos `exp_config.sh`:

```bash
dvc exp run -S train.rul_clip=150
dvc exp run -S train.rul_clip=130
dvc exp run -S train.rul_clip=125
dvc exp run -S train.rul_clip=120
dvc exp run -S train.rul_clip=90
dvc exp run -S train.rul_clip=70
dvc exp run -S train.rul_clip=50
dvc exp run -S train.rul_clip=30
dvc exp run -S train.rul_clip=10
```

Estudiaremos el efecto de varios niveles de clipping en Colab.

<center>
<a href="https://colab.research.google.com/github/datacubeR/cmapps/blob/LR-v2/LR_v2.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg"></a>
</center>


{% include alert success= 'Ahora les toca poder ejecutar todo este proceso en Colab. ¿Con cuántas features se entrenó el modelo?¿Sirvió de algo lo que implementamos? ¿Cuál es el mejor valor de Clipping? ¿Ves algún problema con las predicciones?'%}

[**Alfonso**]({{ site.baseurl }}/contact/)


