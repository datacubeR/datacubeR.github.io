---
permalink: /ds-lib/ 
title: "¬øQu√© debo aprender para ser Data Scientist?"
subheadline: "Un compendio con m√°s de 100 tecnolog√≠as para Ciencia de Datos."
teaser: ""
# layout: page-fullwidth
usemathjax: true
category: ds
header: no
image:
    thumb: libraries/librer√≠as.png
tags:
- python
- tutorial
published: true
---

![picture of me]({{ site.urlimg }}libraries/librer√≠as.png){: .left .show-for-large-up .hide-for-print width="300"}
![picture of me]({{ site.urlimg }}libraries/librer√≠as.png){: .center .hide-for-large-up width="250"}

La ciencia de datos es una de las disciplinas m√°s de moda hoy en d√≠a. Y c√≥mo que por alguna raz√≥n todos quieren ser parte de ello. Sin duda en el mediano/largo plazo probablemente todas las disciplinas tendr√°n una componente de datos y la verdad es que vale la pena aprender a lidiar con ellos.<!--more-->

Hoy en d√≠a la decisi√≥n es simple, trabajar con R o con Python, pero el tema es que Python tiene 150.000+ librer√≠as y R tiene otras tantas, por lo que a veces es abrumante pensar, tengo que aprender todo? Ojo, eso sin contar otro tipo de tecnolog√≠as de Visualizaci√≥n, ETL y un largo etc. Por donde empiezo, tengo un mont√≥n de opciones y no me gustar√≠a perder el tiempo en cosas que no valen la pena.

Adem√°s, en plataformas como Linkedin siempre hay gente en cuyo t√≠tulo dice Data Science \| Machine Learning \| Analytics Expert y un largo etc. y que probablemente en su vida ha programado y comparten publicaciones como esta:

# TL;DR
{: .no_toc }
*[TL;DR]: Too Long; Didn't Read



## TOP 10 LIBRER√çAS DE PYTHON
{: .no_toc }

Esta es una lista que encontr√© por ah√≠:

1. Pandas.
2. NLTK.
3. Plotly.
4. Scikit-learn.
5. Category-encoders (era tremenda librer√≠a pero est√° sin mantenimiento actualmente)
6. Imbalance Learning. (Esta no es ni siquiera una librer√≠a en Python, se llama Imbalanced-Learn)
7. XGBoost.
8. Keras / Tensorflow.
9. Theano. (Nadie usa esto ya)
10. Beautiful Soup.

Colocan una foto llena de logos, y un listado con nombres casi aleatorios:  
![picture of me]({{ site.urlimg }}libraries/ble.png){: .center}

A veces te indican qu√© librer√≠as s√≠ o s√≠ tienes que saber, y nunca las has escuchado:

![picture of me]({{ site.urlimg }}libraries/libraries_1.jpg){: .center}

A veces tienen hasta errores burdos: 

![picture of me]({{ site.urlimg }}libraries/libraries_2.jpg){: .center}

Y uno se pregunta ¬øCon qu√© parto?. Y la verdad es que si bien son librer√≠as que pueden ser √∫tiles, hay que ver si realmente son aplicables al trabajo que haces y si vale el esfuerzo de aprenderlo.

## Un Alto antes de Continuar
{: .no_toc }

La ciencia de datos es una disciplina enorme. Y hay que darla paso a paso, o no vamos a lograr nada y vamos a vivir estresados de tantas cosas que no sabemos usar y que tenemos que aprender. No digo que mi caso sea el perfecto, para nada, pero yo part√≠ as√≠:

* **Business Analyst** (Una especie de Data Analyst, pero enfocado en dar valor al negocio ü§≠ ja ja): En mis primeros 2 a√±os, lo que m√°s hac√≠a era responder preguntas con datos. El resultado, una query en SQL, la mayor parte del tiempo con una tabla exportada en Excel. Aprend√≠ mucho SQL porque las Bases de Datos que us√°bamos eran gigantes y muy complejas. Responder una pregunta de negocio pod√≠a tomar 6 o 7 subqueries, con muchos joins en cada una de ellas. Luego tuve la oportunidad de crear algoritmos sencillos para aplicar l√≥gicas de negocios, a esto le llam√°bamos Calculation Engines (Motores de c√°lculo). Y es b√°sicamente aplicar l√≥gicas de negocio complejas en los datos para chequear qu√© clientes cumpl√≠an o no regulaciones bancarias. Luego mut√© nuevamente a algo m√°s BI, y me tocaba hacer dashboards en Tableau todo el d√≠a, todos los d√≠as. La data que el dashboard necesita no se ordena sola, por lo que aparte de hacer gr√°ficos que digan algo, hab√≠a que hacer mucho SQL de fondo. No fue hasta como mi tercer a√±o de Analista que comenc√© a hacer una Regresi√≥n o un SVM loco por ah√≠. Todo esto en R.

* **Data Scientist**: Luego de como 4 a√±os logre un puesto de Data Scientist. Ya llevaba como 1 a√±o haciendo modelos a escondidas, porque no era mi rol. Y ac√° me cambi√© a Python definitivamente. Tuve que aprender mucho pandas, Scikit-Learn (y los 3 grandes XGBoost, LightGBM y CatBoost) y modelar mucho. Pero con muchos errores te√≥ricos de fondo, y ah√≠ decid√≠ que era importante entender el transfondo te√≥rico. En ese tiempo le√≠a mucho blog y ve√≠a mucho video (a√∫n lo hago, pero ah√≠ part√≠). Quiz√°s desde el 2021 que ya me met√≠ de lleno en el Deep Learning y ac√° estamos.

> Todo tiene que ser progresivo. El `Deep Learning` es s√≥lo una extensi√≥n del `Machine Learning`, en vez de hacer feature selection/engineering, ac√° hay que hacer "Architecture Engineering", tratando de encontrar la arquitectura m√°s apropiada a un problema. Por otra parte el `Machine Learning` es una extensi√≥n del `An√°lisis`. En vez de que tenga que analizar la data manualmente, el modelo aprende los insights por m√≠ y a escala, pero hay que entregar data estructurada. Y el `An√°lisis` es s√≥lo una extensi√≥n de la `Manipulaci√≥n de Datos`. S√≥lo se puede entender la data una vez que la tengo ordenadita. Entonces, hay que partir de a poco, y no saltarse pasos.

{% include toc.md %}

# La idea

Trabajando como Data Scientist creo que he usado 100+ librer√≠as y otras tecnolog√≠as, por lo que quiero hablar de cada una de ellas y dar mi opini√≥n si vale la pena aprenderla o no. Quiero decir que en verdad llevo m√°s tiempo usando R (cerca de 5 a√±os) que Python (3 a√±os), por lo que voy a tratar de dar mi opini√≥n de ambos.

La idea nace porque siempre me pongo a rabiar cuando <q>gente experta</q> publica algo copiado de plataformas como Coding Dojo, Datacamp, etc. con informaci√≥n incompleta y recomendando librer√≠as que nunca han usado (y hoy yo tambi√©n voy a hacer eso ü§≠üòÖ). Entonces decid√≠ que quiero hacer un compendio de las tecnolog√≠as m√°s famosas que hay relacionadas a la ciencia de datos. 

El compendio incluir√° lo siguiente: 

* Todas las librer√≠as/tecnolog√≠as que he utilizado previamente. 
* S√≥lo en ocasiones excepcionales listar√© librer√≠as que no he utilizado cuando ocurra algunos de los siguientes casos:
    * Est√°n en mi lista de estar pr√≥ximo a usarla y si bien no tengo proyectos con ellas ya me he adentrado en su documentaci√≥n.
    * Son demasiado famosas para dejarlas fuera.

Principalmente mencionar√© librer√≠as de Python, porque es el estado del arte en Ciencia de Datos y algunas librer√≠as de mi tiempo usando R. 

Adem√°s me d√≠ la lata de recorrer los 5000 paquetes m√°s descargados en PyPI para recomendar librer√≠as de Python, por lo que en el caso de que corresponda indicar√© el Ranking y el n√∫mero de descargas al 01-07-2022. Debo advertir que puedo estar un poco desactualizado en R porque dej√© de usarlo definitivamente desde fines del 2019. Adem√°s cuando corresponda voy a mencionar otras tecnolog√≠as fuera de R o Python que quiz√°s vale la pena conocer cuando se trabaja en ciertas √°reas de la Ciencia de Datos.

* Librer√≠as de Python incluir√°n Ranking en PyPI (Rk) y n√∫mero de descargas (ND).
* Librer√≠as de R ir√°n acompa√±adas de un indicador (R).
* Otras T√©cnolog√≠as que no son librer√≠as ni de R ni de Python llevar√°n una (O) de Otras.

Voy adem√°s dividirlas en Prioridades:
* 1: Definitivamente debes aprenderlas y empezar a utilizarlas ya. En el caso de R debes aprenderla ya, pero s√≥lo si usas R.
* 2: Dependiendo del caso (si trabajas con tecnolog√≠as anexas) podr√≠a ser una buena opci√≥n.
* 0: No pierdas tu tiempo en aprenderlas. No porque sea mala, sino que la vas a necesitar de manera muy espor√°dica, por lo que hay que saber qu√© puede hacer, para qu√© sirve y puede que en alg√∫n momento de la vida una que otra funci√≥n sea √∫til.

Finalmente, dividir√© todas las recomendaciones en las siguientes categor√≠as:
* Manipulaci√≥n de Datos, 
* Bases de Datos, 
* Machine Learning, 
* Deep Learning, 
* Miscel√°neo. 
* Librer√≠as Est√°ndar

{% include alert todo='Esta lista no es exhaustiva y si alguien quiere contribuir ayudando a reclasificar esto estoy abierto a sugerencias y colaboraciones.' %}

> Disclaimer: Todas las librer√≠as que mencionar√© son excelente en lo que hacen. Si recomiendo no aprenderlas no es porque sean malas (a menos que lo diga), es s√≥lo que muy rara vez necesitar√°s utilizarlas debido a que son demasiado espec√≠ficas y no vale la pena enfocarse en ellas. Basta con leer la documentaci√≥n un rato antes de utilizarla y saber que existe.

Finalmente el objetivo final de este compendio es que los nuevos Data Scientists (y tambi√©n los m√°s experimentados) puedan tener una opini√≥n de qu√© librer√≠as existen y cu√°les s√≠ o s√≠ deber√≠an dominar.

# Manipulaci√≥n de Datos

- **SQL** ((O), Pr: 1): Si bien esta no es una librer√≠a de Python/R, esto es por lejos lo primero que todo Data Scientist debe saber. No es necesario ser un ultra experto en este tema pero s√≠ al menos debes dominar los siguientes aspectos:

* SELECT/FROM
* JOINS: Entender las principales diferencias entre LEFT, RIGHT, INNER, SELF JOINS.
* WHERE, GROUP BY, HAVING.
* ORDER BY
* MIN,MAX, AVG, etc.
* CREATE (volatile, temporary) TABLE, INSERT INTO, WITH (Esto es bien difuso ya que depende del motor).
* Entender al menos los motores m√°s populares que son por lejos MySQL y Postgresql.

Es muy triste ver gente que se hace llamar Data Scientist y no sabe hacer una query. Sin datos, no hay Cient√≠fico de Datos, por lo que s√≠ o s√≠ dale a esto primero que cualquier otra cosa!!

- **Pandas** (Rk: 31, ND: 86M+, Pr: 1): Esta es por lejos la librer√≠a m√°s utilizada en Ciencia de Datos y para mi gusto la m√°s completa. No est√° en el primer lugar porque realmente creo que es m√°s importante saber SQL primero ya que es mucho m√°s simple. B√°sicamente Pandas es un SQL con Esteroides, much√≠simo m√°s poderosa y que bajo ning√∫n motivo puede ser reemplazada por SQL. Pero tiene tantos comandos que al principio uno podr√≠a no saber c√≥mo empezar. Su API es tan buena que existen muchos mirrors, como Dask, koalas, o cuDF, que siguen la misma convenci√≥n s√≥lo que el backend hace algo distinto (B√°sicamente aprendiendo pandas se pueden aprender varias librer√≠as a la vez). Mi recomendaci√≥n es aprender c√≥mo reproducir todo lo aprendido en SQL y luego aprender funciones para resolver problemas espec√≠ficos. ¬øC√≥mo aprender? Lo mejor es a trav√©s del [User Guide](https://pandas.pydata.org/docs/user_guide/index.html) en su propia documentaci√≥n.

- **Numpy** (Rk: 15, ND: 110M+, Pr: 0): Numpy es una librer√≠a de computaci√≥n cient√≠fica, esto quiere decir, computar/calcular implementaciones matem√°ticas/estad√≠sticas desde test de hip√≥tesis, Transformadas de Fourier, y un largo etc. Normalmente se recomienda aprender antes o junto a Pandas, pero realmente creo que (prep√°rense) <mark>no vale la pena aprenderla inicialmente</mark>. Hace unos a√±os era necesario aprender numpy para complementar pandas, ya que hab√≠an muchas cosas que no estaban disponibles en pandas pero s√≠ en Numpy, pero si es que no vas a hacer implementaciones directamente de Algebra Lineal, no va a ser necesario usarla. Obviamente cuando uno es avanzado se dar√° cuenta que es bueno entender conceptos de Numpy como la vectorizaci√≥n. Mi recomendaci√≥n es aprender **s√≥lo funciones que no est√°n en pandas** a medida que las vayas necesitando.

A varios les puede llamar la atenci√≥n que tiene m√°s descargas que Pandas, pero la explicaci√≥n es sencilla. Muchas librer√≠as tiene como dependencia Numpy, Scikit-Learn, Matplotlib, pandas, y un largo etc, que hace obligatorio siempre tenerla instalada.

- **Scipy** (Rk: 65, ND: 42M+, Pr: 0): Este es un pedacito de Numpy a√∫n m√°s espec√≠fico. Definitivamente <mark>no vale la pena aprenderlo</mark>, y s√≥lo se necesitar√°n funciones muy espec√≠ficas. En mi caso s√≥lo la he usado para utilizar matrices sparse cuando queremos disminuir el tama√±o de matrices con demasiados ceros y cuando ense√±√© probabilidad, porque tiene todas las distribuciones de probabilidad (incluso si son muy raras) con sus respectivas funciones para muestreos, pmf, pdf y cdf.

- **dplyr** ((R), Pr: 1): Dir√≠a que es la versi√≥n en R de pandas, pero es un poco m√°s limitado. No porque no tenga las capacidades para hacer lo que pandas hace sino porque el ecosistema de R est√° disperso en m√°s paquetes. Para emular pandas en R se tiene que usar casi todo el tidyverse: `dplyr`, `tidyr`, `lubridate` y `hms` (para fechas), `forecats` (para variables categ√≥ricas), `purrr` (para loops eficientes), `readr` + `vroom` para io, `stringr` y `stringi` para lidiar con strings. Creo que el uso del pipe (%>%) hace que el c√≥digo en R sea m√°s expresivo que en pandas y realmente vale la pena aprender este ecosistema si trabajas en R ya que es mucho m√°s amigable que la sintaxis de R puro.

- **Dask** (Rk: 390, ND: 5.6M+, Pr: 0): Corresponde al motor que provee paralelismo para Pandas. La librer√≠a es excelente pero bajo ning√∫n motivo vale la pena invertir tiempo ac√°, porque b√°sicamente es la misma interfaz de pandas. Basta con hacer `import dask.dataframe as dd` y anteponer `dd` en vez de `pd` y listo. No he tenido que usar nunca esta librer√≠a pero es demasiado famosa para no mencionarla.

- **data.table** (R principalmente pero creo que tambi√©n est√° en Python, Pr: 0): Este es un tema pol√©mico porque hace mucho tiempo hab√≠a una discusi√≥n entre el creador de esta librer√≠a y la gente de RStudio. B√°sicamente `data.table` es la librer√≠a m√°s r√°pida para manejo de datos en R pero su sintaxis no es muy amigable. Afortunadamente Hadley Wickham creo `dtplyr` que permite usar data.table como el backend de dplyr, por lo que dir√≠a que si bien esta librer√≠a es extremadamente poderosa no vale la pena aprenderla si sabes `dplyr`.

- **cudf** (Rk: NA, ND: NA, Pr: 0): `cuDF` es una librer√≠a que es parte de RAPIDS, un set de paquetes en Python desarrollado por NVIDIA que permiten ejecutar todo en GPU. Este es el mirror de Pandas, b√°sicamente la misma sintaxis que pandas pero que en el backend se ejecuta en GPU. <mark>No vale la pena apenderla, ya que es igual a pandas</mark>.

- **cupy** (Rk: NA, ND: NA, Pr: 0): Es el Mirror en este caso de Numpy. Si sabes `numpy` entonces sabes `cupy`, no deber√≠a estar dentro de tus prioridades como Data Scientist. Pero en el caso de querer lanzar tus procesos a la GPU es excelente.

{% include alert alert='Estas librer√≠as no deber√≠an ser la mejor opci√≥n para trabajar con grandes volumentes de datos. Esto porque normalmente la GPU tiene menos RAM, a menos que tengas varias GPU o una RTX3090. La mayor√≠a del tiempo utilizar pandas va a ser m√°s que suficiente.'%}

- **pyspark** (Rk: 127, ND: 23.9M+, Pr: 0): Este es la librer√≠a por excelencia para trabajar con Big Data. `pyspark` es el cliente de Python para el Spark de Scala. Lo bueno de esta librer√≠a es que te da la opci√≥n de usar una API muy similar al Spark en Scala o incluso una que utiliza comandos tipo SQL. Esta va a ser la mejor opci√≥n para cuando tengas que trabajar con Big Data y computaci√≥n distribuida en un Cluster, pero <mark>NO VALE LA PENA APRENDERLO</mark>. Principalmente porque la interfaz de SQL te servir√° la mayor cantidad del tiempo para llevar a cabo ETLs y en caso de procesamiento m√°s rebuscado `koalas` es un mirror de pandas para ejecutar Spark. 

- **findspark** (Rk: 729, ND: 2.4M+, Pr: 0): Tan enredada es la instalaci√≥n de Spark que se cre√≥ una librer√≠a para tener el path de instalaci√≥n y poder levantar un Cluster local. S√≥lo sirve para eso.

- **koalas** (Rk: 1047, ND: 1.4M+, Pr: 0): Si tienes que usar Spark yo creo que es mejor `koalas`, que tiene la sintaxis de pandas que uno ya sabe. No es necesario aprender nada nuevo.

- **sparklyr** ((R), Pr: 2): La √∫nica vez que tuve que trabajar con data en Spark fue en Python y us√© koalas. Pero vale la pena mencionar esta librer√≠a porque b√°sicamente permite ejecutar Spark usando sintaxis de `dplyr`. Si es que llegaras a necesitar Spark, mi recomendaci√≥n ser√≠a hazlo en otro lenguaje (principalmente por los problemas de memory leakage de R) pero si necesitas hacerlo en R, esta es la mejor opci√≥n.

- **NetworkX** (Rk: 147, ND: 20M+, Pr: 2): Es una librer√≠a de manipulaci√≥n de datos, pero en forma de grafos. No la he usado m√°s que para calcular m√©tricas de centralidad (closeness, betweeness, degree, etc). Pero es probable que comience a utilizarla m√°s.

- **Microsoft Excel** ((O), Pr: 1): Excel **nunca** deber√≠a ser una opci√≥n para trabajar con Datos, pero s√≠ o s√≠ tienes que saber usarlo porque lamentablemente los archivos `.xlsx` son todav√≠a un formato extremadamente popular. <mark>NUNCA</mark> deber√≠as utilizar Excel si no es s√≥lo para entregar resultados. Si t√∫ eres de los que a√∫n dice que hay cosas que son m√°s sencillas en Excel que en Pandas o SQL, es que no sabes utilizar bien esas tecnolog√≠as a√∫n.

# Bases de Datos

- **sqlalchemy** (Rk: 49, ND: 49M+, Pr: 1): Esta es por lejos una de las mejores librer√≠as que se han creado en Python. B√°sicamente permite utilizar cualquier Base de Dato SQL con una interfaz com√∫n. Debo decir que si bien esta es una librer√≠a extremadamente poderosa y que vale completamente la pena aprender, la documentaci√≥n est√° pensada para gente bien "comput√≠n" y no es tan amigable. Mi recomendaci√≥n para aprenderla es mediante videos tutoriales. Ahora en Ciencia de Datos la vas a ocupar s√≠ o s√≠ si eres Data Engineer para poder modelar Bases de Datos o hacer consultas. Como Data Scientist normalmente s√≥lo la usar√°s como forma de conexi√≥n con Pandas mediante `create_engine` y `.to_sql()` para extraer datos.

- **sqlmodel** (Rk: 4085, ND: 90K, Pr: 2): Esta es una librer√≠a creada hace muy poco por el gran [Sebasti√°n Ram√≠rez](https://www.linkedin.com/in/tiangolo/?originalSubdomain=de) (Tiangolo). No he utilizado esta librer√≠a pero s√≠ s√© que est√° construida sobre sqlalchemy. `sqlmodel` es a `sqlalchemy` lo que `FastAPI` es a `Flask`. Por lo tanto, es muy posible que en el tiempo esta librer√≠a venga a reemplazar a SQLAlchemy principalmente porque Tiangolo dedica mucho tiempo a la buena documentaci√≥n y casos de usos, cosa que SQLAlchemy no tiene tan bien hecho en mi opini√≥n.

- **DBI** ((R), Pr: 1): DBI viene a ser una interfaz com√∫n para poder consultar datos. Creo que podr√≠a considerarse el s√≠mil de sqlalchemy, pero no s√© si tiene tantas funcionalidades. Al menos esta siempre fue mi opci√≥n para conectarme a DBs en R, pero nunca me toc√≥ modelar una base de datos como s√≠ tuve que hacerlo en Python. DBI tiene conexi√≥n con casi todos los motores de SQL o usando conexi√≥n `odbc`.

- **PyMongo** (Rk: 185, ND: 16.8M+, Pr: 2): Esta es la interfaz para utilizar MongoDB desde Python. MongoDB es probblemente la base de datos no relacional m√°s famosa. S√≥lo vale la pena si es que te toca trabajar con MongoDB pero lo bueno es que su uso es sumamente intuitivo. Utiliza la misma sintaxis que MongoDB pero en vez de usar el formato BSON (que es como un tipo de JSON), lo hace en los diccionarios de Python. Y por cierto, hacer queries en MongoDB es b√°sicamente SQL con otra sintaxis y permitiendo data no estructurada como output, por lo que aprenderla es bastante sencillo.

- **elasticsearch-dsl** (Rk: 732, ND: 2.4M+, Pr: 2): Este no es la librer√≠a m√°s popular para conectarse a ElasticSearch, que es un motor de base de datos basado en documentos que es extremadamente r√°pida. La sintaxis en ElasticSearch es horrible, y yo reconozco que no tengo idea como extraer datos usando ElasticSearch puro. El tema es que elasticsearch-dsl es tan intuitivo que pude generar procesos de ETL en ElasticSearch utilizando esta librer√≠a, ya que su API es como estilo dplyr (aunque es una librer√≠a de Python), lo que le permite ser muy expresiva y f√°cil de crear, leer y entender. Si alguna vez tienes que trabajar con ElasticSearch, usa esta librer√≠a ya que es much√≠simo m√°s sencilla.

- **psycopg2** (Rk: 194 y 99, ND: 31M + 15M, Pr: 0): El Ranking de esta librer√≠a es un poco extra√±o, la raz√≥n es porque si utilizas Windows descargas psycopg2, pero si tienes Mac o Linux descargas psycopg2-binary, por lo que en estricto rigor esta librer√≠a es la suma de ambos. Este es el cliente de Postgresql en Python, un motor de base de datos extremadamente popular y poderoso. Es una interfaz muy parecida a DBI en R. Es un cliente lowlevel y bien r√°pido para poder interactuar con DBs Postgres. Yo la he utilizado como motor tanto para DBs Postgres Puras o para Datawarehouse como Redshift que est√°n basadas en Postgres. Adem√°s se puede conectar con `sqlalchemy`, por lo que dir√≠a que no es necesario aprender mucho su sintaxis porque saber `sqlalchemy` ya hace la pega.

- **pyodbc** (Rk: 161, ND: 19M, Pr: 0): Es una librer√≠a que nos permite hacer conexiones ODBC. Esta librer√≠a la us√© √∫nicamente en Windows para conectarme con Teradata que es un motor de Base de Datos que suele ser utilizado en entornos de alta seguridad como Bancos o Retail (mi recomendaci√≥n: no usen Teradata, funciona bien, es r√°pido y todo pero su documentaci√≥n al no ser c√≥digo abierto es p√©sima, por lo que cosas f√°ciles se pueden hacer pero encontrar c√≥mo hacer algo fuera de la com√∫n es casi imposible. Se los dice alguien que lo us√≥ por 5 a√±os). Normalmente se utiliza una l√≠nea para conectarse y es compatible con `sqlalchemy`, por lo que no es necesario aprender mucho.

- **Neo4J** ((O), Pr: 2): Debo decir que este tipo de bases de Grafo cambi√≥ demasiado mi manera de ver el almacenamiento de datos. Creo, luego de pelear con hartos motores de datos no estructurado que, este es la manera m√°s sencilla de interactuar con datos NoSQL. Entre sus grandes pro est√° el hecho de que su sintaxis es muy f√°cil de aprender (parecida a SQL, pero no igual), es r√°pido, y no requiere joins.

- **rasterio** (Rk: 1454, ND: 749K+, Pr: 0): Esta es una librer√≠a para trabajar con rasters. Rasters son las t√≠picas im√°genes donde cada p√≠xel est√° representado como un valor en una matriz/tensor. En el caso de rasterio, tiene m√°s utility functions para trabajar con im√°genes sat√©litales pero en general se utiliza como complemento a otras librer√≠as. Normalmente se utiliza una que otra funci√≥n.

- **Xarray** (Rk: 1454, ND: 749K+, Pr: 0): No s√© si saben pero antiguamente pandas (que deriva de PAnel DAta ), ten√≠a data panel, que es son varias realizaciones en el tiempo de un DataFrame, o sea un Pandas de 3 dimensiones. Bueno eso hace un tiempo se quit√≥ de pandas y si quer√≠as m√°s de 3 dimensiones necesitabas Numpy. Bueno Xarray permite la data panel, 3 Dimensiones, pero con nombre del nombres de array. Es una extensi√≥n que permite por ejemplo trabajar mejor con Im√°genes Multiespectrales (ya que queda capa tiene un significado: RGB, Infrarrojo Cercano, Infrarrojo Lejano, etc.) y normalmente se combinan para poder crear √≠ndices y falsos colores para destacar ciertos aspectos de la im√°gen. Es una librer√≠a s√∫per espec√≠fica, por lo que s√≥lo ser√° √∫til cuando necesites trabajar con este tipo de datos.

- **Geopandas** (Rk: 733, ND: 2.4M+, Pr: 2): Esta es una extensi√≥n de Pandas, que incluye dos cosas interesantes a mi gusto, el incorportar shapes: Puntos, Pol√≠gonos, etc. Y el hecho de tener joins espaciales. De esta manera puedes combinar datasets si es que comparten mismo espacio, por ejemplo: Tienes puntos (coordenadas) de casas en un csv y tienes pol√≠gonos de regiones en otro csv. Al hacer join espacial, unir√° los registros de casas que est√°n dentro del pol√≠gono regi√≥n igual que un join. El tema es que hay varios tipos de join espaciales: dentro, que colinden, que se intersecten, etc. Excelente librer√≠a, y no muy dificil de aprender.

- **Scikit-Image** (Rk: 325, ND: 8.6M+, Pr: 0): Esta es una librer√≠a de manipulaci√≥n de Im√°genes, muy parecida a OpenCV. Yo la us√© una sola vez para intentar reconstruir una foto que romp√≠ por error. Bien intuitiva tiene muchas built-in functions para manipular im√°genes.

- **Spacy** (Rk: 475, ND: 5.1M+, Pr: 0): Esta es una tremenda librer√≠a para lidiar con texto libre. Tiene modelos pre-entrenados muy buenos en muchos idiomas para llegar y utilizar. Yo la us√© una s√≥la vez porque en Cenco ten√≠amos info sucia de muchas empresas (y quer√≠an sacar promociones en la tarjeta, o algo as√≠): "Hipermercados Lider", "Supermercado Lider", "Falabella" , "Tiendas Falabella". Entonces hicimos un Name Entity Recognition para encontrar nombres de potenciales Comercios donde compraba la gente para poder ofrecer descuentos al sacar la tarjeta Cencosud. Por ejemplo, ellos ten√≠an descuentos en Cine, y nadie y usaba la tarjeta para ir al cine. Pero s√≠ la usaban para Uber, entonces quer√≠an cambiar la estrategia a ofrecer no s√© 10 lucas en Uber o algo as√≠. Aprend√≠ lo que necesitaba en una tarde porque su documentaci√≥n es excelente.

- **DBeaver** ((O), Pr: 2): Esta es un cliente de bases Open Source gratis (aunque tambi√©n tiene una versi√≥n pagada). B√°sicamente es un software que puedes descargar que te permite conectarte a cualquier Base de Datos SQL y muchos otros. Entre los motores disponibles est√°n: Postgresql, MySQL, Hive, ElasticSearch, Redshift, Snowflake y Neo4J entre otros. Adem√°s, en la versi√≥n paga te permite conectarte a MongoDB. Es r√°pido, tiene posibilidad de tener los modelos ER de cada Esquema adem√°s de varios atajos de teclado. Muy buena opci√≥n para conectarse con distintos motores.

# Visualizaciones

Esta es probablemente mi parte m√°s d√©bil principalmente porque es un √°rea que no me gusta. A√∫n as√≠ he usado varias librer√≠as, las cuales voy a mencionar ahora.

- **Seaborn** (Rk: 310, ND: 9M+, Pr: 1): Probablemente no esperaban que esta fuera mi primera opci√≥n. La raz√≥n por la que la menciono en primer lugar es porque es una librer√≠a con funcionalidades restringidas pero que hace la pega muy bien. Tiene la mayor√≠a de gr√°ficos prehechos y permite sin mucho c√≥digo hacer gr√°ficos muy bonitos y muy expresivos. Mi recomendaci√≥n es s√≥lo aprender `sns.catplot()` que permite graficar gr√°ficos de variables categ√≥ricas o combinaci√≥n categ√≥rica num√©rica (conteos, barplots, boxplot y amigos, etc.), `sns.relplot()` que permite generar gr√°ficos para variables s√≥lo n√∫mericas (scatter, lineplots) y `sns.displot()` que grafica b√°sicamente histogramas. Estas 3 funciones tienen interfaz comunes con built-in facet y varias manera de agrupaci√≥n (columnas, filas, colores, estilos, etc.). Una de las cosas que m√°s me entusiasma es que Seaborn comenz√≥ a desarrollar una interfaz muy similar a `ggplot2` de R lo cual la har√≠a extremadamente flexible y f√°cil de usar. Definitivamente vale la pena aprenderla.

- **Matplotlib** (Rk: 110, ND: 26.9M+, Pr: 1): Yo creo que el ranking es un poco mentiroso, principalmente porque matplolib es dependencia de casi todas las librer√≠as de gr√°ficos, por lo que siempre la vas a necesitar. Lamentablemente hay que aprenderla. Y digo lamentable, porque a pesar de ser muy poderosa, considero que la documentaci√≥n es como engorrosa y tiene una sintaxis muy verbosa. Adem√°s `seaborn` est√° construida sobre `matplotlib`, por lo que en casos de querer cambiar elementos del layout en `seaborn` se debe hacer mediante comandos `matplotlib`. Mi recomendaci√≥n es aprenderla con ejemplos y alg√∫n cursito corto en Datacamp, porque es realmente dif√≠cil de aprender (no por su sintaxis sino que porque tiene muchas maneras distintas de hacer lo mismo y que a veces aplican y otras veces no). Igual me he dado cuenta que la termino usando m√°s que Seaborn.

- **ggplot2** ((R), Pr: 1): Para muchos es la mejor librer√≠a de visualizaciones que existe. Y quiz√°s tienen raz√≥n. `ggplot2` es un remake de ggplot (que fue un fracaso) y que est√° basado en el grammar of graphics que es un concepto en el cual las partes del gr√°fico se construye en capas (la figura; ejes; elementos como puntos, l√≠neas, boxplots; c√°lculos como regresiones lineales, promedios, intervalos de confianza; etc.) Adem√°s como que por defecto la paleta de colores y los ejes son bien bonitos. Yo considero que no es tan f√°cil de aprenderla pero es la mejor sintaxis para graficar.
Existen algunas librer√≠as/addins en RStudio como `esquisse` que permiten crear ggplots (te entrega el c√≥digo incluso) con una interfaz tipo Tableau. Muy recomendada si trabajas en R y/o en Python. Adem√°s tiene un enorme ecosistema de librer√≠as complementarias para poder graficar casi cualquier cosa.

- **plotnine** (Rk: 2473, ND: 232K+, Pr: 0): Es la versi√≥n en Python de ggplot2. Creo que es un tremendo esfuerzo y casi todas las funcionalidades est√°n implementadas pero no funciona tan bien como ggplot2 (su ranking lo indica). El problema es que ggplot2 tiene muchos paquetes que lo complementan. Uno de los m√°s poderosos es `patchwork` que es una interfaz para crear gr√°ficos sobre gr√°ficos de manera muy sencilla. Este es precisamente uno de las grandes problem√°ticas de plotnine, si se quieren crear layouts un poco m√°s complejos comenzamos nuevamente a depender de `matplotlib` lo que evita una sintaxis √∫nica. Gracias a ver visto un EDA por [Martin Henze](https://www.linkedin.com/in/martin-henze/) utilizando ggplot comenc√© a usar esta librer√≠a pensando que podr√≠a lograr los mismos resultados, pero lamentablemente ggplot es `muy superior`.

{% include alert info='En mi opini√≥n el 90% del tiempo utilizar gr√°ficos est√°ticos ser√° m√°s que suficiente tanto para compartirlos en un PPT o para hacer EDAs. En caso de crear alguna aplicaci√≥n interactiva entonces gr√°ficos din√°micos e interactivos como los que hacen las siguientes librer√≠as son una buena opci√≥n.'%}

- **plotly** (Rk: 359, ND: 7.5M+, Pr: 0): Plotly es una librer√≠a basada en D3, que a su vez es una librer√≠a de Javascript que se hizo muy popular gracias a su capacidad de desarrollar gr√°ficos interactivos muy bonitos. Hoy tiene APIs en casi todos los lenguajes m√°s populares. Para m√≠ gusto es una librer√≠a que s√≥lo vale la pena aprender si es que est√°s completamente dedicado a las visualizaciones. Si bien es una librer√≠a poderosa es muy verbosa. Afortundamente paquetes como `plotly-express` han aparecido para abstraer la verbosidad y crear versiones de gr√°ficos com√∫nmente usados en pocas l√≠neas.

- **plotly-express** (Rk: 2936, ND: 181K+, Pr: 2): Es la versi√≥n menos verbosa de plotly, si bien es un pel√≠n menos poderosa debido a que es m√°s simple, la mayor parte del tiempo ser√° ma≈õ que suficiente. No entiendo por qu√© no es tan popular a√∫n.

- **altair** (Rk: 360, ND: 7.4M+, Pr: 0): Es otra librer√≠a muy parecida a Seaborn en t√©rminos de sintaxis pero con la interactividad de plotly. Yo la utilic√© s√≥lo una vez creando una app en Streamlit. La raz√≥n: no quer√≠a usar plotly (en ese tiempo no conoc√≠a plotly express) y quedaban los gr√°ficos m√°s bonitos que en matplotlib y seaborn que eran est√°ticos. No vale la pena aprenderla y rara vez la ver√°n por ah√≠.

- **bokeh** (Rk: 674, ND: 1.8M+, Pr: 0): Es otra librer√≠a proveniente de Javascript que puede ser usadas desde R o Python. La verdad es que no la he usado, pero pueden ser alternativas para plotly ya que tambi√©n son interactivas basadas en HTML pero con una sintaxis m√°s simple. Nuevamente las recomiendo s√≥lo en caso de dedicarse el BI o al Data Storytelling donde vale la pena invertir en visualizaciones llamativas.

### Otras herramientas BI

- **Tableau** ((O), Pr: 2): En el caso de trabajar en Business Intelligence donde el foco es m√°s mostrar herramientas interactivas que puedan manipular la data con algunos clicks, aparecen herramientas que no est√°n basadas en c√≥digo. Tableau es una muy buena alternativa. Es r√°pido, f√°cil de crear Dashboard con gr√°ficos que sirven como filtros y pueden interactuar entre ellos. El problema, es que su costo es prohibitivo, su licencia es extremadamente cara y hoy existen otras herramientas m√°s baratas que hacen lo mismo.

- **PowerBI** ((O), Pr: 2): Es el Tableau de Microsoft. Es una buena alternativa con costos de licencias bastante m√°s bajo. Sigue la misma idea de Tableau de usar cajitas tipo Pivot Tables para crear gr√°ficos. Igual de eficiente que Tableau pero mucho m√°s barato.

- **Qliksense** ((O), Pr: 2): No recuerdo quien cre√≥ esto, pero es otra versi√≥n. Funciona exactamente igual que los otros dos. Tienen las mismas funcionalidades. Ninguna ventaja ni desventaja con los otros. 

{% include alert tip='¬øCu√°l elegir? Da lo mismo, es lo que tu empresa est√© dispuesta a pagar.'%}

- **Shiny** ((R), Pr: 1): Podr√≠amos decir que es la versi√≥n en R de estos productos. La diferencia es que es gratis, y es basado completamente en c√≥digo. Permite crear todo tipo de Dashboards interactivos mezclando cualquier otra librer√≠a de R (aunque tambi√©n se podr√≠a agregar Python mediante `reticulate`) tanto para manipular datos como para visualizar. Es extremadamente poderosa y flexible y hay varias empresas que crean sus portales utilizando Shiny. El problema es que no es tan f√°cil de hostear. En mi tiempo s√≥lo RStudio ofrec√≠a servicios para hostear ShinyApps (algunos gratis y otros de pago). Lo bueno es que se comenz√≥ a crear todo un ecosistema en torno a `Shiny`, el cual tiene temas (basados en Bootstrap, material y otros frameworks de HTML, CSS y Javascript). Adem√°s, hay una librer√≠a llamada `golem`, que permite modularizar grandes aplicaciones e incluso se permiten ingresar elementos nativos en HTML, CSS o Javascript. Vale completamente la pena aprenderlo <mark>si es que</mark> te dedicas al BI en R y tienes tiempo de crear todo desde cero. Va a ser m√°s flexible que Tableau, PowerBI o Qliksense, pero hay que crear todo.

- **streamlit** (Rk: 1361, ND: 853K+, Pr: 1): Similar a Shiny pero en Python. En mi opini√≥n es mucho m√°s sencillo de utilizar, pero mucho m√°s simplista. Tiene lo justo y necesario para hacer funcionar una excelente aplicaci√≥n demo. Lo bueno es que Streamlit fue comprado por HuggingFace por lo que se ha estado llevando sus funcionalidades para que sea el front-end de modelos de Machine Learning. Una ventaja de streamlit es que es f√°cilmente hosteable en cualquier servidor con Python (que son casi todos), en Heroku, en un servicio provisto por la misma gente de Streamlit o en Huggingface Spaces, siendo estos √∫ltimos totalmente gratis. En el caso de querer hacer una demo, se puede crear algo de gran calidad y complejidad en no m√°s de una hora. Su sintaxis es muy sencilla y se puede aprender en unas horas.

- **Dash** (Rk: 1380, ND: 830K+, Pr: 0): Este es casi id√©ntico a Shiny (pero tambi√©n en Python). Yo lo us√© s√≥lo una vez en un proyecto, y no nos gust√≥ porque era muy complicado de setear. B√°sicamente crear el CSS que dejara los distintos divs en orden fue un martirio por lo que siempre nos quedaba la aplicaci√≥n descuadrada. No vale la pena, ya que streamlit simplific√≥ esto infinitamente.

- **Gradio** (Rk: 3187, ND: 148K+, Pr: 2): Es una interfaz a√∫n m√°s simple que Streamlit, pero con muchas menos funcionalidades. Esta librer√≠a s√≠ que se cre√≥ con el s√≥lo prop√≥sito de ser un IO para modelos de Machine Learning. A diferencia de Streamlit que puedes crear Dashboards, sitios webs, agregar gadgets, Gradio s√≥lo le interesa crear gadgets de input/output para un modelo a modo de demo. Yo lo prob√© r√°pidamente y lo encontr√© muy f√°cil. Decid√≠ aprenderlo luego de ver una demo de un Pipeline de Transformers por Omar Sanseviero, donde construy√≥ un front-end con modelos de Generaci√≥n de Texto y Machine Translation en 10 mins. Puedes ver su presentaci√≥n [ac√°](https://www.youtube.com/watch?v=Mg7YeWBUKbM). Vale mencionar que tambi√©n fue adquirido por HuggingFace por lo que puedes hostearlo facilmente en servidores Python, Heroku o Spaces. La gran ventaja de Gradio es que permite hostear de manera gratuita desde cualquier computador por dos d√≠as. Una vez se acabe puedes volver a levantar el servicio, el cual permite el frontend y una API en FastAPI creada autom√°ticamente.

- **Django** (Rk: 357, ND: 7.5M+, Pr: 0): No lo he usado. Pero es por lejos la librer√≠a m√°s poderosa de desarrollo Web. Ac√° ya no hablamos s√≥lo de una interfaz de Dashboards sino que un software completo. Es tanto as√≠ que existen Ingenieros de Software especializados s√≥lamente en el Ecosistema Django. Por nada del mundo como Data Scientist debieras tener que llegar a usar una librer√≠a tan poderosa como esta. Pero si te interesa crear una aplicaci√≥n a nivel profesional con procesos de datos o Modelos de Machine Learning por abajo, esta podr√≠a ser una opci√≥n. Algunas aplicaciones creadas en Django son Instagram, Spotify, Youtube, Dropbox, entre otras.

- **Flask** (Rk: 88, ND: 35.9M+, Pr: 0): Tampoco lo he usado, pero tengo entendido que es un Django peque√±ito, que adem√°s tiene otras funcionalidades como crear APIs. Es a√∫n extremadamente popular en entornos de desarrollo web, pero en mi opini√≥n est√° poco a poco cayendo en desuso, principalmente debido a que FastAPI est√° ganando mucho protagonismo en cu√°nto a APIs se refiere y es una opci√≥n mucho m√°s sencilla de aprender.

# Machine Learning

Esta es por lejos mi secci√≥n favorita, por lo que puede que me extienda un poco m√°s de que el resto.

- **Scikit-Learn** (Rk: 94, ND: 32.6M+, Pr: 1): Es la librer√≠a por excelencia para crear modelos de Machine Learning. La sintaxis de su API est√° tan bien dise√±ada que una manera de reconocer que otras librer√≠as de Machine Learning son confiables es si es que siguen su API. B√°sicamente `scikit-learn` es super reconocida por sus modelos como Clase y su estandar `fit-transform-predict`, adem√°s de casi 15 a√±os de vida. Si quieres hacer modelos de Machine Learning s√≠ o s√≠ tienes que partir por ac√° por varias razones: (1) Su documentaci√≥n es excelente, incluso puedes aprender la teor√≠a detras de cada modelo leyendo su [User Guide](https://scikit-learn.org/stable/user_guide.html) (toda persona que se dedique al ML deber√≠a leer la documentaci√≥n completa de Sklearn una vez al a√±o ü§™). Adem√°s contiene s√≥lo modelos ML que est√°n en el estado del arte. De hecho para que un modelo se implemente en Scikit Learn tiene que cumplir [requisitos](https://scikit-learn.org/stable/faq.html) muy estrictos. Andreas Mueller, mantenedor de Scikit-Learn tiene un curso disponible de manera gratuita [ac√°](https://www.youtube.com/watch?v=d79mzijMAw0&list=PL_pVmAaAnxIRnSw6wiCpSvshFyCREZmlM). Este es por lejos una de las mejores inversiones que uno har√° como Data Scientist, ya que aprendiendo a utilizar esta librer√≠a podr√°s utilizar millones de otras basadas en la misma API. [Ac√°]({{ site.baseurl }}/titanic/)un ejemplo de modelamiento en Scikit-Learn.

- **tidymodels** (R, Pr: 2): Yo sol√≠a ser un fan de esta compilaci√≥n de librer√≠as. Creo que Max Kuhn es un tremendo desarrollador y lo respeto profundamente, pero creo que parsnip trat√≥ de llevar el modelamiento en R a un estado incluso m√°s flexible que `scikit-learn` pero no les funcion√≥. Lamentablemente el Machine Learning en R est√° disgregado en muchas librer√≠as todas con APIs diferentes, por lo que este esfuerzo de unificar todo es incre√≠ble. Lamentablemente el memory leakage que sufre R y el tremendo trabajo de los mantenedores de `scikit-learn` hacen que un esfuerzo como este nunca logre la popularidad que tiene Python en este rubro. Tidymodels est√° basado en 3 paquetes principalmente: `recipes`, para el preprocesamiento, que a mi gusto tiene una API muy similar a los Pipelines de Scikit, `parsnip`, que es la unificaci√≥n de todos los modelos de ML implementados en R y `yardstick` que contiene todas las m√©tricas de evaluaci√≥n. Si te dedicas a hacer modelos peque√±itos de prueba, sin mucho intensidad de c√≥mputo es una opci√≥n, en cualquier otro caso vale m√°s cambiarse a `scikit-learn`.

- **caret** (R, Pr: 2): Este es el predecesor de `tidymodels`. A pesar de ser una librer√≠a que se le quit√≥ mantenimiento hace un tiempo sigue disfruntando de mucha popularidad ya que tiene m√°s de 200 modelos implementados. El prop√≥sito de Caret es el mismo de tidymodels s√≥lo que su API no era compatible con el tidyverse por lo que decidieron seguir el esfuerzo de tidymodels. Este proyecto contaba con todo integrado, preprocesamiento, entrenamiento, postprocesamiento, esquemas de validaci√≥n, m√©tricas de evaluaci√≥n, incluso ensambles. Por alguna raz√≥n lamentablemente decidieron cortarlo.

- **pycaret** (Rk: 1940, ND: 432K+, Pr: 2): Este es un proyecto en Python que nace de la base de Caret y que se ha hecho extremadamente popular. En mi opini√≥n s√≥lo vale la pena aprenderlo si es que no te gusta codear. Las ventajas es que permite hacer mucho en pocas l√≠neas de c√≥digo y es compatible con muchas librer√≠as externas como XGBoost, LightGBM, etc. Adem√°s cuando uno no es experto en tareas menos habituales como Anomaly Detection o Series de Tiempo permite seguir el mismo esquema de c√≥digo. Lo que me gusta del creador de esta librer√≠a es que √©l deja muy en claro que su objetivo que es que los Citizen Data Scientist pueden tener modelos de alta calidad a la mano. Creo que est√°n haciendo un tremendo trabajo y he visto muchos Notebooks en Kaggle que lo usan y obtienen muy buenos resultados.

- **Feature Engine** (Rk: 3096, ND: 99K+, Pr: 1): Para m√≠ esta es una librer√≠a de primer√≠sima calidad. Tiene muy buen mantenimiento y tiene much√≠simos mejores preprocesamiento que Scikit-Learn y adem√°s implementados en DataFrames. Contiene muchos de los excelentes encoders que ten√≠a Category Encoders y adem√°s un Wrapper que permite convertir los preprocesadores de Scikit para que devuelvan pandas DataFrames en vez de Numpy Arrays. Espero que gane m√°s popularidad, yo al menos la uso mucho.

- **category-encoders** (Rk: 814, ND: 2M+, Pr: 0): Esta sol√≠a ser mi librer√≠a de encoders por defecto, pero dej√≥ de mantenerse porque los mantenedores se cansaron. En su momento fue muy buena y todav√≠a tiene mucha popularidad. Particularmente encontr√© un par de issues que report√© pero se demoraron casi un a√±o en corregirlo. Una pena.

- **statsmodels** (Rk: 294, ND: 9.6M+, Pr: 2): Si trabajas en Estad√≠stica en Python esta es la librer√≠a. Yo no soy muy fan de los modelos estad√≠sticos, pero igualmente creo que es una librer√≠a interesante, porque tambi√©n contiene muchas herramientas para trabajar con series de tiempo. En caso de necesitar mucho poder estad√≠stico, creo que R es mucho m√°s potente ac√°.

- **XGBoost** (Rk: 320, ND: 8.8M+, Pr: 1): Uno de los problemas que Scikit-Learn sol√≠a tener es que no ten√≠a una buena implementaci√≥n de algoritmos de Gradient Boosting (hoy tiene una buena implementaci√≥n de HistGradientBoosting similar a LightGBM) y XGBoost quiz√°s es la implementaci√≥n m√°s famosa que hay. Desde el 2014 viene dominando por lejos el modelamiento en data tabular y definitivamente es un algoritmo que hay que dominar. Si bien es cierto su performance es superior, llegar a esa performance es dif√≠cil de lograr, ya que hay que hacer un buen afinamiento de Hiperp√°r√°metros. Definitivamente un algoritmo que hay que aprender.

- **LightGBM** (Rk: 393, ND: 6.5M+, Pr: 1): Me llama la atenci√≥n que tenga menos descargas. Porque LightGBM para m√≠ supera a XGBoost, por poco pero lo supera. En general para todas las competencias en la que he estado y modelos en producci√≥n que he dejado siempre obtengo mejor performance con LightGBM. Esta es una implementaci√≥n liberada por Microsoft en 2016, y en mi opini√≥n es bastante m√°s r√°pido que XGBoost y menos complicado de afinar Hiperpar√°metros. El problema es la instalaci√≥n, las docs de instalaci√≥n son malitas, y la versi√≥n con GPU es bien enredada de instalar. Definitivamente, hay que tenerlo en el arsenal.

- **CatBoost** (Rk: 747, ND: 2.3M+, Pr: 1): Otro Gradient Boosting que est√° muy de moda. En mi opini√≥n es el algoritmo m√°s f√°cil de afinar. Casi no hay que mover los Hiperpar√°metros para obtener muy buenos resultados. Es f√°cil de instalar, pero en velocidad es similar a XGBoost. Creo que el √∫nico problema que le he visto es que cuando guardas el modelo es muy pesado. Por ejemplo, una vez entren√© los 3 Boosting (t√≠pico en Kaggle) y no s√©, XGBoost y LightGBM pesaban del orden de megas mientras que CatBoost pesaba 11 GB, no s√© si habr√© hecho algo mal, pero encontr√© que era muy pesado. El otro contra (no tan contra), es que siempre queda fuera de los frameworks, y la API es un poquito diferente a Scikit. (XGBoost y LightGBM tienen versiones con API de Scikit). Definitivamente hay que aprenderlo.

{% include alert info='Lo bueno de los 3 grandes Boosting es que todos tienen Early Stopping y permiten el uso de un set de Validaci√≥n mietras se entrena, igual que los algoritmos de Deep Learning.'%}

- **DeepChecks** (Rk: NA, ND: NA, Pr: 2): Yo no lo he usado a√∫n en mis pegas, pero he hecho pruebas y revisado a fondo la documentaci√≥n y creo que es una excelente librer√≠a para estudios previos de la data (chequear potenciales drifts y el potencial poder de generalizaci√≥n de un modelo) y para monitoreo. Permite realizar distintas validaciones para entre tu set de entrenamiento y tu data real, o test set para chequear que el modelo funciones bien en el tiempo.

- **Mapie** (Rk: NA, ND: NA, Pr: 2): Excelente librer√≠a para aplicar Conformal Prediction, es decir, se pueden generar predicciones con intervalos de confianza en Regresi√≥n y Clasificaci√≥n probabil√≠stica para modelos de clasificaci√≥n. Lo bueno es que es solo un wrapper y es Scikit-Learn compatible. Tuve la oportunidad de estudiar la documentaci√≥n a fondo y es realmente la manera de generar modelos robustos en especial cuando hay mucha incertidumbre.

- **mlxtend** (Rk: 1024, ND: 1.4M+, Pr: 2): Tremenda librer√≠a creada por Sebastian Raschka, profesor de Wisconsin Madison y parte de Lightning AI. Es un complemento a Scikit-Learn y tiene varios elementos que permiten extender las capacidad de Scikit. En particular rescato las herramientas para ensambles tipo Stacking. Muy necesaria si quieres competir, y si quieres un modelo ensamblado.

- **pyGAM** (Rk: 2237, ND: 325K+, Pr: 0): Es una librer√≠a que hace modelos GAM (Generalized Additive Models). Estos modelos son famosos por ser la mejor mezcla entre buena predicci√≥n y buena explicabilidad. Quiz√°s el modelo GAM m√°s conocido es `prophet` de Meta. En general esta librer√≠a no me gust√≥, y si es que realmente quieres meterte en este tipo de modelos mejor utilizar `mgcv` en R que es a√±os luz m√°s maduro. No creo que valga la pena aprenderlo.

- **CuML** (Rk: NA, ND: NA, Pr: 0): Esta es una librer√≠a que est√° a√∫n en desarrollo por parte de NVIDIA, pero es la parte de ML de cuDF y cuPY. Es un mirror de Scikit-Learn, pero que corre en GPU. En especial algoritmos como Random Forest y SVM pueden verse muy beneficiados. No creo que valga la pena aprenderlo, porque es lo mismo que Scikit-Learn.

- **Imbalanced-Learn** (Rk: 650, ND: 3M+, Pr: 0): Es la librer√≠a por excelencia para desbalance de clases. Lo bueno es que incluye t√©cnicas de undersampling, oversampling, SMOTE y algoritmos propios que funcionan con desbalance como RUSBoost y BalancedRandomForest. Debo confesar que casi nunca obtengo mejores modelos utilizando estas estrategias, y no me ha tocado usarlo a√∫n, pero normalmente utilizando el par√°metro sample_weigths de cualquier modelo de Scikit-learn podr√≠a funcionar mejor.

- **Shap** (Rk: 530, ND: 4.1M+, Pr: 1): Es hoy quiz√°s la librer√≠a m√°s poderosa para dar explicabilidad. Existen varios spin-offs enfocados en problemas espec√≠ficos pero creo que es algo que todos deber√≠amos dominar porque al negocio siempre le interesa entender por qu√© un modelo predice lo que predice.

- **ELI5** (Rk: 1022, ND: 1.4M+, Pr: 2): Otra opci√≥n para la explicabilidad de modelos. No lo he usado pero sol√≠a ser la librer√≠a por defecto antes que apareciera el boom de los shap values.

- **Implicit** (Rk: 2761, ND: 207K+, Pr: 2): Librer√≠a de Factorization Machines para modelos de recomendaci√≥n Implicita. Esta la us√© una vez para una prueba de Concepto en Cencosud. F√°cil de usar, buenos tutoriales, me gust√≥. No tengo m√°s que decir, porque fue "el uso" que le d√≠.

- **Surprise** (Scikit-Surprise) (Rk: 2860, ND: 195K+, Pr: 2): No alcanc√© a usarla, porque en la misma Prueba de Concepto anterior me d√≠ cuenta que ten√≠amos un recomendador impl√≠cito y Surprise es para modelos expl√≠citos. Para tenerlo en cuenta. 

- **LightFM** (Rk: 1920, ND: 441K+, Pr: 2): Esta fue la librer√≠a que termin√© utilizando, debido a su r√°pidez. Recuerdo que en ese momento no pude sacarle todo el potencial porque funciona mejor en entornos Unix y obvio, nos obligaban a usar Windows. Tambi√©n para tenerla en cuenta.

- **H2O** (Rk: 1954, ND: 428K+, Pr: 2, (R)): Es una librer√≠a que est√° tanto en Python como en R que por detr√°s corre una JVM. Es la librer√≠a en CPU m√°s r√°pida que he visto. Yo s√≥lo la v√≠ en curso en R con Erin Ledell. Es buena para hacer cosas r√°pido. Adem√°s posee AutoML y Stacking, para los que les guste algo r√°pido con poquito c√≥digo.

- **Prophet** (Rk: 1367, ND: 848K+, Pr: 2): Hace poco hubo un esc√°ndolo porque la empresa Zillow hizo un uso indiscriminado de Prophet entrenando modelos sin entender y eso le signific√≥ un impacto muy negativo (pueden leer m√°s al respeco [ac√°](https://towardsdatascience.com/in-defense-of-zillows-besieged-data-scientists-e4c4f1cece3c)). Pero si se le da un uso correcto, creo que es una tremenda librer√≠a. Es f√°cil de usar y tienen muchas ventajas. Konrad Banachewicz est√° haciendo un curso de series de tiempo en el canal de [Abishek Thakur](https://www.youtube.com/channel/UCBPRJjIWfyNG4X-CRbnv78A) y habl√≥ sobre este modelo, y la verdad lo encontr√© muy interesante. √öselo con precauci√≥n y bajo su propio riesgo.

- **Neuralprophet** (Rk: 4635, ND: 68K+, Pr: 2): Spin-off de Prophet pero utilizando algoritmos de Redes Neuronales. Mismo cuidado que con prophet.

- **Sktime** (Rk: 2739, ND: 211K+, Pr: 2): Es una extensi√≥n de Scikit-Learn para modelos aplicados a Series de Tiempo. Tiene algoritmos propios para clasificaci√≥n (de series de tiempos, o sea clasificar un secuencia), regresi√≥n, forecast (no es lo mismo que regresi√≥n), anomaly detection y tiene varios CV propios de series de tiempo. Yo no la us√© propiamente tal, pero aprend√≠ mucho leyendo su documentaci√≥n, en especial para entender la diferencia entre forecast y regresi√≥n. Adem√°s posee un transformer que permite convertir modelos de forecasting en Regresi√≥n. Muy buena librer√≠a si trabajas con series de tiempo.

- **Skforecast** (Rk: NA, ND: NA, Pr: 2): Muy similar a sktime pero creada por Joaquin Amat, un data scientist espa√±ol. Creo que siempre el trabajo en espa√±ol tiene que ser destacado.

- **TSFresh** (Rk: 1888, ND: 456K+, Pr: 2): Yo utilic√© esta librer√≠a como herramienta de feature extraction para series de tiempo. Posee una funci√≥n `extract_features` que permite crear much√≠simas features para series de tiempo. Muy buena librer√≠a.

- **Lifetimes** (Rk: 1473, ND: 731K+, Pr: 2): Librer√≠a especializada en Survival Models. Los modelos de sobrevivencia son modelos que buscan estimar el tiempo a un evento. Lo utilic√© en la competencia de Mercado Libre, pero no me di√≥ muy bueno as√≠ que segu√≠ por otro lado. Es bueno tenerlo como alternativa para tipos de modelaci√≥n no tan comunes.

- **Boruta-Shap** (Rk: NA, ND: NA, Pr: 0): Es una librer√≠a muy peque√±ita que permite utilizar el algoritmo Boruta m√°s Shap Values para Feature Selection. Por defecto utiliza un Random Forest para escoger las variables m√°s importantes, pero yo lo utilic√© con XGBoost y LightGBM en GPU y funciona bastante bien.

- **LOFO** (Rk: NA, ND: NA, Pr: 0): Es otra librer√≠a de Feature Selection. En este caso la ventaja que ofrece sobre Boruta Shap es que se realiza una selecci√≥n utilizando un modelo espec√≠fico pero en un esquema de Cross Validation. Esta la utilic√© en una competencia que ten√≠a muchas variables an√≥nimas, y funcion√≥ bastante bien.

- **Optuna** (Rk: 613, ND: 3.2M+, Pr: 1): Es probablemente la mejor librer√≠a de optimizaci√≥n que hay hoy. Originalmente permite resoluci√≥n de algoritmos de Optimizaci√≥n (min, max, minmax). Pero su gran fortaleza es que permite la implementaci√≥n de algoritmos Bayesianos de b√∫squeda compatibles con modelos de Machine Learning y Deep Learning (agregando Pruning, que permite terminar la b√∫squeda en espacios poco prometedores). Es obligaci√≥n aprender a utilizarla, 100-200 iteraciones de Optuna es equivalente a una b√∫squeda gigantesca en GridSearch o RandomSearch.

- **Scikit-Optimize** (Rk: 613, ND: 3.2M+, Pr: 0): No lo he usado, pero es competidor directo de Optuna. No s√© mucho m√°s pero creo que era necesario mencionarlo.

- **Hyperopt** (Rk: 809, ND: 3.2M+, Pr: 0): Idem al anterior.

- **Scikit-plot** (Rk: 1756, ND: 520K+, Pr: 0): Es en estricto rigor una librer√≠a de visualizaciones, pero s√≥lo tiene visualizaciones asociadas a Machine Learning. Es muy sencillo de usar y con un comando permite graficar matrices de confusi√≥n, curvas ROC, curvas Precision-Recall, Curvas de Aprendizaje, Silhouette, Curvas de Calibraci√≥n, etc. Yo comenc√© utilizandola porque antes los Plot de Scikit-Learn quedaban muy feos. Esto est√° muy mejorado actualmente y recomendar√≠a utilizar este tipo de librer√≠as s√≥lo para curvas muy espec√≠ficas.

- **Yellowbrick** (Rk: 1659, ND: 578K+, Pr: 0): Para m√≠, hace y tiene exactamente lo mismo que Scikit-Plot. No recuerdo por qu√© comenc√© a usar Scikit-Plot por sobre esta.

# Deep Learning

- **Pytorch** (Rk: NA, ND: NA, Pr: 1): Es el framework de Deep Learning de Meta. Quiz√°s esto es sorpresivo. Pero la raz√≥n por la que Pytorch no est√° en el Ranking es porque se recomienda su instalaci√≥n via Conda. Para m√≠ (y esto es muy sesgado), es la mejor librer√≠a de Deep Learning. Y la raz√≥n es porque te permite entender el funcionamiento de una red neuronal de mejor manera que con otros frameworks. El contra de Pytorch es que necesitas mucho c√≥digo para entrenar principalmente, pero permite entender muy bien cuando hay que setear los gradientes a cero, en qu√© parte se eval√∫a la loss function, cuando haces backpropagation y actualizas los pesos. Adem√°s como te fuerza a utilizar clases permite mejorar tu programaci√≥n orientada a objetos y su gran fuerte es la documentaci√≥n, muy buena en t√©rminos de uso, pero tambi√©n de teor√≠a. Otro aspecto espectacular de Pytorch es que permite el desarrollo de spin-offs que mencionar√© m√°s tarde. ¬øEs Pytorch perfecto? la verdad es que no. Como dije antes, es muy verboso y entrenar en Aceleradores es engorroso. Hay que estar consciente en todo momento de si tu tensor vive en CPU o GPU, hay que moverlo manualmente. No, es un cacho. A√∫n as√≠, creo que es necesario hacer al menos un par de modelos en Pytorch Nativo, ac√° un [ejemplo]({{ site.baseurl }}/pytorch-native/). Si quieres iniciarte en Pytorch, lo mejor es partir por el 60 minutes [Blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html).

- **Pytorch-Lightning** (Rk: 692, ND: 2.7M+, Pr: 1): Pero afortunadamente existe Pytorch Lightning que soluciona todos los inconvenientes de Pytorch Nativo. Permite organizar mucho del excesivo c√≥digo de Pytorch y tiene una API que permite escalar a GPUs, TPUs, IPUs y HPUs sin casi ning√∫n cambio. Adem√°s permite la portabilidad del c√≥digo, haciendo que un mismo m√≥dulo sea muy f√°cil de reutilizar casi sin latencia. Creo que definitivamente Lightning es la raz√≥n por la que me enamor√© de Pytorch. Dentro de los mejores lugares para entender bien el funcionamiento de Pytorch Lightning est√° este el [level up](https://pytorch-lightning.readthedocs.io/en/latest/expertise_levels.html) y una serie de [tutoriales](https://pytorch-lightning.readthedocs.io/en/latest/notebooks/course_UvA-DL/01-introduction-to-pytorch.html) de la Universidad de Amsterdam y [otros m√°s](https://pytorch-lightning.readthedocs.io/en/latest/tutorials.html).

- **Tensorflow** (Rk: 181, ND: 17.2M+, Pr: 0): Es el primer framework de Deep Learning liberado por Google en el 2015. Esto no es sesgo. No conozco a nadie que haga sus modelos utilizando Tensorflow. Inicialmente el hecho de tener ejecuci√≥n est√°tica, hac√≠a que fuera muy dif√≠cil programar en √©l, adem√°s de que se sent√≠a como programar en otro lenguaje distinto de Python. La versi√≥n dos permite ejecuci√≥n din√°mica, para debuggear en tiempo real, pero siento que ya qued√≥ muy por detr√°s de Pytorch. Ahora, ¬øpor qu√© tiene tantas descargas? Porque se necesita el backend para programar en Keras que s√≠ es la manera en que todo el mundo usa Tensorflow.

- **Keras** (Rk: 292, ND: 17.2M+, Pr: 1): Para los que no les gusta complicarse con Pytorch pero igualmente quieren utilizar Redes Neuronales, Keras es la soluci√≥n. Es por lejos la API m√°s famosa, y m√°s sencilla de aprender. Es un poco m√°s lento que Tensorflow puro pero se encuentran muchos tutoriales de c√≥mo implementar modelos sencillos. Yo comenc√© a aprender redes neuronales en Keras pero me fui desalentando porque no me gust√≥ la documentaci√≥n, la encontr√© muy engorrosa, y adem√°s porque empec√© a confundirme. Hay como 3 formas distintas de implementar modelos, hoy algunas muy parecidos a Pytorch utilizando clases. No hay mejor o peor entre Keras o Pytorch, pero Pytorch est√° ganando mucha popularidad, mientras Tensorflow la pierde. Ac√° tengo un peque√±o [ejemplo]({{ site.baseurl }}/keras/) de c√≥mo utilizar Keras.

- **Jax** (Rk: 1546, ND: 662K+, Pr: 0): No la he usado, y no est√° en mi agenda aprenderlo, pero puede que gane mucha popularidad. Corresponde a otro framework desarrollado por Google y fue adoptado por DeepMind, por lo que quiz√°s debido al tremendo desarrollo que ellos hacen comience a hacerse famoso.

- **Pytorch-Geometric** (Rk: 4190, ND: 86K+, Pr: 2): Es una extensi√≥n de Pytorch para trabajar con Redes de Grafos (Geometric Deep Learning). Yo lo encontr√© dif√≠cil de aprender, pero no por el framework sino que las redes de Grafos son m√°s enredadas. Para tenerlo en cuenta. Tiene muy buena [documentaci√≥n](https://pytorch-geometric.readthedocs.io/en/latest/), por lo que pueden comenzar el aprendizaje por ah√≠.

- **Pytorch-Forecasting** (Rk: 4346, ND: 78K+, Pr: 2): Es un spin-off de Pytorch para Forecast utilizando Redes Neuronales. Lo interesantees que tiene varios algoritmos famosos implementados como N-Beats, DeepAR y Temporal Fusion Transformer. Adem√°s tiene Dataloaders que est√°n dise√±ados para tipos de predicci√≥n propios de series de tiempo. Yo no la utilic√© pero s√≠ estudi√© bastante sus docs para ver si pod√≠a utilizarla.

- **Pycox** (Rk: NA, ND: NA, Pr: 2): Spin-Off de Pytorch para el uso de Modelos Survival en Deep Learning. Tampoco alcanc√© a utilizarla, pero tambi√©n para tenerla en el arsenal si usamos este tipo de modelos.

- **torchvision** (Rk: 518, ND: 4.3M+, Pr: 0): Es una librer√≠a auxiliar a Pytorch para Visi√≥n que provee de datasets, Data Augmentation y algunos modelos preentrenados. Particularmente creo que hoy no vale la pena. Existen otras librer√≠as m√°s potentes que esta y se demora mucho en incluir cosas nuevas. No vale la pena a mi gusto.

- **Albumentations** (Rk: 2391, ND: 283K+, Pr: 1): Es por lejos la mejor librer√≠a de Data Augmentation en Im√°genes. No s√≥lo es r√°pida sino que permite augmentation de Im√°genes y Masks. No es muy dificil de aprender y es compatible tanto con Pytorch como con Tensorflow/Keras. Muy buena librer√≠a.

- **Kornia** (Rk: 1918, ND: 441K+, Pr: 2): Si bien Albumentations funciona sumamente r√°pido, funciona en CPU. Kornia es un Albumentation en GPU, lo cual permitir√≠a, es especial en multiple GPU, tener una que se dedique al preprocesamiento. No la he usado, pero est√° ganando mucha popularidad.

- **OpenCV** (Rk: 466, ND: 5.2M+, Pr: 0): Si bien es una librer√≠a agn√≥stica de Visi√≥n, posee algunos modelitos internos que funcionan s√∫per bien de manera r√°pida para tareas de detecci√≥n de objetos, segmentaci√≥n, etc. con los que f√°cil y r√°pidamente puedes impresionar. Yo la uso principalmente junto con Albumentations y es espectacular. 

- **Timm** (Rk: 837, ND: 1.9M+, Pr: 0): Si te dedicas a la Visi√≥n Computacional tienes que conocer esta librer√≠a, debe tener un par de comandos y su principal funci√≥n es descargar modelos pre-entrenados. Principalmente sus modelos son compatibles con Pytorch pero creo que ya se pueden utilizar en Tensorflow/Keras tambi√©n. Lo mejor de esta librer√≠a es que en quiz√°s un par de semanas de salido una arquitectura estado del arte (SOTA Model) ya va a estar disponible ac√°. Puedes encontrar desde MobileNet o ResNets, hasta ViT, ConvNext, EfficientNets, y un largo etc. Otra buena noticia es que Timm se asoci√≥ con HuggingFace por lo que muy probablemente ser√° a√∫n m√°s r√°pido ver avances en arquitecturas ultra modernas.

- **Transformers** (Rk: 403, ND: 6.3M+, Pr: 1): Es quiz√°s por lejos la librer√≠a que m√°s r√°pido ha crecido en el √∫ltimo tiempo y es mantenida por HuggingFace. Inicialmente estaba enfocada en proveer modelos preentrenados y tokenizers de modelos de NLP. Hoy tiene modelos, de Visi√≥n, Audio, y dicen que vienen de Grafos. Yo no la he usado mucho, porque no estoy muy metido en el √°rea de NLP, pero hay que conocerla. Con un par de l√≠neas puedes hacer un tremendo transformer estado del arte. Aprovecho de destacar el trabajo que hace la Universidad de Chile que tiene un Bert preentrenado en espa√±ol disponible para uso libre, el [Beto](https://github.com/dccuchile/beto).

- **torchinfo** (torch-summary) (Rk: 4030, ND: 93K+, Pr: 0): Es una librer√≠a peque√±ita que con una funci√≥n `summary` permite ver un detalle de la red neuronal: capas, par√°metros, tama√±o, peso, id√©ntico a como lo permite Keras. Es una funci√≥n literalmente.

- **torchmetrics** (Rk: 705, ND: 2.6M+, Pr: 0): Es una excelente librer√≠a con m√©tricas de evaluaci√≥n para Deep Learning. ¬øPor qu√© no usar las t√≠picas de Scikit-Learn? Primero, esta tiene muchas m√°s m√©tricas espec√≠ficas para NLP, Object Detection y un largo etc. Adem√°s estas m√©tricas se pueden ejecutar en GPU o Clusters, dependiendo de la paralelizaci√≥n o distribuci√≥n, lo cu√°l las hacen mucho m√°s r√°pidas.

# Miscel√°neo

- **VSCode** ((O), Pr: 1): Para m√≠, el mejor IDE para programar hoy en d√≠a, aunque es agn√≥stico, puedes programar casi lo que quieras ac√°. Principalmente porque es liviano, evita muchas complejidades para trabajar en ambientes aislados (conda o venv). Lo bueno es que es totalmente personalizable, tiene extensiones para todo. De hecho este blog es escrito en Markdown utilizando distintas extensiones que me facilitan la escritura. Otro aspecto para los m√°s computines es que puede utilizar keycodes populares como Vim, Emacs o Sublime para usar s√≥lo el teclado. En particular VSCode tiene muy buen soporte para Python permitiendo el uso de Notebooks, Scripts o una Consola Interactiva. Adem√°s es posible utilizar terminal (aunque incre√≠blemente no funciona tan bien en Windows, por eso Linux for the "Win"), tiene soporte de GIT, debugger y un largo etc. Vale la pena, toma un tiempo aprenderlo pero no se van a arrepentir.

- **RStudio** ((O), (R) Pr: 1): Hay que decir que este es por lejos el IDE m√°s optimizado para R. Permite instalar librer√≠as directo de CRAN, tiene visualizador de Datasets, un sector de Plots, Documentaci√≥n incluida, Explorador de Archivos y Terminal. Adem√°s tiene integraci√≥n con GIT y librer√≠as como blogdown (para hacer tu sitio web en R, mi antiguo sitio fue hecho ah√≠), bookdown (mi tesis de pregrado la escrib√≠ ah√≠), etc.

- **Spyder** ((O), (R) Pr: 2): Este es como una r√©plica de Rstudio pero para Python. Inicialmente cuando me mov√≠ de Python comenc√© a utilizarlo, y es bien completo, permite Scripts, tiene extensiones para Notebooks, tiene explorador de variables. A m√≠ particularmente me molestaban dos cosas, que se demora en iniciar, y que nunca pude encontrar una paleta de colores para el highlighting. Es una buena opci√≥n para programar en un ambiente que est√° dise√±ado para ciencia de datos.

- **Pycharm** ((O), (R) Pr: 0): Tambi√©n lo utilic√© con licencia completa y debo decir que si bien es un IDE enfocado exclusivamente en Python me carg√≥. Siento que no est√° pensado para Ciencia de Datos. Es muy pesado, se demora mucho en partir, su configuraci√≥n inicial es terrible y al menos a m√≠ siempre se me qued√≥ pegado. Jetbrains (los creadores de esto) creo que se dieron cuenta que no era lo mejor y crearon un IDE enfocado en Ciecia de datos ([DataSpell](https://www.jetbrains.com/es-es/dataspell/)), pero la verdad no lo he probado. Es tan completo que llega ser abrumante, y nunca pude aprender todo lo que pod√≠a eventualmente servirme. Para m√≠, no vale mucho la pena.

- **Atom** ((O), (R) Pr: 0): Para m√≠ era lejos el mejor IDE para programar, creado por Github. Tiene extensiones, muy buenos atajos de teclado, era r√°pido, liviano y ten√≠a una extensi√≥n llamada Hydrogen que permit√≠a tener los resultados de tu c√≥digo directamente en el Script de manera muy intuititva y c√≥moda. ¬øPor qu√© dej√© de usarlo? Siento que dejaron de darle tanto soporte luego que Github fue adquirido por Microsoft y favorecieron m√°s VSCode. Adem√°s luego de usarlo por un rato, comandos simples como `df.shape` tomaba 40-50 segundos, lo cual era inaceptable. Cr√©anme que volver√≠a mil veces a utilizarlo si viera que hay soporte y mantenimiento continuo. Una l√°stima.

- **GIT/Github** ((O), Pr: 1): Me cuesta creer que a√∫n existen muchos "Data Algo" que no usan GIT. Esto deber√≠a ser obligaci√≥n y requisito siempre. Afortunadamente me toc√≥ trabajar en un equipo con muy buenas pr√°cticas de desarrollo donde entend√≠ la importancia de llevar control de versiones siempre. GIT no es dif√≠cil, pero es importante entender conceptos de Commits, push, trabajo en ramas. Adicionalmente llevarlo con Github (u otras variantes como GitLab o BitBucket) y entender conceptos como Pull Request, levantar Issues, Revisiones de c√≥digos, approvals, etc. Si no usas GIT/Github, no te sientas mal. Hay empresas gigantes que no lo usan, pero aprenderlo y fomentar su uso te lleva f√°cilmente a un nivel m√°s alto de calidad. Si quieres aprenderlo tengo una serie de tutoriales que parten [ac√°]({{ site.baseurl }}/github/).

- **Docker** ((O), Pr: 1): Hoy por hoy es imprescindible mover a producci√≥n todo en Docker. No soy para nada experto en el tema pero puedo crear un contenedor, conectarlo con el mundo real y eventualmente hostearlo en alguna parte. Es por lejos la mejor manera de asegurar reproducibilidad en cualquier ambiente (Unix, Max o incluso Windows con WSL2). Hay que aprenderlo s√≠ o s√≠.

- **Bash** ((O), Pr: 1): Creo que es sumamente importante conocer un poquito de Bash, en especial para automatizar procesos. Bash es el lenguaje de tu computador y te permite interactuar con √©l. Algunas cosas interesantes que puedes hacer: Agendar trabajos peri√≥dicos de manera autom√°tica, mandar correos cuando termine un proceso largo, apagar el computador luego de entrenar un modelo por la noche. No es dificil de aprender, y la mayor√≠a de las veces vas a googlear en Stackoverflow para salir del paso.

- **Wandb** (Rk: 791, ND: 2.1M+, Pr: 2): Este es un logger, que si bien permite llevar registro de modelos de ML y DL, funciona mejor en Deep Learning. F√°cil de usar, muy linda interfaz y permite llevar registro de Arquitectura, Hiperpar√°metros, Curvas de Aprendizaje, ejemplos de Inferencia, almacenar tablas y gr√°ficas, etc. Adem√°s contiene un sistema de B√∫squeda de Hiperpar√°metros distribuido usando Hyperband, es decir, se puede entrenar el mismo modelo en distintas m√°quinas sin interferir entre ellos y sin repetir b√∫squeda, Weights & Biases lleva el control.

- **MLFlow** (Rk: 260, ND: 11.1M+, Pr: 2): La verdad es que MLFlow es igual o mejor que Weights & Biases, pero a m√≠ no me gust√≥. Encuentro que su documentaci√≥n es engorrosa y su API no es tan intuitiva. Hace lo mismo adem√°s de poder llevar proyectos y un Model Registry para llevar control de versiones del entrenamiento de tu modelo. Si les interesa aprenderlo, tengo un tutorial [ac√°]({{ site.baseurl }}/mlflow/).

- **FastAPI** (Rk: 377, ND: 6.8M+, Pr: 1): Es quiz√°s una de las librer√≠as m√°s r√°pidas en Python y es muy f√°cil de usar. Primero, est√° hecha por un Colombiano (Tiangolo), es de excelent√≠sima c√°lidad, muy buena documentaci√≥n, muchas funcionalidades, y requiere de poquito c√≥digo, ¬øqu√© m√°s se puede pedir?. Definitivamente si quieres distribuir lo que sea, data, un modelo de ML, FastAPI es la mejor opci√≥n. Es tanto la popularidad que varias librer√≠as utilizan esta librer√≠a under the hood.

- **Airflow** (Rk: 375, ND: 6.8M+, Pr: 1): Yo creo que a menos que seas Analista de Datos, es una herramienta que hay que aprender. Airflow es un orquestador creado por Airbnb, que permite ejecutar y agendar Scripts para ser ejecutados de manera local o remota. Lo bueno de Airflow es que servicios como AWS, o Astronomer permiten ejecutarlos en entornos autoescalables en Kubernetes, lo cual quita una capa de complejidad, en especial a los que no sabemos c√≥mo demonios funciona Kubernetes (un orquestador de contenedores). Airflow se hizo famoso como un orquestador de ETLs, que es compatible con casi todo. Yo lo he usado con: AWS, Spark, AWS Glue, ElasticSearch, MongoDB, SQLAlchemy, Redshift, Postgres. Es tan potente que incluso permite entrenar modelos de ML localmente o en entornos como Amazon SageMaker (aunque no es la opci√≥n √≥ptima para ML), de hecho Airbnb cre√≥ BigHead para eso, que no ha sido liberado al p√∫blico. Creo que su √∫nico contra es que un poco verboso, y tiene harto c√≥digo boilerplate. Pero su funcionamiento es impecable.

- **Metaflow** (Rk: NA, ND: NA, Pr: 2): Otro orquestador, pero creado por Netflix, pero que est√° enfocado en llevar modelos de ML a producci√≥n. Las ventajas, mucho menos boilerplate que Airflow, no tienes los t√≠picos problemas de Xcoms en Airflow, puede ejecutarse local o en AWS mediante AWS Batch, EC2 y Step Functions. Permite automatizar todo el proceso de entrenamiento creando de ser necesarios ambientes anacondas independientes para cumplir con requerimientos de versiones espec√≠ficas. No alcanc√© a utilizarlo, pero me toc√≥ leerme toda la documentaci√≥n para impulsar su uso.

- **Kedro** (Rk: 2066, ND: 378K+, Pr: 0): Otro orquestador, pero desarrollado por QuantumBlack. Es bien poderoso, en el sentido que permite crear Pipelines de carga de datos, y de entrenamiento de modelos, pero no logr√© encontrar tantas opciones de escalabilidad. Si bien permite por ejemplo conexi√≥n con Sagemaker en AWS, no tiene las opciones m√°s avanzadas de escalamiento vertical y horizontal que tiene Airflow y Metaflow. Adem√°s lo encontr√© en su momento un poco verboso, y sus Docs ten√≠an errores, que hizo que me costar√° mucho entenderlo. 

- **DVC** (Rk: 1700, ND: 551K+, Pr: 1): Para m√≠ es el orquestador m√°s liviano, con menos Boilerplate y m√°s sencillo de utilizar, pero tiene una cierta inclinaci√≥n al entrenamiento de modelos. DVC es m√°s que un orquestador, permite llevar registro de versiones de tu data, los cuales normalmente no es posible llevar en GIT; organizar Pipelines, llevar registro de Hiperpar√°metros, guardar m√©tricas de performance, etc. Me gust√≥ mucho m√°s que Airflow, pero para una orquestaci√≥n local, aunque podr√≠a escalar. Puedes aprender de √©l en este [tutorial]({{ site.baseurl }}/dvc/).

- **Great-Expectations** (Rk: 429, ND: 5.9M+, Pr: 1): Es un validador de datos. No les puedo explicar lo necesario que es empezar a incluir elementos como estos en nuestros Pipelines de datos. Todas las empresas tienen datos, pero pocas empresas con calidad suficiente para llegar y utilizar. Great Expectations es como una librer√≠a de Tests asociados a si los datos cumplen: rangos, tipos, cantidad, distribuci√≥n y un largo etc. En caso de no cumplir levanta la alerta dando en detalle qu√© registros no cumplen con el est√°ndar solicitado. Adem√°s es compatible con Airflow, por lo que uno puede usar como Gate de Ejecuci√≥n si tu data cumple o no los requerimientos de modo de no cargar datos sucios en tus fuentes principales de almacenamiento. Muy buena librer√≠a.

- **Pytest** (Rk: 72, ND: 39.4M+, Pr: 1): Librer√≠a de Unit Test, algo que los Data Scientist rara vez hacemos. Es muy buena librer√≠a, f√°cil de usar, aunque es media rara la Documentaci√≥n, pero nada que un buen tutorial de Youtube no pueda ense√±ar. Todos los pipelines de datos, deber√≠an considerar Unit Tests.

- **Hydra** (Rk: 1507, ND: 698K+, Pr: 1): Para m√≠ el mejor CLI para modelos de Machine Learning, nacida en el equipo de Research de Facebook, ahora Meta. No s√≥lo permite crear comandos personalizados para ejecutar Scripts desde el terminal sino que tambi√©n permite crear configuraciones muy complejas tanto para modelos de ML como para Pipelines en general. Para los que siguen el Blog saben que es de mis favoritas, y pueden ver [ejemplos]({{ site.baseurl }}/hydra/) ac√°. Muy buena librer√≠a, aunque no es tan famosa a√∫n.

- **CML** (Rk: NA, ND: NA, Pr: 0): Es una librer√≠a para automatizar procesos con Github Actions. Si les interesa ver en acci√≥n pueden chequear [ac√°]({{ site.baseurl }}/cml/). No vale la pena aprenderla, son s√≥lo un par de comandos y ya.

- **BentoML** (Rk: NA, ND: NA, Pr: 0): Esta es una librer√≠a que permite automatizar el Deployment de Modelos de Machine Learning. No la he usado pero he le√≠do mucho su documentaci√≥n, porque en estricto rigor permite crear de manera muy sencilla un Docker con tu modelo que est√© listo para entregar al equipo de desarrollo. Tambi√©n crea una API Rest autom√°ticamente. Definitivamente voy a estar meti√©ndome m√°s en el tema.

- **MLEM** (Rk: NA, ND: NA, Pr: 0): Esta es una librer√≠a que me ofrec√≠ a probarla en Beta. Hace lo mismo que Bento, pero permite r√°pidamente deploy en Cloud (AWS, Azure y GCP y Heroku), para cualquier tipo de modelo, y crea el Docker autom√°ticamente. Cuando la v√≠ me pareci√≥ demasiado m√°gica y est√° reci√©n partiendo. Lo bueno es que incluye un curso que se puede tomar de manera gratuita [ac√°](https://learn.iterative.ai/).

- **Typer** (Rk: 349, ND: 7.8M+, Pr: 2): Creada tambi√©n por Tiangolo, es un CLI mucho m√°s poderoso que Hydra pero con un enfoque general. Su API es muy parecida a FastAPI, muy sencilla y potente. Yo la prob√© antes de conocer Hydra, pero igual creo que vale mucho la pena.

- **BeautifulSoup4** (Rk: 63, ND: 42M+, Pr: 2): Es una herramienta de Scrapping para poder tomar data de p√°ginas web. S√∫per potente, ya que tiene mucho del trabajo que uno normal necesita hacer automatizado. Su documentaci√≥n es buena y es f√°cil de aprender. Si quieres saber c√≥mo usarla tengo un tutorial [ac√°]({{ site.baseurl }}/dtc/).

- **Boto3** (Rk: 1, ND: 392M+, Pr: 0): Es impresionante la cantidad de descargas de Boto3. Lamentablemente s√≥lo ser√° √∫til si utilizas AWS. Yo la he usado principalmente para interactuar con S3. Adem√°s si instalas `s3fs` y `fsspec` es posible utilizar pd.read_* y .to_* de pandas utilizando un URI de S3 directamente, por ejemplo: `pd.read_csv('S3://bucket/folder/file.ext')`.

- **Joblib** (Rk: 126, ND: 24M+, Pr: 0): Yo lo uso principalmente para serializar modelos entrenados de Scikit-Learn y similares de acuerdo a [esto](https://scikit-learn.org/stable/model_persistence.html).

- **Pickle** (Rk: NA, ND: NA, Pr: 0): Dej√© de usarlo, porque Scikit-Learn favorece guardarlo en formato joblib.

- **Faker** (Rk: 454, ND: 5.4M+, Pr: 0): Yo s√≥lo lo utilic√© para una prueba de t√©cnica para un candidato. Quer√≠a poner la misma data que utilizabamos pero sin entregar informaci√≥n confidencial. Faker permite emular info de manera muy real, creando de todo. En ese momento, cree: Nombres, Apellidos, Direcciones, Tel√©fonos, Patentes de Auto, Empresas, y un largo etc. Es sumamente bueno cuando se quiere generar un producto en el cual la data no est√° lista. S√∫per √∫til, pero no lo vas a usar siempre.

- **pyyaml** (Rk: 11, ND: 142M+, Pr: 0): No vale la pena aprender m√°s que una funci√≥n para importar un yaml, esto permitir√° manipular tu `yaml file` como diccionario de Python. De esta manera toda tu configuraci√≥n vive en un archivo yaml, y no ensucia tus Scripts.

- **pdbpp** (Rk: 2999, ND: 173K+, Pr: 2): Es un debugger en terminal. Personalmente no me gusta el debugger de VSCode, por eso uso este. Tiene atajos de teclado y es bastante r√°pido. Lo recomiendo, aunque no es necesario que lo sepan utilizar.

- **holidays** (Rk: 526, ND: 4.2M+, Pr: 0): Es una librer√≠a peque√±ita pero muy poderosa (se ve en su ND). Tiene todos los feriados, de todos los pa√≠ses de todos los a√±os. S√≥lo indicas pa√≠s, periodo y ya. Yo la utilice para crear features en un [Tabular Playground de Kaggle]({{ site.baseurl }}/kaggle-tps/). Muy √∫til en series de tiempo, pero tiene un m√©todo y ya.

- **Python-Box** (Rk: 1038, ND: 1.4M+, Pr: 0): Es s√∫per √∫til, solo envuelves un diccionario con `Box()` y puedes llamar tu diccionario como `dict.key` en vez de `dict['key']`. Ahorras varios caract√©res.

- **beepr** ((R), Pr: 0): Esta es una librer√≠a in√∫til, pero que me encantaba. Pod√≠as agregar sonidos cuando tu c√≥digo fallaba o terminaba correctamente (t√≠pico sonido de Mario al pasar el n√≠vel), lo cual sac√≥ m√°s de una carcajada en el equipo. 

- **chime** (Rk: NA, ND: NA, Pr: 0): Ser√≠a como el equivalente en Python de Beepr. Hay otra librer√≠a m√°s que ocup√© que no recuerdo el nombre pero no funcion√≥ tan bien.

- **Rich** (Rk: 290, ND: 9.8M+ Pr: 2): Esta es una librer√≠a muy poderosa para agregar color a tu terminal. Tiene muchas funcionalidades, barras de progreso, outputs de colores, quiz√°s la mejor es que es posible que los errores en Python se rendericen m√°s bonitos, para por lo menos frustrarse menor cuando algo falla. Creo que igual vale la pena invertir en una mejor experiencia de usuario cuando crees productos CLI, por lo que vale la pena aprenderla en ese caso. 

- **tqdm** (Rk: 77, ND: 38M+ Pr: 0): Tiene dos funciones interesantes, `tqdm` para envolver un For Loop y tener barra de progreso. Y otra para llamada `progress_apply` que permite barra para el apply de pandas. No te demoras nada en dominarla.

# Librer√≠as est√°ndar que deber√≠as usar/conocer

- **Logging** (Rk: NA, ND: NA Pr: 1): Si vas a automatizar algo en Python, sea cual sea su uso, debes loggear todo. Logging permite generar archivos `.log` que permitir√°n analizar a posteriori si un Script termin√≥ con √©xito o no. S√∫per √∫til, f√°cil de aprender, tiene s√≥lo un par de comandos para indicar √©xito, info, warning, errores. Puedes combinar con chime y con Rich para tener un producto multicolor y sonoro. Hace m√°s agradable la pega.

- **requests** (Rk: 5, ND: 194M+ Pr: 0): Sirve para conectarse a una API o en combinaci√≥n con BeautifulSoup para obtener el HTML de un sitio WEB. Yo la he utilizado s√≥lo para eso y no cuesta nada aprender a utilizarla, aunque quiz√°s si debas entender el output que normalmente es un string con HTML o string con arreglos de diccionarios anidados si proviene de una API. 

- **glob** (Rk: NA, ND: NA Pr: 0): Permite revisar directorios utilizando s√≥lo el comando `glob` y un path con expresiones regulares simples. S√∫per √∫til, por ejemplo, cuando tienes que importar muchos archivos en un s√≥lo pandas DataFrame.

- **json** (Rk: NA, ND: NA Pr: 0): Yo lo he usado para convertir el output de requests en diccionarios y para guardar outputs como json. S√≥lo eso!

- **pathlib** (Rk: NA, ND: NA Pr: 2): Esta es una librer√≠a bien interesante para poder automatizar la creaci√≥n de directorios y llevar tus Path de manera m√°s sencilla. Puedes manipular Path combinandolos, creando Paths m√°s sencillos y crear o eliminar carpetas dentro de ellos. Es f√°cil de utilizar y tengo ejemplos de ello en mis tutoriales de [DVC]({{ site.baseurl }}/dvc/).

- **getpass** (Rk: NA, ND: NA Pr: 0): Esta librer√≠a tiene una funci√≥n llamada `getpass`, que funciona como un Text Input pero con los caract√©res ocultos. √ötil para ingresar data que no quieres que se vea, pero no la encripta ojo.

## Uff
{: .no_toc }

Y con esto terminamos. Debo decir que este es al art√≠culo que m√°s trabajo me ha dado. Y demor√© cerca de dos meses en escribirlo. Voy a tratar de ir llenando esto con el tiempo a medida que vaya probando m√°s cosas. Algunas de las tecnolog√≠as que se me quedaron en el tintero porque no cumplen los requisitos exigidos arriba:

* Varios servicios AWS
  * Sagemaker
  * AWS Lambda
  * API Gateway
  * Step Functions
* [PRegex](https://pregex.readthedocs.io/en/latest/)
* [Dagshub](https://dagshub.com/)
* [poetry](https://python-poetry.org/). Por alguna raz√≥n me da terror instalarla, aunque he le√≠do bastante de ella.
* [fancyimpute](https://pypi.org/project/fancyimpute/)
* [NGBoost](https://stanfordmlgroup.github.io/projects/ngboost/)
* [SKLego](https://scikit-lego.readthedocs.io/en/latest/)
* [tabnet](https://github.com/dreamquark-ai/tabnet)
* [UMAP](https://umap-learn.readthedocs.io/en/latest/)
* [Segmentation Models](https://github.com/qubvel/segmentation_models.pytorch)
* [NannyML](https://www.nannyml.com/)
* [DGL](https://www.dgl.ai/)
* [BioPython](https://biopython.org/)
* Ecosistema Pytorch :
  * [torchtext](https://pytorch.org/text/stable/index.html)
  * [torchaudio](https://pytorch.org/audio/stable/index.html)
  * [torchgeo](https://torchgeo.readthedocs.io/en/stable/)
  * [Pytorch Geometric Temporal](https://github.com/benedekrozemberczki/pytorch_geometric_temporal)
  * [torchrec](https://pytorch.org/torchrec/)
  * [Pytorch Video](https://pytorchvideo.org/)

Espero que esto sea de utilidad para tenerlo como referencia a la hora de enfrentar distintos problemas en Ciencia de Datos.

Nos vemos,

[**Alfonso**]({{ site.baseurl }}/contact/)
