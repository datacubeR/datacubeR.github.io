---
permalink: /ds-lib/ 
title: "쯈u칠 debo aprender para ser Data Scientist?"
subheadline: "Un compendio con m치s de 100 tecnolog칤as para Ciencia de Datos."
teaser: ""
# layout: page-fullwidth
usemathjax: true
category: ds
header: no
image:
    thumb: libraries/librer칤as.png
tags:
- python
- tutorial
published: true
---

![picture of me]({{ site.urlimg }}libraries/librer칤as.png){: .left .show-for-large-up .hide-for-print width="300"}
![picture of me]({{ site.urlimg }}libraries/librer칤as.png){: .center .hide-for-large-up width="250"}

La ciencia de datos es una de las disciplinas m치s de moda hoy en d칤a. Y c칩mo que por alguna raz칩n todos quieren ser parte de ello. Sin duda en el mediano/largo plazo probablemente todas las disciplinas tendr치n una componente de datos y la verdad es que vale la pena aprender a lidiar con ellos.<!--more-->

Hoy en d칤a la decisi칩n es simple, trabajar con R o con Python, pero el tema es que Python tiene 150.000+ librer칤as y R tiene otras tantas, por lo que a veces es abrumante pensar, tengo que aprender todo? Ojo, eso sin contar otro tipo de tecnolog칤as de Visualizaci칩n, ETL y un largo etc. Por donde empiezo, tengo un mont칩n de opciones y no me gustar칤a perder el tiempo en cosas que no valen la pena.

Adem치s, en plataformas como Linkedin siempre hay gente en cuyo t칤tulo dice Data Science \| Machine Learning \| Analytics Expert y un largo etc. y que probablemente en su vida ha programado y comparten publicaciones como esta:

# TL;DR
{: .no_toc }
*[TL;DR]: Too Long; Didn't Read



## TOP 10 LIBRER칈AS DE PYTHON
{: .no_toc }

Esta es una lista que encontr칠 por ah칤:

1. Pandas.
2. NLTK.
3. Plotly.
4. Scikit-learn.
5. Category-encoders (era tremenda librer칤a pero est치 sin mantenimiento actualmente)
6. Imbalance Learning. (Esta no es ni siquiera una librer칤a en Python, se llama Imbalanced-Learn)
7. XGBoost.
8. Keras / Tensorflow.
9. Theano. (Nadie usa esto ya)
10. Beautiful Soup.

Colocan una foto llena de logos, y un listado con nombres casi aleatorios:  
![picture of me]({{ site.urlimg }}libraries/ble.png){: .center}

A veces te indican qu칠 librer칤as s칤 o s칤 tienes que saber, y nunca las has escuchado:

![picture of me]({{ site.urlimg }}libraries/libraries_1.jpg){: .center}

A veces tienen hasta errores burdos: 

![picture of me]({{ site.urlimg }}libraries/libraries_2.jpg){: .center}

Y uno se pregunta 쮺on qu칠 parto?. Y la verdad es que si bien son librer칤as que pueden ser 칰tiles, hay que ver si realmente son aplicables al trabajo que haces y si vale el esfuerzo de aprenderlo.

## Un Alto antes de Continuar
{: .no_toc }

La ciencia de datos es una disciplina enorme. Y hay que darla paso a paso, o no vamos a lograr nada y vamos a vivir estresados de tantas cosas que no sabemos usar y que tenemos que aprender. No digo que mi caso sea el perfecto, para nada, pero yo part칤 as칤:

* **Business Analyst** (Una especie de Data Analyst, pero enfocado en dar valor al negocio 游뱘 ja ja): En mis primeros 2 a침os, lo que m치s hac칤a era responder preguntas con datos. El resultado, una query en SQL, la mayor parte del tiempo con una tabla exportada en Excel. Aprend칤 mucho SQL porque las Bases de Datos que us치bamos eran gigantes y muy complejas. Responder una pregunta de negocio pod칤a tomar 6 o 7 subqueries, con muchos joins en cada una de ellas. Luego tuve la oportunidad de crear algoritmos sencillos para aplicar l칩gicas de negocios, a esto le llam치bamos Calculation Engines (Motores de c치lculo). Y es b치sicamente aplicar l칩gicas de negocio complejas en los datos para chequear qu칠 clientes cumpl칤an o no regulaciones bancarias. Luego mut칠 nuevamente a algo m치s BI, y me tocaba hacer dashboards en Tableau todo el d칤a, todos los d칤as. La data que el dashboard necesita no se ordena sola, por lo que aparte de hacer gr치ficos que digan algo, hab칤a que hacer mucho SQL de fondo. No fue hasta como mi tercer a침o de Analista que comenc칠 a hacer una Regresi칩n o un SVM loco por ah칤. Todo esto en R.

* **Data Scientist**: Luego de como 4 a침os logre un puesto de Data Scientist. Ya llevaba como 1 a침o haciendo modelos a escondidas, porque no era mi rol. Y ac치 me cambi칠 a Python definitivamente. Tuve que aprender mucho pandas, Scikit-Learn (y los 3 grandes XGBoost, LightGBM y CatBoost) y modelar mucho. Pero con muchos errores te칩ricos de fondo, y ah칤 decid칤 que era importante entender el transfondo te칩rico. En ese tiempo le칤a mucho blog y ve칤a mucho video (a칰n lo hago, pero ah칤 part칤). Quiz치s desde el 2021 que ya me met칤 de lleno en el Deep Learning y ac치 estamos.

> Todo tiene que ser progresivo. El `Deep Learning` es s칩lo una extensi칩n del `Machine Learning`, en vez de hacer feature selection/engineering, ac치 hay que hacer "Architecture Engineering", tratando de encontrar la arquitectura m치s apropiada a un problema. Por otra parte el `Machine Learning` es una extensi칩n del `An치lisis`. En vez de que tenga que analizar la data manualmente, el modelo aprende los insights por m칤 y a escala, pero hay que entregar data estructurada. Y el `An치lisis` es s칩lo una extensi칩n de la `Manipulaci칩n de Datos`. S칩lo se puede entender la data una vez que la tengo ordenadita. Entonces, hay que partir de a poco, y no saltarse pasos.

{% include toc.md %}

# La idea

Trabajando como Data Scientist creo que he usado 100+ librer칤as y otras tecnolog칤as, por lo que quiero hablar de cada una de ellas y dar mi opini칩n si vale la pena aprenderla o no. Quiero decir que en verdad llevo m치s tiempo usando R (cerca de 5 a침os) que Python (3 a침os), por lo que voy a tratar de dar mi opini칩n de ambos.

La idea nace porque siempre me pongo a rabiar cuando <q>gente experta</q> publica algo copiado de plataformas como Coding Dojo, Datacamp, etc. con informaci칩n incompleta y recomendando librer칤as que nunca han usado (y hoy yo tambi칠n voy a hacer eso 游뱘游땐). Entonces decid칤 que quiero hacer un compendio de las tecnolog칤as m치s famosas que hay relacionadas a la ciencia de datos. 

El compendio incluir치 lo siguiente: 

* Todas las librer칤as/tecnolog칤as que he utilizado previamente. 
* S칩lo en ocasiones excepcionales listar칠 librer칤as que no he utilizado cuando ocurra algunos de los siguientes casos:
    * Est치n en mi lista de estar pr칩ximo a usarla y si bien no tengo proyectos con ellas ya me he adentrado en su documentaci칩n.
    * Son demasiado famosas para dejarlas fuera.

Principalmente mencionar칠 librer칤as de Python, porque es el estado del arte en Ciencia de Datos y algunas librer칤as de mi tiempo usando R. 

Adem치s me d칤 la lata de recorrer los 5000 paquetes m치s descargados en PyPI para recomendar librer칤as de Python, por lo que en el caso de que corresponda indicar칠 el Ranking y el n칰mero de descargas al 01-07-2022. Debo advertir que puedo estar un poco desactualizado en R porque dej칠 de usarlo definitivamente desde fines del 2019. Adem치s cuando corresponda voy a mencionar otras tecnolog칤as fuera de R o Python que quiz치s vale la pena conocer cuando se trabaja en ciertas 치reas de la Ciencia de Datos.

* Librer칤as de Python incluir치n Ranking en PyPI (Rk) y n칰mero de descargas (ND).
* Librer칤as de R ir치n acompa침adas de un indicador (R).
* Otras T칠cnolog칤as que no son librer칤as ni de R ni de Python llevar치n una (O) de Otras.

Voy adem치s dividirlas en Prioridades:
* 1: Definitivamente debes aprenderlas y empezar a utilizarlas ya. En el caso de R debes aprenderla ya, pero s칩lo si usas R.
* 2: Dependiendo del caso (si trabajas con tecnolog칤as anexas) podr칤a ser una buena opci칩n.
* 0: No pierdas tu tiempo en aprenderlas. No porque sea mala, sino que la vas a necesitar de manera muy espor치dica, por lo que hay que saber qu칠 puede hacer, para qu칠 sirve y puede que en alg칰n momento de la vida una que otra funci칩n sea 칰til.

Finalmente, dividir칠 todas las recomendaciones en las siguientes categor칤as:
* Manipulaci칩n de Datos, 
* Bases de Datos, 
* Machine Learning, 
* Deep Learning, 
* Miscel치neo. 
* Librer칤as Est치ndar

{% include alert todo='Esta lista no es exhaustiva y si alguien quiere contribuir ayudando a reclasificar esto estoy abierto a sugerencias y colaboraciones.' %}

> Disclaimer: Todas las librer칤as que mencionar칠 son excelente en lo que hacen. Si recomiendo no aprenderlas no es porque sean malas (a menos que lo diga), es s칩lo que muy rara vez necesitar치s utilizarlas debido a que son demasiado espec칤ficas y no vale la pena enfocarse en ellas. Basta con leer la documentaci칩n un rato antes de utilizarla y saber que existe.

Finalmente el objetivo final de este compendio es que los nuevos Data Scientists (y tambi칠n los m치s experimentados) puedan tener una opini칩n de qu칠 librer칤as existen y cu치les s칤 o s칤 deber칤an dominar.

# Manipulaci칩n de Datos

- **SQL** ((O), Pr: 1): Si bien esta no es una librer칤a de Python/R, esto es por lejos lo primero que todo Data Scientist debe saber. No es necesario ser un ultra experto en este tema pero s칤 al menos debes dominar los siguientes aspectos:

* SELECT/FROM
* JOINS: Entender las principales diferencias entre LEFT, RIGHT, INNER, SELF JOINS.
* WHERE, GROUP BY, HAVING.
* ORDER BY
* MIN,MAX, AVG, etc.
* CREATE (volatile, temporary) TABLE, INSERT INTO, WITH (Esto es bien difuso ya que depende del motor).
* Entender al menos los motores m치s populares que son por lejos MySQL y Postgresql.

Es muy triste ver gente que se hace llamar Data Scientist y no sabe hacer una query. Sin datos, no hay Cient칤fico de Datos, por lo que s칤 o s칤 dale a esto primero que cualquier otra cosa!!

- **Pandas** (Rk: 31, ND: 86M+, Pr: 1): Esta es por lejos la librer칤a m치s utilizada en Ciencia de Datos y para mi gusto la m치s completa. No est치 en el primer lugar porque realmente creo que es m치s importante saber SQL primero ya que es mucho m치s simple. B치sicamente Pandas es un SQL con Esteroides, much칤simo m치s poderosa y que bajo ning칰n motivo puede ser reemplazada por SQL. Pero tiene tantos comandos que al principio uno podr칤a no saber c칩mo empezar. Su API es tan buena que existen muchos mirrors, como Dask, koalas, o cuDF, que siguen la misma convenci칩n s칩lo que el backend hace algo distinto (B치sicamente aprendiendo pandas se pueden aprender varias librer칤as a la vez). Mi recomendaci칩n es aprender c칩mo reproducir todo lo aprendido en SQL y luego aprender funciones para resolver problemas espec칤ficos. 쮺칩mo aprender? Lo mejor es a trav칠s del [User Guide](https://pandas.pydata.org/docs/user_guide/index.html) en su propia documentaci칩n.

- **Numpy** (Rk: 15, ND: 110M+, Pr: 0): Numpy es una librer칤a de computaci칩n cient칤fica, esto quiere decir, computar/calcular implementaciones matem치ticas/estad칤sticas desde test de hip칩tesis, Transformadas de Fourier, y un largo etc. Normalmente se recomienda aprender antes o junto a Pandas, pero realmente creo que (prep치rense) <mark>no vale la pena aprenderla inicialmente</mark>. Hace unos a침os era necesario aprender numpy para complementar pandas, ya que hab칤an muchas cosas que no estaban disponibles en pandas pero s칤 en Numpy, pero si es que no vas a hacer implementaciones directamente de Algebra Lineal, no va a ser necesario usarla. Obviamente cuando uno es avanzado se dar치 cuenta que es bueno entender conceptos de Numpy como la vectorizaci칩n. Mi recomendaci칩n es aprender **s칩lo funciones que no est치n en pandas** a medida que las vayas necesitando.

A varios les puede llamar la atenci칩n que tiene m치s descargas que Pandas, pero la explicaci칩n es sencilla. Muchas librer칤as tiene como dependencia Numpy, Scikit-Learn, Matplotlib, pandas, y un largo etc, que hace obligatorio siempre tenerla instalada.

- **Scipy** (Rk: 65, ND: 42M+, Pr: 0): Este es un pedacito de Numpy a칰n m치s espec칤fico. Definitivamente <mark>no vale la pena aprenderlo</mark>, y s칩lo se necesitar치n funciones muy espec칤ficas. En mi caso s칩lo la he usado para utilizar matrices sparse cuando queremos disminuir el tama침o de matrices con demasiados ceros y cuando ense침칠 probabilidad, porque tiene todas las distribuciones de probabilidad (incluso si son muy raras) con sus respectivas funciones para muestreos, pmf, pdf y cdf.

- **dplyr** ((R), Pr: 1): Dir칤a que es la versi칩n en R de pandas, pero es un poco m치s limitado. No porque no tenga las capacidades para hacer lo que pandas hace sino porque el ecosistema de R est치 disperso en m치s paquetes. Para emular pandas en R se tiene que usar casi todo el tidyverse: `dplyr`, `tidyr`, `lubridate` y `hms` (para fechas), `forecats` (para variables categ칩ricas), `purrr` (para loops eficientes), `readr` + `vroom` para io, `stringr` y `stringi` para lidiar con strings. Creo que el uso del pipe (%>%) hace que el c칩digo en R sea m치s expresivo que en pandas y realmente vale la pena aprender este ecosistema si trabajas en R ya que es mucho m치s amigable que la sintaxis de R puro.

- **Dask** (Rk: 390, ND: 5.6M+, Pr: 0): Corresponde al motor que provee paralelismo para Pandas. La librer칤a es excelente pero bajo ning칰n motivo vale la pena invertir tiempo ac치, porque b치sicamente es la misma interfaz de pandas. Basta con hacer `import dask.dataframe as dd` y anteponer `dd` en vez de `pd` y listo. No he tenido que usar nunca esta librer칤a pero es demasiado famosa para no mencionarla.

- **data.table** (R principalmente pero creo que tambi칠n est치 en Python, Pr: 0): Este es un tema pol칠mico porque hace mucho tiempo hab칤a una discusi칩n entre el creador de esta librer칤a y la gente de RStudio. B치sicamente `data.table` es la librer칤a m치s r치pida para manejo de datos en R pero su sintaxis no es muy amigable. Afortunadamente Hadley Wickham creo `dtplyr` que permite usar data.table como el backend de dplyr, por lo que dir칤a que si bien esta librer칤a es extremadamente poderosa no vale la pena aprenderla si sabes `dplyr`.

- **cudf** (Rk: NA, ND: NA, Pr: 0): `cuDF` es una librer칤a que es parte de RAPIDS, un set de paquetes en Python desarrollado por NVIDIA que permiten ejecutar todo en GPU. Este es el mirror de Pandas, b치sicamente la misma sintaxis que pandas pero que en el backend se ejecuta en GPU. <mark>No vale la pena apenderla, ya que es igual a pandas</mark>.

- **cupy** (Rk: NA, ND: NA, Pr: 0): Es el Mirror en este caso de Numpy. Si sabes `numpy` entonces sabes `cupy`, no deber칤a estar dentro de tus prioridades como Data Scientist. Pero en el caso de querer lanzar tus procesos a la GPU es excelente.

{% include alert alert='Estas librer칤as no deber칤an ser la mejor opci칩n para trabajar con grandes volumentes de datos. Esto porque normalmente la GPU tiene menos RAM, a menos que tengas varias GPU o una RTX3090. La mayor칤a del tiempo utilizar pandas va a ser m치s que suficiente.'%}

- **pyspark** (Rk: 127, ND: 23.9M+, Pr: 0): Este es la librer칤a por excelencia para trabajar con Big Data. `pyspark` es el cliente de Python para el Spark de Scala. Lo bueno de esta librer칤a es que te da la opci칩n de usar una API muy similar al Spark en Scala o incluso una que utiliza comandos tipo SQL. Esta va a ser la mejor opci칩n para cuando tengas que trabajar con Big Data y computaci칩n distribuida en un Cluster, pero <mark>NO VALE LA PENA APRENDERLO</mark>. Principalmente porque la interfaz de SQL te servir치 la mayor cantidad del tiempo para llevar a cabo ETLs y en caso de procesamiento m치s rebuscado `koalas` es un mirror de pandas para ejecutar Spark. 

- **findspark** (Rk: 729, ND: 2.4M+, Pr: 0): Tan enredada es la instalaci칩n de Spark que se cre칩 una librer칤a para tener el path de instalaci칩n y poder levantar un Cluster local. S칩lo sirve para eso.

- **koalas** (Rk: 1047, ND: 1.4M+, Pr: 0): Si tienes que usar Spark yo creo que es mejor `koalas`, que tiene la sintaxis de pandas que uno ya sabe. No es necesario aprender nada nuevo.

- **sparklyr** ((R), Pr: 2): La 칰nica vez que tuve que trabajar con data en Spark fue en Python y us칠 koalas. Pero vale la pena mencionar esta librer칤a porque b치sicamente permite ejecutar Spark usando sintaxis de `dplyr`. Si es que llegaras a necesitar Spark, mi recomendaci칩n ser칤a hazlo en otro lenguaje (principalmente por los problemas de memory leakage de R) pero si necesitas hacerlo en R, esta es la mejor opci칩n.

- **NetworkX** (Rk: 147, ND: 20M+, Pr: 2): Es una librer칤a de manipulaci칩n de datos, pero en forma de grafos. No la he usado m치s que para calcular m칠tricas de centralidad (closeness, betweeness, degree, etc). Pero es probable que comience a utilizarla m치s.

- **Microsoft Excel** ((O), Pr: 1): Excel **nunca** deber칤a ser una opci칩n para trabajar con Datos, pero s칤 o s칤 tienes que saber usarlo porque lamentablemente los archivos `.xlsx` son todav칤a un formato extremadamente popular. <mark>NUNCA</mark> deber칤as utilizar Excel si no es s칩lo para entregar resultados. Si t칰 eres de los que a칰n dice que hay cosas que son m치s sencillas en Excel que en Pandas o SQL, es que no sabes utilizar bien esas tecnolog칤as a칰n.

# Bases de Datos

- **sqlalchemy** (Rk: 49, ND: 49M+, Pr: 1): Esta es por lejos una de las mejores librer칤as que se han creado en Python. B치sicamente permite utilizar cualquier Base de Dato SQL con una interfaz com칰n. Debo decir que si bien esta es una librer칤a extremadamente poderosa y que vale completamente la pena aprender, la documentaci칩n est치 pensada para gente bien "comput칤n" y no es tan amigable. Mi recomendaci칩n para aprenderla es mediante videos tutoriales. Ahora en Ciencia de Datos la vas a ocupar s칤 o s칤 si eres Data Engineer para poder modelar Bases de Datos o hacer consultas. Como Data Scientist normalmente s칩lo la usar치s como forma de conexi칩n con Pandas mediante `create_engine` y `.to_sql()` para extraer datos.

- **sqlmodel** (Rk: 4085, ND: 90K, Pr: 2): Esta es una librer칤a creada hace muy poco por el gran [Sebasti치n Ram칤rez](https://www.linkedin.com/in/tiangolo/?originalSubdomain=de) (Tiangolo). No he utilizado esta librer칤a pero s칤 s칠 que est치 construida sobre sqlalchemy. `sqlmodel` es a `sqlalchemy` lo que `FastAPI` es a `Flask`. Por lo tanto, es muy posible que en el tiempo esta librer칤a venga a reemplazar a SQLAlchemy principalmente porque Tiangolo dedica mucho tiempo a la buena documentaci칩n y casos de usos, cosa que SQLAlchemy no tiene tan bien hecho en mi opini칩n.

- **DBI** ((R), Pr: 1): DBI viene a ser una interfaz com칰n para poder consultar datos. Creo que podr칤a considerarse el s칤mil de sqlalchemy, pero no s칠 si tiene tantas funcionalidades. Al menos esta siempre fue mi opci칩n para conectarme a DBs en R, pero nunca me toc칩 modelar una base de datos como s칤 tuve que hacerlo en Python. DBI tiene conexi칩n con casi todos los motores de SQL o usando conexi칩n `odbc`.

- **PyMongo** (Rk: 185, ND: 16.8M+, Pr: 2): Esta es la interfaz para utilizar MongoDB desde Python. MongoDB es probblemente la base de datos no relacional m치s famosa. S칩lo vale la pena si es que te toca trabajar con MongoDB pero lo bueno es que su uso es sumamente intuitivo. Utiliza la misma sintaxis que MongoDB pero en vez de usar el formato BSON (que es como un tipo de JSON), lo hace en los diccionarios de Python. Y por cierto, hacer queries en MongoDB es b치sicamente SQL con otra sintaxis y permitiendo data no estructurada como output, por lo que aprenderla es bastante sencillo.

- **elasticsearch-dsl** (Rk: 732, ND: 2.4M+, Pr: 2): Este no es la librer칤a m치s popular para conectarse a ElasticSearch, que es un motor de base de datos basado en documentos que es extremadamente r치pida. La sintaxis en ElasticSearch es horrible, y yo reconozco que no tengo idea como extraer datos usando ElasticSearch puro. El tema es que elasticsearch-dsl es tan intuitivo que pude generar procesos de ETL en ElasticSearch utilizando esta librer칤a, ya que su API es como estilo dplyr (aunque es una librer칤a de Python), lo que le permite ser muy expresiva y f치cil de crear, leer y entender. Si alguna vez tienes que trabajar con ElasticSearch, usa esta librer칤a ya que es much칤simo m치s sencilla.

- **psycopg2** (Rk: 194 y 99, ND: 31M + 15M, Pr: 0): El Ranking de esta librer칤a es un poco extra침o, la raz칩n es porque si utilizas Windows descargas psycopg2, pero si tienes Mac o Linux descargas psycopg2-binary, por lo que en estricto rigor esta librer칤a es la suma de ambos. Este es el cliente de Postgresql en Python, un motor de base de datos extremadamente popular y poderoso. Es una interfaz muy parecida a DBI en R. Es un cliente lowlevel y bien r치pido para poder interactuar con DBs Postgres. Yo la he utilizado como motor tanto para DBs Postgres Puras o para Datawarehouse como Redshift que est치n basadas en Postgres. Adem치s se puede conectar con `sqlalchemy`, por lo que dir칤a que no es necesario aprender mucho su sintaxis porque saber `sqlalchemy` ya hace la pega.

- **pyodbc** (Rk: 161, ND: 19M, Pr: 0): Es una librer칤a que nos permite hacer conexiones ODBC. Esta librer칤a la us칠 칰nicamente en Windows para conectarme con Teradata que es un motor de Base de Datos que suele ser utilizado en entornos de alta seguridad como Bancos o Retail (mi recomendaci칩n: no usen Teradata, funciona bien, es r치pido y todo pero su documentaci칩n al no ser c칩digo abierto es p칠sima, por lo que cosas f치ciles se pueden hacer pero encontrar c칩mo hacer algo fuera de la com칰n es casi imposible. Se los dice alguien que lo us칩 por 5 a침os). Normalmente se utiliza una l칤nea para conectarse y es compatible con `sqlalchemy`, por lo que no es necesario aprender mucho.

- **Neo4J** ((O), Pr: 2): Debo decir que este tipo de bases de Grafo cambi칩 demasiado mi manera de ver el almacenamiento de datos. Creo, luego de pelear con hartos motores de datos no estructurado que, este es la manera m치s sencilla de interactuar con datos NoSQL. Entre sus grandes pro est치 el hecho de que su sintaxis es muy f치cil de aprender (parecida a SQL, pero no igual), es r치pido, y no requiere joins.

- **rasterio** (Rk: 1454, ND: 749K+, Pr: 0): Esta es una librer칤a para trabajar con rasters. Rasters son las t칤picas im치genes donde cada p칤xel est치 representado como un valor en una matriz/tensor. En el caso de rasterio, tiene m치s utility functions para trabajar con im치genes sat칠litales pero en general se utiliza como complemento a otras librer칤as. Normalmente se utiliza una que otra funci칩n.

- **Xarray** (Rk: 1454, ND: 749K+, Pr: 0): No s칠 si saben pero antiguamente pandas (que deriva de PAnel DAta ), ten칤a data panel, que es son varias realizaciones en el tiempo de un DataFrame, o sea un Pandas de 3 dimensiones. Bueno eso hace un tiempo se quit칩 de pandas y si quer칤as m치s de 3 dimensiones necesitabas Numpy. Bueno Xarray permite la data panel, 3 Dimensiones, pero con nombre del nombres de array. Es una extensi칩n que permite por ejemplo trabajar mejor con Im치genes Multiespectrales (ya que queda capa tiene un significado: RGB, Infrarrojo Cercano, Infrarrojo Lejano, etc.) y normalmente se combinan para poder crear 칤ndices y falsos colores para destacar ciertos aspectos de la im치gen. Es una librer칤a s칰per espec칤fica, por lo que s칩lo ser치 칰til cuando necesites trabajar con este tipo de datos.

- **Geopandas** (Rk: 733, ND: 2.4M+, Pr: 2): Esta es una extensi칩n de Pandas, que incluye dos cosas interesantes a mi gusto, el incorportar shapes: Puntos, Pol칤gonos, etc. Y el hecho de tener joins espaciales. De esta manera puedes combinar datasets si es que comparten mismo espacio, por ejemplo: Tienes puntos (coordenadas) de casas en un csv y tienes pol칤gonos de regiones en otro csv. Al hacer join espacial, unir치 los registros de casas que est치n dentro del pol칤gono regi칩n igual que un join. El tema es que hay varios tipos de join espaciales: dentro, que colinden, que se intersecten, etc. Excelente librer칤a, y no muy dificil de aprender.

- **Scikit-Image** (Rk: 325, ND: 8.6M+, Pr: 0): Esta es una librer칤a de manipulaci칩n de Im치genes, muy parecida a OpenCV. Yo la us칠 una sola vez para intentar reconstruir una foto que romp칤 por error. Bien intuitiva tiene muchas built-in functions para manipular im치genes.

- **Spacy** (Rk: 475, ND: 5.1M+, Pr: 0): Esta es una tremenda librer칤a para lidiar con texto libre. Tiene modelos pre-entrenados muy buenos en muchos idiomas para llegar y utilizar. Yo la us칠 una s칩la vez porque en Cenco ten칤amos info sucia de muchas empresas (y quer칤an sacar promociones en la tarjeta, o algo as칤): "Hipermercados Lider", "Supermercado Lider", "Falabella" , "Tiendas Falabella". Entonces hicimos un Name Entity Recognition para encontrar nombres de potenciales Comercios donde compraba la gente para poder ofrecer descuentos al sacar la tarjeta Cencosud. Por ejemplo, ellos ten칤an descuentos en Cine, y nadie y usaba la tarjeta para ir al cine. Pero s칤 la usaban para Uber, entonces quer칤an cambiar la estrategia a ofrecer no s칠 10 lucas en Uber o algo as칤. Aprend칤 lo que necesitaba en una tarde porque su documentaci칩n es excelente.

- **DBeaver** ((O), Pr: 2): Esta es un cliente de bases Open Source gratis (aunque tambi칠n tiene una versi칩n pagada). B치sicamente es un software que puedes descargar que te permite conectarte a cualquier Base de Datos SQL y muchos otros. Entre los motores disponibles est치n: Postgresql, MySQL, Hive, ElasticSearch, Redshift, Snowflake y Neo4J entre otros. Adem치s, en la versi칩n paga te permite conectarte a MongoDB. Es r치pido, tiene posibilidad de tener los modelos ER de cada Esquema adem치s de varios atajos de teclado. Muy buena opci칩n para conectarse con distintos motores.

# Visualizaciones

Esta es probablemente mi parte m치s d칠bil principalmente porque es un 치rea que no me gusta. A칰n as칤 he usado varias librer칤as, las cuales voy a mencionar ahora.

- **Seaborn** (Rk: 310, ND: 9M+, Pr: 1): Probablemente no esperaban que esta fuera mi primera opci칩n. La raz칩n por la que la menciono en primer lugar es porque es una librer칤a con funcionalidades restringidas pero que hace la pega muy bien. Tiene la mayor칤a de gr치ficos prehechos y permite sin mucho c칩digo hacer gr치ficos muy bonitos y muy expresivos. Mi recomendaci칩n es s칩lo aprender `sns.catplot()` que permite graficar gr치ficos de variables categ칩ricas o combinaci칩n categ칩rica num칠rica (conteos, barplots, boxplot y amigos, etc.), `sns.relplot()` que permite generar gr치ficos para variables s칩lo n칰mericas (scatter, lineplots) y `sns.displot()` que grafica b치sicamente histogramas. Estas 3 funciones tienen interfaz comunes con built-in facet y varias manera de agrupaci칩n (columnas, filas, colores, estilos, etc.). Una de las cosas que m치s me entusiasma es que Seaborn comenz칩 a desarrollar una interfaz muy similar a `ggplot2` de R lo cual la har칤a extremadamente flexible y f치cil de usar. Definitivamente vale la pena aprenderla.

- **Matplotlib** (Rk: 110, ND: 26.9M+, Pr: 1): Yo creo que el ranking es un poco mentiroso, principalmente porque matplolib es dependencia de casi todas las librer칤as de gr치ficos, por lo que siempre la vas a necesitar. Lamentablemente hay que aprenderla. Y digo lamentable, porque a pesar de ser muy poderosa, considero que la documentaci칩n es como engorrosa y tiene una sintaxis muy verbosa. Adem치s `seaborn` est치 construida sobre `matplotlib`, por lo que en casos de querer cambiar elementos del layout en `seaborn` se debe hacer mediante comandos `matplotlib`. Mi recomendaci칩n es aprenderla con ejemplos y alg칰n cursito corto en Datacamp, porque es realmente dif칤cil de aprender (no por su sintaxis sino que porque tiene muchas maneras distintas de hacer lo mismo y que a veces aplican y otras veces no). Igual me he dado cuenta que la termino usando m치s que Seaborn.

- **ggplot2** ((R), Pr: 1): Para muchos es la mejor librer칤a de visualizaciones que existe. Y quiz치s tienen raz칩n. `ggplot2` es un remake de ggplot (que fue un fracaso) y que est치 basado en el grammar of graphics que es un concepto en el cual las partes del gr치fico se construye en capas (la figura; ejes; elementos como puntos, l칤neas, boxplots; c치lculos como regresiones lineales, promedios, intervalos de confianza; etc.) Adem치s como que por defecto la paleta de colores y los ejes son bien bonitos. Yo considero que no es tan f치cil de aprenderla pero es la mejor sintaxis para graficar.
Existen algunas librer칤as/addins en RStudio como `esquisse` que permiten crear ggplots (te entrega el c칩digo incluso) con una interfaz tipo Tableau. Muy recomendada si trabajas en R y/o en Python. Adem치s tiene un enorme ecosistema de librer칤as complementarias para poder graficar casi cualquier cosa.

- **plotnine** (Rk: 2473, ND: 232K+, Pr: 0): Es la versi칩n en Python de ggplot2. Creo que es un tremendo esfuerzo y casi todas las funcionalidades est치n implementadas pero no funciona tan bien como ggplot2 (su ranking lo indica). El problema es que ggplot2 tiene muchos paquetes que lo complementan. Uno de los m치s poderosos es `patchwork` que es una interfaz para crear gr치ficos sobre gr치ficos de manera muy sencilla. Este es precisamente uno de las grandes problem치ticas de plotnine, si se quieren crear layouts un poco m치s complejos comenzamos nuevamente a depender de `matplotlib` lo que evita una sintaxis 칰nica. Gracias a ver visto un EDA por [Martin Henze](https://www.linkedin.com/in/martin-henze/) utilizando ggplot comenc칠 a usar esta librer칤a pensando que podr칤a lograr los mismos resultados, pero lamentablemente ggplot es `muy superior`.

{% include alert info='En mi opini칩n el 90% del tiempo utilizar gr치ficos est치ticos ser치 m치s que suficiente tanto para compartirlos en un PPT o para hacer EDAs. En caso de crear alguna aplicaci칩n interactiva entonces gr치ficos din치micos e interactivos como los que hacen las siguientes librer칤as son una buena opci칩n.'%}

- **plotly** (Rk: 359, ND: 7.5M+, Pr: 0): Plotly es una librer칤a basada en D3, que a su vez es una librer칤a de Javascript que se hizo muy popular gracias a su capacidad de desarrollar gr치ficos interactivos muy bonitos. Hoy tiene APIs en casi todos los lenguajes m치s populares. Para m칤 gusto es una librer칤a que s칩lo vale la pena aprender si es que est치s completamente dedicado a las visualizaciones. Si bien es una librer칤a poderosa es muy verbosa. Afortundamente paquetes como `plotly-express` han aparecido para abstraer la verbosidad y crear versiones de gr치ficos com칰nmente usados en pocas l칤neas.

- **plotly-express** (Rk: 2936, ND: 181K+, Pr: 2): Es la versi칩n menos verbosa de plotly, si bien es un pel칤n menos poderosa debido a que es m치s simple, la mayor parte del tiempo ser치 ma콑 que suficiente. No entiendo por qu칠 no es tan popular a칰n.

- **altair** (Rk: 360, ND: 7.4M+, Pr: 0): Es otra librer칤a muy parecida a Seaborn en t칠rminos de sintaxis pero con la interactividad de plotly. Yo la utilic칠 s칩lo una vez creando una app en Streamlit. La raz칩n: no quer칤a usar plotly (en ese tiempo no conoc칤a plotly express) y quedaban los gr치ficos m치s bonitos que en matplotlib y seaborn que eran est치ticos. No vale la pena aprenderla y rara vez la ver치n por ah칤.

- **bokeh** (Rk: 674, ND: 1.8M+, Pr: 0): Es otra librer칤a proveniente de Javascript que puede ser usadas desde R o Python. La verdad es que no la he usado, pero pueden ser alternativas para plotly ya que tambi칠n son interactivas basadas en HTML pero con una sintaxis m치s simple. Nuevamente las recomiendo s칩lo en caso de dedicarse el BI o al Data Storytelling donde vale la pena invertir en visualizaciones llamativas.

### Otras herramientas BI

- **Tableau** ((O), Pr: 2): En el caso de trabajar en Business Intelligence donde el foco es m치s mostrar herramientas interactivas que puedan manipular la data con algunos clicks, aparecen herramientas que no est치n basadas en c칩digo. Tableau es una muy buena alternativa. Es r치pido, f치cil de crear Dashboard con gr치ficos que sirven como filtros y pueden interactuar entre ellos. El problema, es que su costo es prohibitivo, su licencia es extremadamente cara y hoy existen otras herramientas m치s baratas que hacen lo mismo.

- **PowerBI** ((O), Pr: 2): Es el Tableau de Microsoft. Es una buena alternativa con costos de licencias bastante m치s bajo. Sigue la misma idea de Tableau de usar cajitas tipo Pivot Tables para crear gr치ficos. Igual de eficiente que Tableau pero mucho m치s barato.

- **Qliksense** ((O), Pr: 2): No recuerdo quien cre칩 esto, pero es otra versi칩n. Funciona exactamente igual que los otros dos. Tienen las mismas funcionalidades. Ninguna ventaja ni desventaja con los otros. 

{% include alert tip='쮺u치l elegir? Da lo mismo, es lo que tu empresa est칠 dispuesta a pagar.'%}

- **Shiny** ((R), Pr: 1): Podr칤amos decir que es la versi칩n en R de estos productos. La diferencia es que es gratis, y es basado completamente en c칩digo. Permite crear todo tipo de Dashboards interactivos mezclando cualquier otra librer칤a de R (aunque tambi칠n se podr칤a agregar Python mediante `reticulate`) tanto para manipular datos como para visualizar. Es extremadamente poderosa y flexible y hay varias empresas que crean sus portales utilizando Shiny. El problema es que no es tan f치cil de hostear. En mi tiempo s칩lo RStudio ofrec칤a servicios para hostear ShinyApps (algunos gratis y otros de pago). Lo bueno es que se comenz칩 a crear todo un ecosistema en torno a `Shiny`, el cual tiene temas (basados en Bootstrap, material y otros frameworks de HTML, CSS y Javascript). Adem치s, hay una librer칤a llamada `golem`, que permite modularizar grandes aplicaciones e incluso se permiten ingresar elementos nativos en HTML, CSS o Javascript. Vale completamente la pena aprenderlo <mark>si es que</mark> te dedicas al BI en R y tienes tiempo de crear todo desde cero. Va a ser m치s flexible que Tableau, PowerBI o Qliksense, pero hay que crear todo.

- **streamlit** (Rk: 1361, ND: 853K+, Pr: 1): Similar a Shiny pero en Python. En mi opini칩n es mucho m치s sencillo de utilizar, pero mucho m치s simplista. Tiene lo justo y necesario para hacer funcionar una excelente aplicaci칩n demo. Lo bueno es que Streamlit fue comprado por HuggingFace por lo que se ha estado llevando sus funcionalidades para que sea el front-end de modelos de Machine Learning. Una ventaja de streamlit es que es f치cilmente hosteable en cualquier servidor con Python (que son casi todos), en Heroku, en un servicio provisto por la misma gente de Streamlit o en Huggingface Spaces, siendo estos 칰ltimos totalmente gratis. En el caso de querer hacer una demo, se puede crear algo de gran calidad y complejidad en no m치s de una hora. Su sintaxis es muy sencilla y se puede aprender en unas horas.

- **Dash** (Rk: 1380, ND: 830K+, Pr: 0): Este es casi id칠ntico a Shiny (pero tambi칠n en Python). Yo lo us칠 s칩lo una vez en un proyecto, y no nos gust칩 porque era muy complicado de setear. B치sicamente crear el CSS que dejara los distintos divs en orden fue un martirio por lo que siempre nos quedaba la aplicaci칩n descuadrada. No vale la pena, ya que streamlit simplific칩 esto infinitamente.

- **Gradio** (Rk: 3187, ND: 148K+, Pr: 2): Es una interfaz a칰n m치s simple que Streamlit, pero con muchas menos funcionalidades. Esta librer칤a s칤 que se cre칩 con el s칩lo prop칩sito de ser un IO para modelos de Machine Learning. A diferencia de Streamlit que puedes crear Dashboards, sitios webs, agregar gadgets, Gradio s칩lo le interesa crear gadgets de input/output para un modelo a modo de demo. Yo lo prob칠 r치pidamente y lo encontr칠 muy f치cil. Decid칤 aprenderlo luego de ver una demo de un Pipeline de Transformers por Omar Sanseviero, donde construy칩 un front-end con modelos de Generaci칩n de Texto y Machine Translation en 10 mins. Puedes ver su presentaci칩n [ac치](https://www.youtube.com/watch?v=Mg7YeWBUKbM). Vale mencionar que tambi칠n fue adquirido por HuggingFace por lo que puedes hostearlo facilmente en servidores Python, Heroku o Spaces. La gran ventaja de Gradio es que permite hostear de manera gratuita desde cualquier computador por dos d칤as. Una vez se acabe puedes volver a levantar el servicio, el cual permite el frontend y una API en FastAPI creada autom치ticamente.

- **Django** (Rk: 357, ND: 7.5M+, Pr: 0): No lo he usado. Pero es por lejos la librer칤a m치s poderosa de desarrollo Web. Ac치 ya no hablamos s칩lo de una interfaz de Dashboards sino que un software completo. Es tanto as칤 que existen Ingenieros de Software especializados s칩lamente en el Ecosistema Django. Por nada del mundo como Data Scientist debieras tener que llegar a usar una librer칤a tan poderosa como esta. Pero si te interesa crear una aplicaci칩n a nivel profesional con procesos de datos o Modelos de Machine Learning por abajo, esta podr칤a ser una opci칩n. Algunas aplicaciones creadas en Django son Instagram, Spotify, Youtube, Dropbox, entre otras.

- **Flask** (Rk: 88, ND: 35.9M+, Pr: 0): Tampoco lo he usado, pero tengo entendido que es un Django peque침ito, que adem치s tiene otras funcionalidades como crear APIs. Es a칰n extremadamente popular en entornos de desarrollo web, pero en mi opini칩n est치 poco a poco cayendo en desuso, principalmente debido a que FastAPI est치 ganando mucho protagonismo en cu치nto a APIs se refiere y es una opci칩n mucho m치s sencilla de aprender.

# Machine Learning

Esta es por lejos mi secci칩n favorita, por lo que puede que me extienda un poco m치s de que el resto.

- **Scikit-Learn** (Rk: 94, ND: 32.6M+, Pr: 1): Es la librer칤a por excelencia para crear modelos de Machine Learning. La sintaxis de su API est치 tan bien dise침ada que una manera de reconocer que otras librer칤as de Machine Learning son confiables es si es que siguen su API. B치sicamente `scikit-learn` es super reconocida por sus modelos como Clase y su estandar `fit-transform-predict`, adem치s de casi 15 a침os de vida. Si quieres hacer modelos de Machine Learning s칤 o s칤 tienes que partir por ac치 por varias razones: (1) Su documentaci칩n es excelente, incluso puedes aprender la teor칤a detras de cada modelo leyendo su [User Guide](https://scikit-learn.org/stable/user_guide.html) (toda persona que se dedique al ML deber칤a leer la documentaci칩n completa de Sklearn una vez al a침o 游뱕). Adem치s contiene s칩lo modelos ML que est치n en el estado del arte. De hecho para que un modelo se implemente en Scikit Learn tiene que cumplir [requisitos](https://scikit-learn.org/stable/faq.html) muy estrictos. Andreas Mueller, mantenedor de Scikit-Learn tiene un curso disponible de manera gratuita [ac치](https://www.youtube.com/watch?v=d79mzijMAw0&list=PL_pVmAaAnxIRnSw6wiCpSvshFyCREZmlM). Este es por lejos una de las mejores inversiones que uno har치 como Data Scientist, ya que aprendiendo a utilizar esta librer칤a podr치s utilizar millones de otras basadas en la misma API. [Ac치]({{ site.baseurl }}/titanic/)un ejemplo de modelamiento en Scikit-Learn.

- **tidymodels** (R, Pr: 2): Yo sol칤a ser un fan de esta compilaci칩n de librer칤as. Creo que Max Kuhn es un tremendo desarrollador y lo respeto profundamente, pero creo que parsnip trat칩 de llevar el modelamiento en R a un estado incluso m치s flexible que `scikit-learn` pero no les funcion칩. Lamentablemente el Machine Learning en R est치 disgregado en muchas librer칤as todas con APIs diferentes, por lo que este esfuerzo de unificar todo es incre칤ble. Lamentablemente el memory leakage que sufre R y el tremendo trabajo de los mantenedores de `scikit-learn` hacen que un esfuerzo como este nunca logre la popularidad que tiene Python en este rubro. Tidymodels est치 basado en 3 paquetes principalmente: `recipes`, para el preprocesamiento, que a mi gusto tiene una API muy similar a los Pipelines de Scikit, `parsnip`, que es la unificaci칩n de todos los modelos de ML implementados en R y `yardstick` que contiene todas las m칠tricas de evaluaci칩n. Si te dedicas a hacer modelos peque침itos de prueba, sin mucho intensidad de c칩mputo es una opci칩n, en cualquier otro caso vale m치s cambiarse a `scikit-learn`.

- **caret** (R, Pr: 2): Este es el predecesor de `tidymodels`. A pesar de ser una librer칤a que se le quit칩 mantenimiento hace un tiempo sigue disfruntando de mucha popularidad ya que tiene m치s de 200 modelos implementados. El prop칩sito de Caret es el mismo de tidymodels s칩lo que su API no era compatible con el tidyverse por lo que decidieron seguir el esfuerzo de tidymodels. Este proyecto contaba con todo integrado, preprocesamiento, entrenamiento, postprocesamiento, esquemas de validaci칩n, m칠tricas de evaluaci칩n, incluso ensambles. Por alguna raz칩n lamentablemente decidieron cortarlo.

- **pycaret** (Rk: 1940, ND: 432K+, Pr: 2): Este es un proyecto en Python que nace de la base de Caret y que se ha hecho extremadamente popular. En mi opini칩n s칩lo vale la pena aprenderlo si es que no te gusta codear. Las ventajas es que permite hacer mucho en pocas l칤neas de c칩digo y es compatible con muchas librer칤as externas como XGBoost, LightGBM, etc. Adem치s cuando uno no es experto en tareas menos habituales como Anomaly Detection o Series de Tiempo permite seguir el mismo esquema de c칩digo. Lo que me gusta del creador de esta librer칤a es que 칠l deja muy en claro que su objetivo que es que los Citizen Data Scientist pueden tener modelos de alta calidad a la mano. Creo que est치n haciendo un tremendo trabajo y he visto muchos Notebooks en Kaggle que lo usan y obtienen muy buenos resultados.

- **Feature Engine** (Rk: 3096, ND: 99K+, Pr: 1): Para m칤 esta es una librer칤a de primer칤sima calidad. Tiene muy buen mantenimiento y tiene much칤simos mejores preprocesamiento que Scikit-Learn y adem치s implementados en DataFrames. Contiene muchos de los excelentes encoders que ten칤a Category Encoders y adem치s un Wrapper que permite convertir los preprocesadores de Scikit para que devuelvan pandas DataFrames en vez de Numpy Arrays. Espero que gane m치s popularidad, yo al menos la uso mucho.

- **category-encoders** (Rk: 814, ND: 2M+, Pr: 0): Esta sol칤a ser mi librer칤a de encoders por defecto, pero dej칩 de mantenerse porque los mantenedores se cansaron. En su momento fue muy buena y todav칤a tiene mucha popularidad. Particularmente encontr칠 un par de issues que report칠 pero se demoraron casi un a침o en corregirlo. Una pena.

- **statsmodels** (Rk: 294, ND: 9.6M+, Pr: 2): Si trabajas en Estad칤stica en Python esta es la librer칤a. Yo no soy muy fan de los modelos estad칤sticos, pero igualmente creo que es una librer칤a interesante, porque tambi칠n contiene muchas herramientas para trabajar con series de tiempo. En caso de necesitar mucho poder estad칤stico, creo que R es mucho m치s potente ac치.

- **XGBoost** (Rk: 320, ND: 8.8M+, Pr: 1): Uno de los problemas que Scikit-Learn sol칤a tener es que no ten칤a una buena implementaci칩n de algoritmos de Gradient Boosting (hoy tiene una buena implementaci칩n de HistGradientBoosting similar a LightGBM) y XGBoost quiz치s es la implementaci칩n m치s famosa que hay. Desde el 2014 viene dominando por lejos el modelamiento en data tabular y definitivamente es un algoritmo que hay que dominar. Si bien es cierto su performance es superior, llegar a esa performance es dif칤cil de lograr, ya que hay que hacer un buen afinamiento de Hiperp치r치metros. Definitivamente un algoritmo que hay que aprender.

- **LightGBM** (Rk: 393, ND: 6.5M+, Pr: 1): Me llama la atenci칩n que tenga menos descargas. Porque LightGBM para m칤 supera a XGBoost, por poco pero lo supera. En general para todas las competencias en la que he estado y modelos en producci칩n que he dejado siempre obtengo mejor performance con LightGBM. Esta es una implementaci칩n liberada por Microsoft en 2016, y en mi opini칩n es bastante m치s r치pido que XGBoost y menos complicado de afinar Hiperpar치metros. El problema es la instalaci칩n, las docs de instalaci칩n son malitas, y la versi칩n con GPU es bien enredada de instalar. Definitivamente, hay que tenerlo en el arsenal.

- **CatBoost** (Rk: 747, ND: 2.3M+, Pr: 1): Otro Gradient Boosting que est치 muy de moda. En mi opini칩n es el algoritmo m치s f치cil de afinar. Casi no hay que mover los Hiperpar치metros para obtener muy buenos resultados. Es f치cil de instalar, pero en velocidad es similar a XGBoost. Creo que el 칰nico problema que le he visto es que cuando guardas el modelo es muy pesado. Por ejemplo, una vez entren칠 los 3 Boosting (t칤pico en Kaggle) y no s칠, XGBoost y LightGBM pesaban del orden de megas mientras que CatBoost pesaba 11 GB, no s칠 si habr칠 hecho algo mal, pero encontr칠 que era muy pesado. El otro contra (no tan contra), es que siempre queda fuera de los frameworks, y la API es un poquito diferente a Scikit. (XGBoost y LightGBM tienen versiones con API de Scikit). Definitivamente hay que aprenderlo.

{% include alert info='Lo bueno de los 3 grandes Boosting es que todos tienen Early Stopping y permiten el uso de un set de Validaci칩n mietras se entrena, igual que los algoritmos de Deep Learning.'%}

- **DeepChecks** (Rk: NA, ND: NA, Pr: 2): Yo no lo he usado a칰n en mis pegas, pero he hecho pruebas y revisado a fondo la documentaci칩n y creo que es una excelente librer칤a para estudios previos de la data (chequear potenciales drifts y el potencial poder de generalizaci칩n de un modelo) y para monitoreo. Permite realizar distintas validaciones para entre tu set de entrenamiento y tu data real, o test set para chequear que el modelo funciones bien en el tiempo.

- **Mapie** (Rk: NA, ND: NA, Pr: 2): Excelente librer칤a para aplicar Conformal Prediction, es decir, se pueden generar predicciones con intervalos de confianza en Regresi칩n y Clasificaci칩n probabil칤stica para modelos de clasificaci칩n. Lo bueno es que es solo un wrapper y es Scikit-Learn compatible. Tuve la oportunidad de estudiar la documentaci칩n a fondo y es realmente la manera de generar modelos robustos en especial cuando hay mucha incertidumbre.

- **mlxtend** (Rk: 1024, ND: 1.4M+, Pr: 2): Tremenda librer칤a creada por Sebastian Raschka, profesor de Wisconsin Madison y parte de Lightning AI. Es un complemento a Scikit-Learn y tiene varios elementos que permiten extender las capacidad de Scikit. En particular rescato las herramientas para ensambles tipo Stacking. Muy necesaria si quieres competir, y si quieres un modelo ensamblado.

- **pyGAM** (Rk: 2237, ND: 325K+, Pr: 0): Es una librer칤a que hace modelos GAM (Generalized Additive Models). Estos modelos son famosos por ser la mejor mezcla entre buena predicci칩n y buena explicabilidad. Quiz치s el modelo GAM m치s conocido es `prophet` de Meta. En general esta librer칤a no me gust칩, y si es que realmente quieres meterte en este tipo de modelos mejor utilizar `mgcv` en R que es a침os luz m치s maduro. No creo que valga la pena aprenderlo.

- **CuML** (Rk: NA, ND: NA, Pr: 0): Esta es una librer칤a que est치 a칰n en desarrollo por parte de NVIDIA, pero es la parte de ML de cuDF y cuPY. Es un mirror de Scikit-Learn, pero que corre en GPU. En especial algoritmos como Random Forest y SVM pueden verse muy beneficiados. No creo que valga la pena aprenderlo, porque es lo mismo que Scikit-Learn.

- **Imbalanced-Learn** (Rk: 650, ND: 3M+, Pr: 0): Es la librer칤a por excelencia para desbalance de clases. Lo bueno es que incluye t칠cnicas de undersampling, oversampling, SMOTE y algoritmos propios que funcionan con desbalance como RUSBoost y BalancedRandomForest. Debo confesar que casi nunca obtengo mejores modelos utilizando estas estrategias, y no me ha tocado usarlo a칰n, pero normalmente utilizando el par치metro sample_weigths de cualquier modelo de Scikit-learn podr칤a funcionar mejor.

- **Shap** (Rk: 530, ND: 4.1M+, Pr: 1): Es hoy quiz치s la librer칤a m치s poderosa para dar explicabilidad. Existen varios spin-offs enfocados en problemas espec칤ficos pero creo que es algo que todos deber칤amos dominar porque al negocio siempre le interesa entender por qu칠 un modelo predice lo que predice.

- **ELI5** (Rk: 1022, ND: 1.4M+, Pr: 2): Otra opci칩n para la explicabilidad de modelos. No lo he usado pero sol칤a ser la librer칤a por defecto antes que apareciera el boom de los shap values.

- **Implicit** (Rk: 2761, ND: 207K+, Pr: 2): Librer칤a de Factorization Machines para modelos de recomendaci칩n Implicita. Esta la us칠 una vez para una prueba de Concepto en Cencosud. F치cil de usar, buenos tutoriales, me gust칩. No tengo m치s que decir, porque fue "el uso" que le d칤.

- **Surprise** (Scikit-Surprise) (Rk: 2860, ND: 195K+, Pr: 2): No alcanc칠 a usarla, porque en la misma Prueba de Concepto anterior me d칤 cuenta que ten칤amos un recomendador impl칤cito y Surprise es para modelos expl칤citos. Para tenerlo en cuenta. 

- **LightFM** (Rk: 1920, ND: 441K+, Pr: 2): Esta fue la librer칤a que termin칠 utilizando, debido a su r치pidez. Recuerdo que en ese momento no pude sacarle todo el potencial porque funciona mejor en entornos Unix y obvio, nos obligaban a usar Windows. Tambi칠n para tenerla en cuenta.

- **H2O** (Rk: 1954, ND: 428K+, Pr: 2, (R)): Es una librer칤a que est치 tanto en Python como en R que por detr치s corre una JVM. Es la librer칤a en CPU m치s r치pida que he visto. Yo s칩lo la v칤 en curso en R con Erin Ledell. Es buena para hacer cosas r치pido. Adem치s posee AutoML y Stacking, para los que les guste algo r치pido con poquito c칩digo.

- **Prophet** (Rk: 1367, ND: 848K+, Pr: 2): Hace poco hubo un esc치ndolo porque la empresa Zillow hizo un uso indiscriminado de Prophet entrenando modelos sin entender y eso le signific칩 un impacto muy negativo (pueden leer m치s al respeco [ac치](https://towardsdatascience.com/in-defense-of-zillows-besieged-data-scientists-e4c4f1cece3c)). Pero si se le da un uso correcto, creo que es una tremenda librer칤a. Es f치cil de usar y tienen muchas ventajas. Konrad Banachewicz est치 haciendo un curso de series de tiempo en el canal de [Abishek Thakur](https://www.youtube.com/channel/UCBPRJjIWfyNG4X-CRbnv78A) y habl칩 sobre este modelo, y la verdad lo encontr칠 muy interesante. 칔selo con precauci칩n y bajo su propio riesgo.

- **Neuralprophet** (Rk: 4635, ND: 68K+, Pr: 2): Spin-off de Prophet pero utilizando algoritmos de Redes Neuronales. Mismo cuidado que con prophet.

- **Sktime** (Rk: 2739, ND: 211K+, Pr: 2): Es una extensi칩n de Scikit-Learn para modelos aplicados a Series de Tiempo. Tiene algoritmos propios para clasificaci칩n (de series de tiempos, o sea clasificar un secuencia), regresi칩n, forecast (no es lo mismo que regresi칩n), anomaly detection y tiene varios CV propios de series de tiempo. Yo no la us칠 propiamente tal, pero aprend칤 mucho leyendo su documentaci칩n, en especial para entender la diferencia entre forecast y regresi칩n. Adem치s posee un transformer que permite convertir modelos de forecasting en Regresi칩n. Muy buena librer칤a si trabajas con series de tiempo.

- **Skforecast** (Rk: NA, ND: NA, Pr: 2): Muy similar a sktime pero creada por Joaquin Amat, un data scientist espa침ol. Creo que siempre el trabajo en espa침ol tiene que ser destacado.

- **TSFresh** (Rk: 1888, ND: 456K+, Pr: 2): Yo utilic칠 esta librer칤a como herramienta de feature extraction para series de tiempo. Posee una funci칩n `extract_features` que permite crear much칤simas features para series de tiempo. Muy buena librer칤a.

- **Lifetimes** (Rk: 1473, ND: 731K+, Pr: 2): Librer칤a especializada en Survival Models. Los modelos de sobrevivencia son modelos que buscan estimar el tiempo a un evento. Lo utilic칠 en la competencia de Mercado Libre, pero no me di칩 muy bueno as칤 que segu칤 por otro lado. Es bueno tenerlo como alternativa para tipos de modelaci칩n no tan comunes.

- **Boruta-Shap** (Rk: NA, ND: NA, Pr: 0): Es una librer칤a muy peque침ita que permite utilizar el algoritmo Boruta m치s Shap Values para Feature Selection. Por defecto utiliza un Random Forest para escoger las variables m치s importantes, pero yo lo utilic칠 con XGBoost y LightGBM en GPU y funciona bastante bien.

- **LOFO** (Rk: NA, ND: NA, Pr: 0): Es otra librer칤a de Feature Selection. En este caso la ventaja que ofrece sobre Boruta Shap es que se realiza una selecci칩n utilizando un modelo espec칤fico pero en un esquema de Cross Validation. Esta la utilic칠 en una competencia que ten칤a muchas variables an칩nimas, y funcion칩 bastante bien.

- **Optuna** (Rk: 613, ND: 3.2M+, Pr: 1): Es probablemente la mejor librer칤a de optimizaci칩n que hay hoy. Originalmente permite resoluci칩n de algoritmos de Optimizaci칩n (min, max, minmax). Pero su gran fortaleza es que permite la implementaci칩n de algoritmos Bayesianos de b칰squeda compatibles con modelos de Machine Learning y Deep Learning (agregando Pruning, que permite terminar la b칰squeda en espacios poco prometedores). Es obligaci칩n aprender a utilizarla, 100-200 iteraciones de Optuna es equivalente a una b칰squeda gigantesca en GridSearch o RandomSearch.

- **Scikit-Optimize** (Rk: 613, ND: 3.2M+, Pr: 0): No lo he usado, pero es competidor directo de Optuna. No s칠 mucho m치s pero creo que era necesario mencionarlo.

- **Hyperopt** (Rk: 809, ND: 3.2M+, Pr: 0): Idem al anterior.

- **Scikit-plot** (Rk: 1756, ND: 520K+, Pr: 0): Es en estricto rigor una librer칤a de visualizaciones, pero s칩lo tiene visualizaciones asociadas a Machine Learning. Es muy sencillo de usar y con un comando permite graficar matrices de confusi칩n, curvas ROC, curvas Precision-Recall, Curvas de Aprendizaje, Silhouette, Curvas de Calibraci칩n, etc. Yo comenc칠 utilizandola porque antes los Plot de Scikit-Learn quedaban muy feos. Esto est치 muy mejorado actualmente y recomendar칤a utilizar este tipo de librer칤as s칩lo para curvas muy espec칤ficas.

- **Yellowbrick** (Rk: 1659, ND: 578K+, Pr: 0): Para m칤, hace y tiene exactamente lo mismo que Scikit-Plot. No recuerdo por qu칠 comenc칠 a usar Scikit-Plot por sobre esta.

# Deep Learning

- **Pytorch** (Rk: NA, ND: NA, Pr: 1): Es el framework de Deep Learning de Meta. Quiz치s esto es sorpresivo. Pero la raz칩n por la que Pytorch no est치 en el Ranking es porque se recomienda su instalaci칩n via Conda. Para m칤 (y esto es muy sesgado), es la mejor librer칤a de Deep Learning. Y la raz칩n es porque te permite entender el funcionamiento de una red neuronal de mejor manera que con otros frameworks. El contra de Pytorch es que necesitas mucho c칩digo para entrenar principalmente, pero permite entender muy bien cuando hay que setear los gradientes a cero, en qu칠 parte se eval칰a la loss function, cuando haces backpropagation y actualizas los pesos. Adem치s como te fuerza a utilizar clases permite mejorar tu programaci칩n orientada a objetos y su gran fuerte es la documentaci칩n, muy buena en t칠rminos de uso, pero tambi칠n de teor칤a. Otro aspecto espectacular de Pytorch es que permite el desarrollo de spin-offs que mencionar칠 m치s tarde. 쮼s Pytorch perfecto? la verdad es que no. Como dije antes, es muy verboso y entrenar en Aceleradores es engorroso. Hay que estar consciente en todo momento de si tu tensor vive en CPU o GPU, hay que moverlo manualmente. No, es un cacho. A칰n as칤, creo que es necesario hacer al menos un par de modelos en Pytorch Nativo, ac치 un [ejemplo]({{ site.baseurl }}/pytorch-native/). Si quieres iniciarte en Pytorch, lo mejor es partir por el 60 minutes [Blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html).

- **Pytorch-Lightning** (Rk: 692, ND: 2.7M+, Pr: 1): Pero afortunadamente existe Pytorch Lightning que soluciona todos los inconvenientes de Pytorch Nativo. Permite organizar mucho del excesivo c칩digo de Pytorch y tiene una API que permite escalar a GPUs, TPUs, IPUs y HPUs sin casi ning칰n cambio. Adem치s permite la portabilidad del c칩digo, haciendo que un mismo m칩dulo sea muy f치cil de reutilizar casi sin latencia. Creo que definitivamente Lightning es la raz칩n por la que me enamor칠 de Pytorch. Dentro de los mejores lugares para entender bien el funcionamiento de Pytorch Lightning est치 este el [level up](https://pytorch-lightning.readthedocs.io/en/latest/expertise_levels.html) y una serie de [tutoriales](https://pytorch-lightning.readthedocs.io/en/latest/notebooks/course_UvA-DL/01-introduction-to-pytorch.html) de la Universidad de Amsterdam y [otros m치s](https://pytorch-lightning.readthedocs.io/en/latest/tutorials.html).

- **Tensorflow** (Rk: 181, ND: 17.2M+, Pr: 0): Es el primer framework de Deep Learning liberado por Google en el 2015. Esto no es sesgo. No conozco a nadie que haga sus modelos utilizando Tensorflow. Inicialmente el hecho de tener ejecuci칩n est치tica, hac칤a que fuera muy dif칤cil programar en 칠l, adem치s de que se sent칤a como programar en otro lenguaje distinto de Python. La versi칩n dos permite ejecuci칩n din치mica, para debuggear en tiempo real, pero siento que ya qued칩 muy por detr치s de Pytorch. Ahora, 쯣or qu칠 tiene tantas descargas? Porque se necesita el backend para programar en Keras que s칤 es la manera en que todo el mundo usa Tensorflow.

- **Keras** (Rk: 292, ND: 17.2M+, Pr: 1): Para los que no les gusta complicarse con Pytorch pero igualmente quieren utilizar Redes Neuronales, Keras es la soluci칩n. Es por lejos la API m치s famosa, y m치s sencilla de aprender. Es un poco m치s lento que Tensorflow puro pero se encuentran muchos tutoriales de c칩mo implementar modelos sencillos. Yo comenc칠 a aprender redes neuronales en Keras pero me fui desalentando porque no me gust칩 la documentaci칩n, la encontr칠 muy engorrosa, y adem치s porque empec칠 a confundirme. Hay como 3 formas distintas de implementar modelos, hoy algunas muy parecidos a Pytorch utilizando clases. No hay mejor o peor entre Keras o Pytorch, pero Pytorch est치 ganando mucha popularidad, mientras Tensorflow la pierde. Ac치 tengo un peque침o [ejemplo]({{ site.baseurl }}/keras/) de c칩mo utilizar Keras.

- **Jax** (Rk: 1546, ND: 662K+, Pr: 0): No la he usado, y no est치 en mi agenda aprenderlo, pero puede que gane mucha popularidad. Corresponde a otro framework desarrollado por Google y fue adoptado por DeepMind, por lo que quiz치s debido al tremendo desarrollo que ellos hacen comience a hacerse famoso.

- **Pytorch-Geometric** (Rk: 4190, ND: 86K+, Pr: 2): Es una extensi칩n de Pytorch para trabajar con Redes de Grafos (Geometric Deep Learning). Yo lo encontr칠 dif칤cil de aprender, pero no por el framework sino que las redes de Grafos son m치s enredadas. Para tenerlo en cuenta. Tiene muy buena [documentaci칩n](https://pytorch-geometric.readthedocs.io/en/latest/), por lo que pueden comenzar el aprendizaje por ah칤.

- **Pytorch-Forecasting** (Rk: 4346, ND: 78K+, Pr: 2): Es un spin-off de Pytorch para Forecast utilizando Redes Neuronales. Lo interesantees que tiene varios algoritmos famosos implementados como N-Beats, DeepAR y Temporal Fusion Transformer. Adem치s tiene Dataloaders que est치n dise침ados para tipos de predicci칩n propios de series de tiempo. Yo no la utilic칠 pero s칤 estudi칠 bastante sus docs para ver si pod칤a utilizarla.

- **Pycox** (Rk: NA, ND: NA, Pr: 2): Spin-Off de Pytorch para el uso de Modelos Survival en Deep Learning. Tampoco alcanc칠 a utilizarla, pero tambi칠n para tenerla en el arsenal si usamos este tipo de modelos.

- **torchvision** (Rk: 518, ND: 4.3M+, Pr: 0): Es una librer칤a auxiliar a Pytorch para Visi칩n que provee de datasets, Data Augmentation y algunos modelos preentrenados. Particularmente creo que hoy no vale la pena. Existen otras librer칤as m치s potentes que esta y se demora mucho en incluir cosas nuevas. No vale la pena a mi gusto.

- **Albumentations** (Rk: 2391, ND: 283K+, Pr: 1): Es por lejos la mejor librer칤a de Data Augmentation en Im치genes. No s칩lo es r치pida sino que permite augmentation de Im치genes y Masks. No es muy dificil de aprender y es compatible tanto con Pytorch como con Tensorflow/Keras. Muy buena librer칤a.

- **Kornia** (Rk: 1918, ND: 441K+, Pr: 2): Si bien Albumentations funciona sumamente r치pido, funciona en CPU. Kornia es un Albumentation en GPU, lo cual permitir칤a, es especial en multiple GPU, tener una que se dedique al preprocesamiento. No la he usado, pero est치 ganando mucha popularidad.

- **OpenCV** (Rk: 466, ND: 5.2M+, Pr: 0): Si bien es una librer칤a agn칩stica de Visi칩n, posee algunos modelitos internos que funcionan s칰per bien de manera r치pida para tareas de detecci칩n de objetos, segmentaci칩n, etc. con los que f치cil y r치pidamente puedes impresionar. Yo la uso principalmente junto con Albumentations y es espectacular. 

- **Timm** (Rk: 837, ND: 1.9M+, Pr: 0): Si te dedicas a la Visi칩n Computacional tienes que conocer esta librer칤a, debe tener un par de comandos y su principal funci칩n es descargar modelos pre-entrenados. Principalmente sus modelos son compatibles con Pytorch pero creo que ya se pueden utilizar en Tensorflow/Keras tambi칠n. Lo mejor de esta librer칤a es que en quiz치s un par de semanas de salido una arquitectura estado del arte (SOTA Model) ya va a estar disponible ac치. Puedes encontrar desde MobileNet o ResNets, hasta ViT, ConvNext, EfficientNets, y un largo etc. Otra buena noticia es que Timm se asoci칩 con HuggingFace por lo que muy probablemente ser치 a칰n m치s r치pido ver avances en arquitecturas ultra modernas.

- **Transformers** (Rk: 403, ND: 6.3M+, Pr: 1): Es quiz치s por lejos la librer칤a que m치s r치pido ha crecido en el 칰ltimo tiempo y es mantenida por HuggingFace. Inicialmente estaba enfocada en proveer modelos preentrenados y tokenizers de modelos de NLP. Hoy tiene modelos, de Visi칩n, Audio, y dicen que vienen de Grafos. Yo no la he usado mucho, porque no estoy muy metido en el 치rea de NLP, pero hay que conocerla. Con un par de l칤neas puedes hacer un tremendo transformer estado del arte. Aprovecho de destacar el trabajo que hace la Universidad de Chile que tiene un Bert preentrenado en espa침ol disponible para uso libre, el [Beto](https://github.com/dccuchile/beto).

- **torchinfo** (torch-summary) (Rk: 4030, ND: 93K+, Pr: 0): Es una librer칤a peque침ita que con una funci칩n `summary` permite ver un detalle de la red neuronal: capas, par치metros, tama침o, peso, id칠ntico a como lo permite Keras. Es una funci칩n literalmente.

- **torchmetrics** (Rk: 705, ND: 2.6M+, Pr: 0): Es una excelente librer칤a con m칠tricas de evaluaci칩n para Deep Learning. 쯇or qu칠 no usar las t칤picas de Scikit-Learn? Primero, esta tiene muchas m치s m칠tricas espec칤ficas para NLP, Object Detection y un largo etc. Adem치s estas m칠tricas se pueden ejecutar en GPU o Clusters, dependiendo de la paralelizaci칩n o distribuci칩n, lo cu치l las hacen mucho m치s r치pidas.

# Miscel치neo

- **VSCode** ((O), Pr: 1): Para m칤, el mejor IDE para programar hoy en d칤a, aunque es agn칩stico, puedes programar casi lo que quieras ac치. Principalmente porque es liviano, evita muchas complejidades para trabajar en ambientes aislados (conda o venv). Lo bueno es que es totalmente personalizable, tiene extensiones para todo. De hecho este blog es escrito en Markdown utilizando distintas extensiones que me facilitan la escritura. Otro aspecto para los m치s computines es que puede utilizar keycodes populares como Vim, Emacs o Sublime para usar s칩lo el teclado. En particular VSCode tiene muy buen soporte para Python permitiendo el uso de Notebooks, Scripts o una Consola Interactiva. Adem치s es posible utilizar terminal (aunque incre칤blemente no funciona tan bien en Windows, por eso Linux for the "Win"), tiene soporte de GIT, debugger y un largo etc. Vale la pena, toma un tiempo aprenderlo pero no se van a arrepentir.

- **RStudio** ((O), (R) Pr: 1): Hay que decir que este es por lejos el IDE m치s optimizado para R. Permite instalar librer칤as directo de CRAN, tiene visualizador de Datasets, un sector de Plots, Documentaci칩n incluida, Explorador de Archivos y Terminal. Adem치s tiene integraci칩n con GIT y librer칤as como blogdown (para hacer tu sitio web en R, mi antiguo sitio fue hecho ah칤), bookdown (mi tesis de pregrado la escrib칤 ah칤), etc.

- **Spyder** ((O), (R) Pr: 2): Este es como una r칠plica de Rstudio pero para Python. Inicialmente cuando me mov칤 de Python comenc칠 a utilizarlo, y es bien completo, permite Scripts, tiene extensiones para Notebooks, tiene explorador de variables. A m칤 particularmente me molestaban dos cosas, que se demora en iniciar, y que nunca pude encontrar una paleta de colores para el highlighting. Es una buena opci칩n para programar en un ambiente que est치 dise침ado para ciencia de datos.

- **Pycharm** ((O), (R) Pr: 0): Tambi칠n lo utilic칠 con licencia completa y debo decir que si bien es un IDE enfocado exclusivamente en Python me carg칩. Siento que no est치 pensado para Ciencia de Datos. Es muy pesado, se demora mucho en partir, su configuraci칩n inicial es terrible y al menos a m칤 siempre se me qued칩 pegado. Jetbrains (los creadores de esto) creo que se dieron cuenta que no era lo mejor y crearon un IDE enfocado en Ciecia de datos ([DataSpell](https://www.jetbrains.com/es-es/dataspell/)), pero la verdad no lo he probado. Es tan completo que llega ser abrumante, y nunca pude aprender todo lo que pod칤a eventualmente servirme. Para m칤, no vale mucho la pena.

- **Atom** ((O), (R) Pr: 0): Para m칤 era lejos el mejor IDE para programar, creado por Github. Tiene extensiones, muy buenos atajos de teclado, era r치pido, liviano y ten칤a una extensi칩n llamada Hydrogen que permit칤a tener los resultados de tu c칩digo directamente en el Script de manera muy intuititva y c칩moda. 쯇or qu칠 dej칠 de usarlo? Siento que dejaron de darle tanto soporte luego que Github fue adquirido por Microsoft y favorecieron m치s VSCode. Adem치s luego de usarlo por un rato, comandos simples como `df.shape` tomaba 40-50 segundos, lo cual era inaceptable. Cr칠anme que volver칤a mil veces a utilizarlo si viera que hay soporte y mantenimiento continuo. Una l치stima.

- **GIT/Github** ((O), Pr: 1): Me cuesta creer que a칰n existen muchos "Data Algo" que no usan GIT. Esto deber칤a ser obligaci칩n y requisito siempre. Afortunadamente me toc칩 trabajar en un equipo con muy buenas pr치cticas de desarrollo donde entend칤 la importancia de llevar control de versiones siempre. GIT no es dif칤cil, pero es importante entender conceptos de Commits, push, trabajo en ramas. Adicionalmente llevarlo con Github (u otras variantes como GitLab o BitBucket) y entender conceptos como Pull Request, levantar Issues, Revisiones de c칩digos, approvals, etc. Si no usas GIT/Github, no te sientas mal. Hay empresas gigantes que no lo usan, pero aprenderlo y fomentar su uso te lleva f치cilmente a un nivel m치s alto de calidad. Si quieres aprenderlo tengo una serie de tutoriales que parten [ac치]({{ site.baseurl }}/github/).

- **Docker** ((O), Pr: 1): Hoy por hoy es imprescindible mover a producci칩n todo en Docker. No soy para nada experto en el tema pero puedo crear un contenedor, conectarlo con el mundo real y eventualmente hostearlo en alguna parte. Es por lejos la mejor manera de asegurar reproducibilidad en cualquier ambiente (Unix, Max o incluso Windows con WSL2). Hay que aprenderlo s칤 o s칤.

- **Bash** ((O), Pr: 1): Creo que es sumamente importante conocer un poquito de Bash, en especial para automatizar procesos. Bash es el lenguaje de tu computador y te permite interactuar con 칠l. Algunas cosas interesantes que puedes hacer: Agendar trabajos peri칩dicos de manera autom치tica, mandar correos cuando termine un proceso largo, apagar el computador luego de entrenar un modelo por la noche. No es dificil de aprender, y la mayor칤a de las veces vas a googlear en Stackoverflow para salir del paso.

- **Wandb** (Rk: 791, ND: 2.1M+, Pr: 2): Este es un logger, que si bien permite llevar registro de modelos de ML y DL, funciona mejor en Deep Learning. F치cil de usar, muy linda interfaz y permite llevar registro de Arquitectura, Hiperpar치metros, Curvas de Aprendizaje, ejemplos de Inferencia, almacenar tablas y gr치ficas, etc. Adem치s contiene un sistema de B칰squeda de Hiperpar치metros distribuido usando Hyperband, es decir, se puede entrenar el mismo modelo en distintas m치quinas sin interferir entre ellos y sin repetir b칰squeda, Weights & Biases lleva el control.

- **MLFlow** (Rk: 260, ND: 11.1M+, Pr: 2): La verdad es que MLFlow es igual o mejor que Weights & Biases, pero a m칤 no me gust칩. Encuentro que su documentaci칩n es engorrosa y su API no es tan intuitiva. Hace lo mismo adem치s de poder llevar proyectos y un Model Registry para llevar control de versiones del entrenamiento de tu modelo. Si les interesa aprenderlo, tengo un tutorial [ac치]({{ site.baseurl }}/mlflow/).

- **FastAPI** (Rk: 377, ND: 6.8M+, Pr: 1): Es quiz치s una de las librer칤as m치s r치pidas en Python y es muy f치cil de usar. Primero, est치 hecha por un Colombiano (Tiangolo), es de excelent칤sima c치lidad, muy buena documentaci칩n, muchas funcionalidades, y requiere de poquito c칩digo, 쯤u칠 m치s se puede pedir?. Definitivamente si quieres distribuir lo que sea, data, un modelo de ML, FastAPI es la mejor opci칩n. Es tanto la popularidad que varias librer칤as utilizan esta librer칤a under the hood.

- **Airflow** (Rk: 375, ND: 6.8M+, Pr: 1): Yo creo que a menos que seas Analista de Datos, es una herramienta que hay que aprender. Airflow es un orquestador creado por Airbnb, que permite ejecutar y agendar Scripts para ser ejecutados de manera local o remota. Lo bueno de Airflow es que servicios como AWS, o Astronomer permiten ejecutarlos en entornos autoescalables en Kubernetes, lo cual quita una capa de complejidad, en especial a los que no sabemos c칩mo demonios funciona Kubernetes (un orquestador de contenedores). Airflow se hizo famoso como un orquestador de ETLs, que es compatible con casi todo. Yo lo he usado con: AWS, Spark, AWS Glue, ElasticSearch, MongoDB, SQLAlchemy, Redshift, Postgres. Es tan potente que incluso permite entrenar modelos de ML localmente o en entornos como Amazon SageMaker (aunque no es la opci칩n 칩ptima para ML), de hecho Airbnb cre칩 BigHead para eso, que no ha sido liberado al p칰blico. Creo que su 칰nico contra es que un poco verboso, y tiene harto c칩digo boilerplate. Pero su funcionamiento es impecable.

- **Metaflow** (Rk: NA, ND: NA, Pr: 2): Otro orquestador, pero creado por Netflix, pero que est치 enfocado en llevar modelos de ML a producci칩n. Las ventajas, mucho menos boilerplate que Airflow, no tienes los t칤picos problemas de Xcoms en Airflow, puede ejecutarse local o en AWS mediante AWS Batch, EC2 y Step Functions. Permite automatizar todo el proceso de entrenamiento creando de ser necesarios ambientes anacondas independientes para cumplir con requerimientos de versiones espec칤ficas. No alcanc칠 a utilizarlo, pero me toc칩 leerme toda la documentaci칩n para impulsar su uso.

- **Kedro** (Rk: 2066, ND: 378K+, Pr: 0): Otro orquestador, pero desarrollado por QuantumBlack. Es bien poderoso, en el sentido que permite crear Pipelines de carga de datos, y de entrenamiento de modelos, pero no logr칠 encontrar tantas opciones de escalabilidad. Si bien permite por ejemplo conexi칩n con Sagemaker en AWS, no tiene las opciones m치s avanzadas de escalamiento vertical y horizontal que tiene Airflow y Metaflow. Adem치s lo encontr칠 en su momento un poco verboso, y sus Docs ten칤an errores, que hizo que me costar치 mucho entenderlo. 

- **DVC** (Rk: 1700, ND: 551K+, Pr: 1): Para m칤 es el orquestador m치s liviano, con menos Boilerplate y m치s sencillo de utilizar, pero tiene una cierta inclinaci칩n al entrenamiento de modelos. DVC es m치s que un orquestador, permite llevar registro de versiones de tu data, los cuales normalmente no es posible llevar en GIT; organizar Pipelines, llevar registro de Hiperpar치metros, guardar m칠tricas de performance, etc. Me gust칩 mucho m치s que Airflow, pero para una orquestaci칩n local, aunque podr칤a escalar. Puedes aprender de 칠l en este [tutorial]({{ site.baseurl }}/dvc/).

- **Great-Expectations** (Rk: 429, ND: 5.9M+, Pr: 1): Es un validador de datos. No les puedo explicar lo necesario que es empezar a incluir elementos como estos en nuestros Pipelines de datos. Todas las empresas tienen datos, pero pocas empresas con calidad suficiente para llegar y utilizar. Great Expectations es como una librer칤a de Tests asociados a si los datos cumplen: rangos, tipos, cantidad, distribuci칩n y un largo etc. En caso de no cumplir levanta la alerta dando en detalle qu칠 registros no cumplen con el est치ndar solicitado. Adem치s es compatible con Airflow, por lo que uno puede usar como Gate de Ejecuci칩n si tu data cumple o no los requerimientos de modo de no cargar datos sucios en tus fuentes principales de almacenamiento. Muy buena librer칤a.

- **Pytest** (Rk: 72, ND: 39.4M+, Pr: 1): Librer칤a de Unit Test, algo que los Data Scientist rara vez hacemos. Es muy buena librer칤a, f치cil de usar, aunque es media rara la Documentaci칩n, pero nada que un buen tutorial de Youtube no pueda ense침ar. Todos los pipelines de datos, deber칤an considerar Unit Tests.

- **Hydra** (Rk: 1507, ND: 698K+, Pr: 1): Para m칤 el mejor CLI para modelos de Machine Learning, nacida en el equipo de Research de Facebook, ahora Meta. No s칩lo permite crear comandos personalizados para ejecutar Scripts desde el terminal sino que tambi칠n permite crear configuraciones muy complejas tanto para modelos de ML como para Pipelines en general. Para los que siguen el Blog saben que es de mis favoritas, y pueden ver [ejemplos]({{ site.baseurl }}/hydra/) ac치. Muy buena librer칤a, aunque no es tan famosa a칰n.

- **CML** (Rk: NA, ND: NA, Pr: 0): Es una librer칤a para automatizar procesos con Github Actions. Si les interesa ver en acci칩n pueden chequear [ac치]({{ site.baseurl }}/cml/). No vale la pena aprenderla, son s칩lo un par de comandos y ya.

- **BentoML** (Rk: NA, ND: NA, Pr: 0): Esta es una librer칤a que permite automatizar el Deployment de Modelos de Machine Learning. No la he usado pero he le칤do mucho su documentaci칩n, porque en estricto rigor permite crear de manera muy sencilla un Docker con tu modelo que est칠 listo para entregar al equipo de desarrollo. Tambi칠n crea una API Rest autom치ticamente. Definitivamente voy a estar meti칠ndome m치s en el tema.

- **MLEM** (Rk: NA, ND: NA, Pr: 0): Esta es una librer칤a que me ofrec칤 a probarla en Beta. Hace lo mismo que Bento, pero permite r치pidamente deploy en Cloud (AWS, Azure y GCP y Heroku), para cualquier tipo de modelo, y crea el Docker autom치ticamente. Cuando la v칤 me pareci칩 demasiado m치gica y est치 reci칠n partiendo. Lo bueno es que incluye un curso que se puede tomar de manera gratuita [ac치](https://learn.iterative.ai/).

- **Typer** (Rk: 349, ND: 7.8M+, Pr: 2): Creada tambi칠n por Tiangolo, es un CLI mucho m치s poderoso que Hydra pero con un enfoque general. Su API es muy parecida a FastAPI, muy sencilla y potente. Yo la prob칠 antes de conocer Hydra, pero igual creo que vale mucho la pena.

- **BeautifulSoup4** (Rk: 63, ND: 42M+, Pr: 2): Es una herramienta de Scrapping para poder tomar data de p치ginas web. S칰per potente, ya que tiene mucho del trabajo que uno normal necesita hacer automatizado. Su documentaci칩n es buena y es f치cil de aprender. Si quieres saber c칩mo usarla tengo un tutorial [ac치]({{ site.baseurl }}/dtc/).

- **Boto3** (Rk: 1, ND: 392M+, Pr: 0): Es impresionante la cantidad de descargas de Boto3. Lamentablemente s칩lo ser치 칰til si utilizas AWS. Yo la he usado principalmente para interactuar con S3. Adem치s si instalas `s3fs` y `fsspec` es posible utilizar pd.read_* y .to_* de pandas utilizando un URI de S3 directamente, por ejemplo: `pd.read_csv('S3://bucket/folder/file.ext')`.

- **Joblib** (Rk: 126, ND: 24M+, Pr: 0): Yo lo uso principalmente para serializar modelos entrenados de Scikit-Learn y similares de acuerdo a [esto](https://scikit-learn.org/stable/model_persistence.html).

- **Pickle** (Rk: NA, ND: NA, Pr: 0): Dej칠 de usarlo, porque Scikit-Learn favorece guardarlo en formato joblib.

- **Faker** (Rk: 454, ND: 5.4M+, Pr: 0): Yo s칩lo lo utilic칠 para una prueba de t칠cnica para un candidato. Quer칤a poner la misma data que utilizabamos pero sin entregar informaci칩n confidencial. Faker permite emular info de manera muy real, creando de todo. En ese momento, cree: Nombres, Apellidos, Direcciones, Tel칠fonos, Patentes de Auto, Empresas, y un largo etc. Es sumamente bueno cuando se quiere generar un producto en el cual la data no est치 lista. S칰per 칰til, pero no lo vas a usar siempre.

- **pyyaml** (Rk: 11, ND: 142M+, Pr: 0): No vale la pena aprender m치s que una funci칩n para importar un yaml, esto permitir치 manipular tu `yaml file` como diccionario de Python. De esta manera toda tu configuraci칩n vive en un archivo yaml, y no ensucia tus Scripts.

- **pdbpp** (Rk: 2999, ND: 173K+, Pr: 2): Es un debugger en terminal. Personalmente no me gusta el debugger de VSCode, por eso uso este. Tiene atajos de teclado y es bastante r치pido. Lo recomiendo, aunque no es necesario que lo sepan utilizar.

- **holidays** (Rk: 526, ND: 4.2M+, Pr: 0): Es una librer칤a peque침ita pero muy poderosa (se ve en su ND). Tiene todos los feriados, de todos los pa칤ses de todos los a침os. S칩lo indicas pa칤s, periodo y ya. Yo la utilice para crear features en un [Tabular Playground de Kaggle]({{ site.baseurl }}/kaggle-tps/). Muy 칰til en series de tiempo, pero tiene un m칠todo y ya.

- **Python-Box** (Rk: 1038, ND: 1.4M+, Pr: 0): Es s칰per 칰til, solo envuelves un diccionario con `Box()` y puedes llamar tu diccionario como `dict.key` en vez de `dict['key']`. Ahorras varios caract칠res.

- **beepr** ((R), Pr: 0): Esta es una librer칤a in칰til, pero que me encantaba. Pod칤as agregar sonidos cuando tu c칩digo fallaba o terminaba correctamente (t칤pico sonido de Mario al pasar el n칤vel), lo cual sac칩 m치s de una carcajada en el equipo. 

- **chime** (Rk: NA, ND: NA, Pr: 0): Ser칤a como el equivalente en Python de Beepr. Hay otra librer칤a m치s que ocup칠 que no recuerdo el nombre pero no funcion칩 tan bien.

- **Rich** (Rk: 290, ND: 9.8M+ Pr: 2): Esta es una librer칤a muy poderosa para agregar color a tu terminal. Tiene muchas funcionalidades, barras de progreso, outputs de colores, quiz치s la mejor es que es posible que los errores en Python se rendericen m치s bonitos, para por lo menos frustrarse menor cuando algo falla. Creo que igual vale la pena invertir en una mejor experiencia de usuario cuando crees productos CLI, por lo que vale la pena aprenderla en ese caso. 

- **tqdm** (Rk: 77, ND: 38M+ Pr: 0): Tiene dos funciones interesantes, `tqdm` para envolver un For Loop y tener barra de progreso. Y otra para llamada `progress_apply` que permite barra para el apply de pandas. No te demoras nada en dominarla.

# Librer칤as est치ndar que deber칤as usar/conocer

- **Logging** (Rk: NA, ND: NA Pr: 1): Si vas a automatizar algo en Python, sea cual sea su uso, debes loggear todo. Logging permite generar archivos `.log` que permitir치n analizar a posteriori si un Script termin칩 con 칠xito o no. S칰per 칰til, f치cil de aprender, tiene s칩lo un par de comandos para indicar 칠xito, info, warning, errores. Puedes combinar con chime y con Rich para tener un producto multicolor y sonoro. Hace m치s agradable la pega.

- **requests** (Rk: 5, ND: 194M+ Pr: 0): Sirve para conectarse a una API o en combinaci칩n con BeautifulSoup para obtener el HTML de un sitio WEB. Yo la he utilizado s칩lo para eso y no cuesta nada aprender a utilizarla, aunque quiz치s si debas entender el output que normalmente es un string con HTML o string con arreglos de diccionarios anidados si proviene de una API. 

- **glob** (Rk: NA, ND: NA Pr: 0): Permite revisar directorios utilizando s칩lo el comando `glob` y un path con expresiones regulares simples. S칰per 칰til, por ejemplo, cuando tienes que importar muchos archivos en un s칩lo pandas DataFrame.

- **json** (Rk: NA, ND: NA Pr: 0): Yo lo he usado para convertir el output de requests en diccionarios y para guardar outputs como json. S칩lo eso!

- **pathlib** (Rk: NA, ND: NA Pr: 2): Esta es una librer칤a bien interesante para poder automatizar la creaci칩n de directorios y llevar tus Path de manera m치s sencilla. Puedes manipular Path combinandolos, creando Paths m치s sencillos y crear o eliminar carpetas dentro de ellos. Es f치cil de utilizar y tengo ejemplos de ello en mis tutoriales de [DVC]({{ site.baseurl }}/dvc/).

- **getpass** (Rk: NA, ND: NA Pr: 0): Esta librer칤a tiene una funci칩n llamada `getpass`, que funciona como un Text Input pero con los caract칠res ocultos. 칔til para ingresar data que no quieres que se vea, pero no la encripta ojo.

## Uff
{: .no_toc }

Y con esto terminamos. Debo decir que este es al art칤culo que m치s trabajo me ha dado. Y demor칠 cerca de dos meses en escribirlo. Voy a tratar de ir llenando esto con el tiempo a medida que vaya probando m치s cosas. Algunas de las tecnolog칤as que se me quedaron en el tintero porque no cumplen los requisitos exigidos arriba:

* Varios servicios AWS
  * Sagemaker
  * AWS Lambda
  * API Gateway
  * Step Functions
* [PRegex](https://pregex.readthedocs.io/en/latest/)
* [Dagshub](https://dagshub.com/)
* [poetry](https://python-poetry.org/). Por alguna raz칩n me da terror instalarla, aunque he le칤do bastante de ella.
* [fancyimpute](https://pypi.org/project/fancyimpute/)
* [NGBoost](https://stanfordmlgroup.github.io/projects/ngboost/)
* [SKLego](https://scikit-lego.readthedocs.io/en/latest/)
* [tabnet](https://github.com/dreamquark-ai/tabnet)
* [UMAP](https://umap-learn.readthedocs.io/en/latest/)
* [Segmentation Models](https://github.com/qubvel/segmentation_models.pytorch)
* [NannyML](https://www.nannyml.com/)
* [DGL](https://www.dgl.ai/)
* [BioPython](https://biopython.org/)
* Ecosistema Pytorch :
  * [torchtext](https://pytorch.org/text/stable/index.html)
  * [torchaudio](https://pytorch.org/audio/stable/index.html)
  * [torchgeo](https://torchgeo.readthedocs.io/en/stable/)
  * [Pytorch Geometric Temporal](https://github.com/benedekrozemberczki/pytorch_geometric_temporal)
  * [torchrec](https://pytorch.org/torchrec/)
  * [Pytorch Video](https://pytorchvideo.org/)

Espero que esto sea de utilidad para tenerlo como referencia a la hora de enfrentar distintos problemas en Ciencia de Datos.

Nos vemos,

[**Alfonso**]({{ site.baseurl }}/contact/)
