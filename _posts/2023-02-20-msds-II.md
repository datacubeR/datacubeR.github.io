---
permalink: /msds/ 
title: "쮻칩nde Aprender Ciencia de Datos?"
subheadline:  Sino, 쮻칩nde?
teaser: 쯌ale la pena tomar un Master para capacitarse en Ciencia de Datos?
# layout: page-fullwidth
usemathjax: true
category: ds
header: no
image:
    thumb: msds/graduado.jpg
tags:
- tutorial
published: true
---

![picture of me]({{ site.urlimg }}msds/graduado.jpg){: .left .show-for-large-up .hide-for-print width="300"}
![picture of me]({{ site.urlimg }}msds/graduado.jpg){: .center .hide-for-large-up width="250"}

 쯇or qu칠 siquiera molestarse en volver a la Universidad si hay tantos cursos por ah칤 que me permiten aprender lo mismo o m치s sin tener que pasar por el estr칠s de la Universidad? Eso es lo que deber칤a haber pensado antes de entrar a <!--more--> la UAI. 
Acabo de terminar mi ~~primer~~ segundo semestre en el MSDS de la Universidad Adolfo Iba침ez, pero 쯌ale la pena el costo? 쯌ale la pena volver a la Universidad para aprender de Ciencia de Datos?

<q>Actualizado 2023</q>

Bueno yo soy de las personas que cree que existen muchos recursos para aprender Ciencia de Datos. Y est치 lleno, algunos de los que yo he utilizado:


{% include alert info='A diferencia de lo que algunas personas muy reputadas en Linkedin puedan pensar yo s칤 creo que es importante programar de manera excelente. Ya que lo que menos uno puede hacer como Cient칤fico de Datos es darse el lujo de desperdiciar recursos por no tener la habilidad suficiente para llevar a cabo una buena implementaci칩n.'%}

* Google + Stackoverflow (no necesariamente para aprender Ciencia de Datos pero para poder implementar algo)
* Datacamp
* Youtube
* Stanford Artificial Intelligence Professional Program
* Coursera
* Udemy
* Contribuyendo en Open Source



En este art칤culo, me gustar칤a contarles cu치l ha sido mi experiencia con estos cursos, cu치les tengo ah칤 esperando a tener tiempo libre y si vale la pena hacer lo que estoy haciendo: El`MSDS`.

## Google + Stackoverflow

Creo que esto es algo transversal para cualquier programador. Siempre que existan dudas de c칩mo implementar algo lo mejor es Googlear. De hecho, me pas칩 de que cuando tuve la oportunidad de estar a cargo de un equipo de Data Science para m칤 es mejor que alguien no sepa, pero sepa Googlear a que *"se las sepa todas"*. Rara vez uno conocer치 todo lo que necesita para una implementaci칩n o para solucionar un error de c칩digo. Creo que hoy en d칤a aprender a Googlear y a elegir cu치l de todas las respuestas de Stackoverflow es la m치s apropiada, es un skill que hay que desarrollar. Con una googleada y 2 o 3 links y ya mi problema deber칤a estar solucionado (a menos que sea un problema muy raro y hay que incluso meterse en el Github del autor de la librer칤a).

**Mi recomendaci칩n:** Es bueno saber googlear, usar palabras claves, comandos de b칰squeda espec칤fica de Google y ser capaz de r치pidamente discernir qu칠 respueta de Stackoverflow es la m치s apropiada. A eso le sumar칤a conocer las documentaciones de sus librer칤as, cu치les son confiables y cu치les no tanto. **Ej:** Pandas, Scikit-Learn, Pytorch son librer칤as con excelente documentaci칩n y que es muy f치cil encontrar algo. Por otro lado, Tensorflow (no me maten), Pytorch Lightning, Statsmodels, son como documentaciones enredadas, dif칤ciles de seguir. No s칠 si han entrado a la Documentaci칩n de SQLAlchemy o Pytest, esas son imposibles. Entonces, si la documentaci칩n es buena ir directo ah칤, sino, Stackoverflow al rescate.

{% include alert warning='Hay otro tipo de documentaci칩n que est치 haciendo bien popular [Tiangolo](https://www.linkedin.com/in/tiangolo/) en librer칤as como SQLModel, Typer o FastAPI que es como un arma de doble filo. Es como en modo historia/tutorial que para aprender la librer칤a est치 espectacular, pero cuando quieres buscar una funcionalidad espec칤fica nunca sabes donde buscar. Pero bueno estamos hablando de otra cosa.'%}

## Datacamp

Creo que he tomado suficientes cursos como para hablar con propiedad: tengo 37 Cursos en Python m치s el Track de Machine Learning Scientist y ML Fundamentals adem치s de 18 en R. No les voy a mentir, no es un curso que sea incre칤blemente dif칤cil y en el que vayan a volverse expertos, pero quita el miedo, y les ayuda a soltar la mano para *codear* r치pido. Yo aprend칤 Python en Datacamp, ven칤a de s칩lo saber R, y aprend칤 Pandas, Scikit-Learn y Python Base a un nivel bastante decente. Eso junto con empezar a implementar cosas fue lo que m치s confianza me di칩 en Python.

Ahora, hay cursos muy buenos como los de Pandas y Scikit-Learn (no todos, pero la mayor칤a), pero encontr칠 particularmente malos los de Matplotlib y Seaborn, m치s que ayudarme a entender la librer칤a me ayudaron a confundirme m치s. Adem치s, tom칠 por ah칤 un curso de GIT y de UNIX que fueron bastante buenos para perder el miedo a estas tecnolog칤as.

**Mi Recomendaci칩n:** Creo que este tipo de cursos s칩lo vale la pena para gente que no conoce una tecnolog칤a y quieres perderle el miedo. Si bien yo pagu칠 dos veces la suscripci칩n anual a Datacamp, no creo que lo volver칤a a hacer. Si te quieres iniciar en R o Python (creo que ahora tambi칠n tiene SQL y Tableau) vale completamente la pena. Si t칰 intenci칩n es especializarte, entonces te vas a aburrir.

## Youtube

Para m칤 es casi mi fuente primaria de sabidur칤a. Obviamente hay de todo y hay que saber filtrar. No tengo las respuestas de todo y probablemente va a depender mucho de cu치les son tus intereses para aprender. Yo puedo compartir los youtubers que m치s sigo para algunos de mis temas:

* Probabilidad y Estad칤stica y Teor칤a en General: [Statsquest](https://www.youtube.com/c/joshstarmer), por lejos lo mejor. A algunos les pueden molestar sus canciones, pero vale la pena aguant치rselas porque el contenido es muy bueno. Y uno que encontr칠 para algebra lineal que es espectacular [3Blue1Brown](https://www.youtube.com/c/3blue1brown) recomendado por mi amigo [츼lex 츼lvarez](https://www.linkedin.com/in/alex-%C3%A1lvarez-l%C3%B3pez-a561ba164/).
* Python Miscel치neo: [Python Engineer](https://www.youtube.com/c/PythonEngineer), [Sentdex](https://www.youtube.com/c/sentdex)(aunque no me gusta mucho en aspectos m치s te칩ricos, es medio chamuyento).
* Deep Learning en Espa침ol: [Sensio](https://www.youtube.com/c/sensio-ia), lo mejor que hay en espa침ol.
* Machine Learning y Deep Learning: [Abishek Thakur](https://www.youtube.com/c/AbhishekThakurAbhi), s칰per buen contenido del primer Cu치druple Kaggle GrandMaster.
* Otros canales buenos: 
  * [ArjanCodes](https://www.youtube.com/@ArjanCodes) es un canal miscel치neo de muchas cosas pero todas en Python. He aprendido muy buenas pr치cticas de dise침o de software viendo este canal. Y el tipo explica muy bien.
  * [HuggingFace](https://www.youtube.com/@HuggingFace) es una joyita bien escondida. 
  * [AI Epiphany](https://www.youtube.com/c/TheAIEpiphany), es un canal mucho m치s avanzado de Aleksa Gordic, un cabro que hoy est치 trabajando en DeepMind. Creo que tanto su canal como su Github tiene mucha info de lo 칰ltimo en Deep Learning.
  * [Aladdin Persson](https://www.youtube.com/c/AladdinPersson), es un canal s칰per denso igual, casi siempre son implementaciones de Papers.


* Cursos de Deep Learning: Canales de Stanford principalmente. 
  * CS229 [2018](https://www.youtube.com/watch?v=jGwO_UgTS7I&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU) y [2019](https://www.youtube.com/watch?v=KzH1ovd4Ots&list=PL4YhK0pT0ZhVf4nIsEjcRT5K47K7WH76P)
  * [CS224N](https://www.youtube.com/watch?v=rmVRLeJRkl4&list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ)
  * [CS224U](https://www.youtube.com/watch?v=rha64cQRLs8&list=PLoROMvodv4rPt5D0zs3YhbWSZA8Q_DyiJ)
  * [CS224W](https://www.youtube.com/watch?v=JAB_plj2rbA&list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn)
  * [Uva Deep Learning](https://www.youtube.com/channel/UCpvn0ycxIA6Uf8W00OX3frQ)
  * [Transformers United](https://www.youtube.com/playlist?list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM) (no lo he visto a칰n)
  * HuggingFace Course: Ac치 tienen varias opciones. Yo estoy en este momento tomando el de NLP, pero no me hab칤a percatado del beneficio de este curso en part칤cular porque se explica demasiado bien el por qu칠 funcionan los transformers.
    * [Curso Transformers](https://huggingface.co/course/chapter1/1).
    * [Curso Reinforcement Learning](https://huggingface.co/deep-rl-course/unit0/introduction)
    * [Diffusion Models](https://github.com/huggingface/diffusion-models-class)
  * etc.

**Mi Recomendaci칩n:** Suelo utilizar Youtube para contenido m치s denso, que no siempre entiendo de un paper o un libro, por lo que prefiero que alguien me lo explique. Para dudas de programaci칩n, normalmente googleo.


## Artificial Intelligence Professional Program

Este es el programa que estoy a punto de terminar en la Universidad de Stanford. B치sicamente te entregan un pool de cursos y t칰 debes tomar 3. Yo tom칠 `XCS229` que es el curso de Machine Learning de Andrew Ng, `XCS224W` que es el curso de Jure Leskovec de Redes Neuronales de Grafos y `XCS224N` que es el de Chris Manning de NLP y Transformers. 

Estos son por lejos los mejores cursos que he tomado. He aprendido much칤simo tanto te칩ricamente, como en implementaciones pr치cticas. Son cursos basados en los cursos dictados en postgrado en Stanford, con las mismas tareas que se dan en el Campus. Son cursos densos, te칩ricamente muy profundos, y las tareas son muy dif칤ciles, normalmente tienen parte te칩rica para probar la matem치tica detr치s e implementaciones en Python (ML implementa en Numpy desde cero y en DL con Pytorch).

**Mi Recomendaci칩n:** Este tipo de cursos se toman s칩lo si te gusta sufrir. Me tom칩 cerca de 2 a침os tomar los 3 cursos, toman un trimestre cada uno, y adem치s son muy caros: ~~US$1595~~ US$1700 y ojo que si no estudias te los puedes echar. Hay alta tasa de deserci칩n y no se devuelve el dinero. Lo que s칤, quedas certificado por la Universidad de Stanford y recibes Certificados y un registro de la Universidad.

## Coursera y Udemy

Este es el cementerio de cursos m치s grandes que tengo, en especial de Udemy. En Udemy, hay harto curso malo, y que luego de un par de videos te das cuenta que no vas a aprender nada nuevo. Yo tom칠 unos de Pytorch que me gustaron y unos de una librer칤a llamada Feature Engine, aunque a칰n me queda uno esperando de MLOps dado por la misma autora. En Coursera, dado que son m치s caros, tengo muchos ah칤 que tom칠 completos, pero sin las tareas. Los mejores cursos a tomar en Coursera son definitivamente cualquiera de *Deep Learning AI* y uno que se llama *How to Win a Kaggle Competition*, que hoy es muy dificil de encontrar porque es dada por una Universidad Rusa y debido a la guerra no est치 disponible para nuevos estudiantes. *How to Win a Kaggle Competition* tiene todos los trucos habidos y por haber de ML cl치sico: EDA, Preprocesamiento, Tuning de Hiperpar치metros, un detalle de todos los modelos m치s comunes, Data Leakage, Cross Validation, Ensambles. 

**Mi recomendaci칩n:** En Coursera, tomar los de Deep Learning AI. Son much칤simos, pero valen la pena aunque sean en Tensorflow (El de GANs es en Pytorch). Y no s칠, en mi opini칩n son cursos dif칤ciles y caros, entonces si hay algo que realmente quieres aprender dale, porque son en general de muy buen nivel. Respecto a Udemy, no s칠, tomarlos bajo tu propio riesgo, es muy alta la chance de salir decepcionado.

## Contribuyendo en Open Source (Nuevo)

Esto es algo nuevo para m칤. Y tengo que agradecer a [Sole Galli](https://www.linkedin.com/in/soledad-galli/) por animarme a hacerlo. Ella es la mantenedora de Feature Engine y me animo a solucionar un bug que encontr칠 en la librer칤a el a침o pasado. Fue genial porque es super presente en las revisiones y en las sugerencias de donde hacer las correcciones. Sigo contribuyendo regularmente a la librer칤a y creo que el mayor aprendizaje es en buenas pr치cticas de programaci칩n y uso de Git.

## 쯏 el MSDS?

Bueno el Master of Science in Data Science (MSDS, igual es como malo el nombre), es un Magister Acad칠mico, es decir, est치 enfocado en quedarse idealmente investigando y/o eventualmente tomar el Doctorado en Data Science. 쯇or qu칠 lo tom칠? No voy a mentir, por el cart칩n. Yo soy solo egresado de Ingenier칤a Civil (y tengo mi licenciatura en Ciencias de la Ingenier칤a), pero es algo que siempre me sacan en cara. A칰n as칤, Jooycar confi칩 en m칤 y me dio la oportunidad de ser Head de Data Science y creo no haberles fallado. Pero en general el cart칩n pesa. Ahora, yo tuve que entrevistar varios tipos con Magister y no les encontr칠 nada especial. Es m치s, incluso algunos sab칤an menos que un Data Scientist con un par de a침os de experiencia.

La siguiente pregunta es: 쯇or qu칠 en la UAI? Bueno, v칤 varias opciones, y Magister en Data Science propiamente tal s칩lo encontr칠 la UAI y la Universidad de Chile. Y la UAI me bec칩, por eso en la UAI. No creo que haya una gran diferencia entre ambas universidades. La otra opci칩n que ten칤a era tomar un Msc. en Inform치tica y armar mi malla con ramos en Ciencia de Datos. Pero la UAI me bec칩 y aqu칤 estamos.

La decisi칩n fue tomada en conciencia de que probablemente no aprender칤a nada nuevo. Esto, luego de ver un video de [Mark Tennenholtz](https://www.linkedin.com/in/mark-tenenholtz-173a3a122/) (Kaggle Master) que est치 haciendo su Master en Georgia Tech y dijo estar aprendiendo incluso menos cosas de las que ha aprendido en Kaggle. Bajo eso, dije bueno: <q>No pierdo nada en intentar estando becado</q> y ~~me he sorprendido para bien, he aprendido m치s de lo que esperaba,~~ me encant칩. La verdad es que termin칠 aprendiendo demasiado de cosas que jam치s pens칠 que fueran tan 칰tiles. Ac치 dejo un detalle de todos los ramos que tom칠, sin pelos en la lengua.

### Primer Semestre

* **An치lisis Geoespacial** (Prof. Moreno Bevilacqua): Creo que fue el ramo que m치s me gust칩 del primer semestre. Es b치sicamente estad칤stica avanzada enfocado en Campos Aleatorios. No s칠 si alguna vez utilice esto, pero la cantidad de estad칤stica multivariada que aprend칤 es impagable. Este tipo de an치lisis permite ajustar modelos en el espacio y espacio-tiempo para luego generar predicciones (Kriging). El ramo lamentablemente se hace en R, pero utilizamos la librer칤a que cre칩 el profe adem치s de implementaciones hechas de manera manual. S칰per buena mezcla entre teor칤a dura y c칩digo.

* **Current Trends in Data Genomics** (Prof. 츼lvaro Cort칠s): Este es quiz치s el ramo m치s interesante. A m칤 no me mat칩 principalmente porque no me gusta la Biolog칤a, pero b치sicamente nos ense침aron lo 칰ltimo en an치lisis gen칠tico tanto de ADN como de ARN. Adem치s lo interesante es que el profe nos hizo clases desde B칠lgica (KU Leuven) y nos di칩 acceso a un Supercomputador (HPC Cluster), lo cu치l fue una tremenda experiencia (trabajamos con Clusters con hasta 384 Nodos). Es sumamente interesante saber c칩mo se pueden detectar mutaciones, c치nceres, variantes gen칠ticas, etc. Es una clase de harta teor칤a, nos hicieron leer varios papers, pero quiz치s lo mejor fue que justo en la mitad del curso se liber칩 el art칤culo indicando que finalmente se pudo secuenciar el Genoma Humano completo, lo cual fue entretenido, porque gracias al curso pudimos entender el alcance de este trabajo. Finalmente (y eso que el curso no me mat칩), el trabajo final consisti칩 (en mi caso) en investigar acerca de un Modelo de Red Neuronal de Grafos para el proceso *de novo assembly*, para poder generar Genomas de especies en las que no se tiene referencia. Realmente fue un joya tener un curso as칤 aunque es dif칤cil que alguna vez lo llegue a aplicar.

* **Percepci칩n Remota** (Prof. Javier Lopat칤n): Otro ramo que me gust칩, y el tema en el que estoy haciendo mi tesis. Al principio el nombre no parec칤a muy atractivo, pero termin칩 siendo s칰per interesante. Principalmente la percepci칩n remota se encarga de utilizar im치genes que pueden ser sat칠litales, de drones, de aviones y un largo etc. para poder detectar cosas. Esto lo encontr칠 s칰per interesante, porque el ramo es en Python, es sumamente aplicado, y adem치s pudimos utilizar librer칤as de manipulaci칩n de im치genes para calcular muchas cosas: pendientes, sombras, altitud. Aprendimos librer칤as s칰per cool como rasterio, xarray, geopandas y es un tema s칰per interesante (por eso mi tema de investigaci칩n), entre otras cosas, por el cambio clim치tico. El ramo ense침a todo lo te칩rico en cu치nto a qu칠 informaci칩n se puede extraer de im치genes hiperespectrales (o sea tienen m치s canales que el RGB) y m칠todos de Machine Learning en Clasificaci칩n, Regresi칩n y Series de Tiempo (aunque es s칩lo una pincelada). **SPOILER**: Estoy trabajando en el uso de Deep Learning para Anomal칤as en Series de Tiempo de Im치genes, s칰per choro.

* **T칩picos en Data Management y Data Analytics** (Nombre fancy para Bases de Datos) (Prof. Miguel Romero): Este pens칠 que ser칤a el ramo m치s aburrido de la vida pero termin칩 siendo s칰per interesante. Aprendimos SQL (y s칤, aprend칤 cosas nuevas de SQL que no sab칤a, como consultas recurrentes, 칤ndices, y uno que otro truquito de queries), aprend칤 Mongo (yo igual hab칤a usado mongo, pero siento que el curso ense침a varias cosas bastante avanzadas que no sab칤a) y lo que m치s me gust칩 fue Neo4j. Neo4j es una base de datos de Grafos, que realmente cambi칩 mi manera de ver la organizaci칩n de la data. Sirve tanto para data estructurada como no estructurada y es poderoso y r치pido, y adem치s permite aplicar proyecciones y algoritmos como PageRank. Definitivamente voy a estar subiendo un tutorial de Mongo y Neo4j. Si bien no esperaba mucho de este curso, que de paso es obligatorio, termin칠 aprendiendo much칤simo.

* **T칠cnicas Estoc치sticas y Estad칤sticas en Data Science** (nombre fancy para estad칤stica b치sica) (Prof. Leopoldo Bertossi): Quiz치s el ramo m치s decepcionante, y no creo que sea por la materia sino por el Profe. Realmente la pasamos mal en este ramo, es estad칤stica b치sica, y realmente aprend칤 conceptos muchos m치s robustos en estad칤stica, variable aleatoria discreta sobre todo, redes de Bayes, algo de Markov, y un poquito de teor칤a de Informaci칩n, pero no volver칤a a tomar este ramo con el mismo profe. Explica bien, pero nunca entendimos lo que preguntaba en las evaluaciones, y lo pasamos mal, era bien pesote. Lo voy a dejar ah칤. Lamentablemente es un ramo obligatorio y que no vale la pena, ya que aprend칤 mucha m치s estad칤stica en An치lisis Geoespacial.

### Segundo Semestre

Durante el segundo semestre tom칠 los siguientes ramos:

* **츼lgebra Lineal y Optimizaci칩n para Data Science (Prof. Miguel Romero)**: Este fue el curso cortacabezas, bien denso teoricamente pero probablemente el mejor curso que he tomado de teor칤a asociada a Data Science. El curso es una joya, especialmente porque est치 dividido en dos partes: Algebra Lineal, creo que en el Algebra Lineal de pregrado rara vez se aborda el entendimiento de Operaciones Matriciales como Transformaciones Lineales que llevan de una dimensi칩n a otra (que es la base del funcionamiento de las redes neuronales). El curso no s칩lo cubre en detalle toda la parte matricial incluyendo interpretabilidad de operaciones, calculo diferencial y optimizaci칩n de funciones matriciales, pero tambi칠n toca en detalles algoritmos basados en operaciones tipo Valores Propios como son PageRank, PCA y SVD. Y una segunda parte de Optimizaci칩n que cubre desde Optimizaci칩n Convexa hasta Optimizaci칩n No Convexa, incluyendo algoritmos como SGD, Momentum, Nesterov, Adagrad, Adadelta, RMSProp y Adam. El curso es muy bueno pero dif칤cil. Las pruebas son de corte m치s te칩rica, incluyendo algunas demostraciones no tan complejas, pero que hay que pensarlas igual, y las tareas son m치s de c칩digo implementando todo en Numpy. Muy buen curso.

* **M칠todos de Aprendizaje de M치quina en Data Science (Prof. Raimundo Sanchez)**: Este fue un ramo obligatorio (y el que pas칠 con la peor nota 游땍) y la verdad no me gust칩 mucho. Siento que no es un curso en el que se ense침e modelamiento (para ser justos hubo otra secci칩n donde se entr칩 en m치s detalle) pero no se entr칩 en el detalle que esperaba (como s칤 se hizo en Algebra Lineal). El profe muy simp치tico, pero hubo tres cosas que me molestaron particularmente: Una que el curso se hizo en R y `tidymodels` (luego de usar Scikit-Learn se nota que R es realmente malo para Machine Learning. La documentaci칩n es p칠sima, los errores son muy confusos y no hay mucha ayuda en StackOverflow, adem치s de que la librer칤a es muy lenta. De hecho fue tanto as칤 que para la 칰ltima tarea se permiti칩 el uso de Python porque la 칰ltima entrega requer칤a del uso de un dataset de 1M de registros y `tidymodels` sencillamente no daba a basto. Segundo, realmente como un curso de post-grado era absolutamente necesario entrar en los detalles m치s m칤nimos y descomponer las ecuaciones detr치s de cada modelo. Humildemente creo que la documentaci칩n de Scikit-Learn es m치s profunda que la clase. Finalmente, me pareci칩 que las pruebas eran muy de opini칩n, muy subjetivas, casi apreciativas, y no creo que sea la mejor forma de evaluar este tipo de curso. En general, no me gust칩 mucho el curso, pero bueno, no me fue tan bien y puede sonar a picado 游땒. 

* **Seminario de Tesis (Prof. Tamara Fern치ndez)**: Este curso fue un desperdicio. Pero espero se entienda bien. No porque el curso fuera malo, sino que porque desaprovechamos una profesora de talla mundial en un curso Online. Creo que ella intent칩 hacer lo mejor que pudo enfoc치ndose en cosas que son sumamente 칰tiles para la investigaci칩n: Aprender a buscar papers, crear documentos acad칠micos, utilizar Latex, y algunas herramientas de mucha utilidad para alguien que quiere investigar. Lamentablemente en mi opini칩n perdimos demasiado tiempo en comandos b치sicos de Latex, que son googleables, y no tuvimos la oportunidad de aprovechar a la profe. Digo esto porque la actividad final del ramo fue dise침ar un p칩ster del trabajo de tesis, que a m칤 en particular me sirvi칩 mucho para poder ordenar mis ideas y encaminar sumamente bien mi tesis (que va avanzando bastante bien), pero tambi칠n tuvimos la oportunidad al finalizar la sesi칩n de quedarnos conversando con ella y aprender much칤simo sobre su experiencia estudiando en Oxford, su trabajo con su supervisor [Yee Whye Teh](https://www.stats.ox.ac.uk/~teh/), Research Scientist en DeepMind, y obviamente aprendiendo a sobrevivir un doctorado. Realmente hubiera sido genial poder tener muchas m치s conversaciones con ella.

{% include alert tip='En mi opini칩n este es uno de los fuertes de la UAI. Viniendo de Universidades como la USM donde al menos en mi tiempo costaba much칤simo que un profesor te diera bola. Tener conversaciones donde los profes no te hagan sentir como "idiota", y en verdad te animen y aconsejen sobre tu futuro es algo invaluable.'%} 

* **Neural Networks (Prof. Daniel Furtado)**: No me gust칩 en general el ramo. No aprend칤 nada nuevo porque en mi opini칩n el curso estaba muy desactualizado, aunque siendo s칰per sincero a muchos les sirvi칩 bastante. Los puntos bajos para m칤 es que tocamos cosas como la historia de la IA o arquitecturas que ya nadie usa y que no existe forma de implementarlas de lo a침ejas que est치n y lo que todo quer칤amos que era algo como Transformers, RF o Stable Diffusion eran temas que el profe ni siquiera conoc칤a. Ahora las tareas fueron bien entretenidas, pero depend칤a mucho de el esfuerzo que uno quisiera poner. Debido a que yo quer칤a sacarle el m치ximo provecho al curso implement칠 en Pytorch un MLP, un RBF-NN, una ResNet, una EfficientNet. Pero una tarea que era implementar una GAN se elimin칩 (y menos mal, porque ten칤amos muy poco tiempo para todo eso). No recomendar칤a el curso, y no me gust칩. Probablemente la gran decepci칩n del semestre. 

* **Grafos en Ciencia de Datos (Prof. Miguel Romero)**: Otro curso excelente, que es una de las grandes joyas del programa. El profe es un crack, y este es el tema que m치s domina. El curso es interesante no s칩lo porque toca temas relacionados a Grafos, pero tambi칠n porque introduce mucho background de Inform치tica que uno como Data Scientist deber칤a tener: Escritura de Algoritmos, Complejidad Algor칤tmica (Notaci칩n Big O, Notaci칩n NP, etc.), estructura de datos, y por supuesto su aplicaci칩n en Grafos. Cosas muy 칰tiles como Breadth First Search, Depth First Search, fueron explicados en detalles e implementados por nosotros en c칩digo adem치s de algoritmos para caminos m칤nimos, minimum spanning trees, clustering, comunidades, cliques, coloreo, homomorfismos, etc. Adem치s pudimos tener una visi칩n general de c칩mo se implementan algoritmos de Machine Learning en Grafos, como PageRank, PageRank con Teleportaci칩n, DeepWalk, Node2vec, Node Embeddings, y entender el detalle la diferencia con las Redes Neuronales de Grafos. En particular agradezco mucho el uso de Pytorch Geometric y el poder entender muy en detalle el funcionamiento interno. Creo que este es el curso en el que m치s cosas nuevas (y 칰tiles) aprend칤.

{% include alert warning='Muchas personas se quejaron porque el profe Romero es un poco bajo perfil. Lo consideran fome y aburrido para sus clases, pero yo lo siento como en el mismo tono de Andrew Ng, que parece que tiene sue침o, su tono es medio plano, pero dejando eso de lado y enfocando en su contenido son demasiado buenos. Sus slides son demasiado ordenadas y el orden en el que va pasando el contenido hace que realmente uno disfrute mucho sus ramos. Para mi gusto (y esto es muy personal) fue el mejor profesor del programa.'%} 

* **Modelos Lineales (Prof. Moreno Bevilacqua)**: Este fue un ramo que me gust칩 mucho tambi칠n. Fue un ramo bien te칩rico y el Profesor Bevilacqua se caracteriza por ser un profesor de mucha pizarra y de mucha demostraci칩n. Siempre es bueno tener en cuenta t칠cnicas de demostraci칩n, los supuestos al momento de generar modelos lineales, y t칠cnicas de optimizaci칩n como el Maximum Likelihood Estimation (MLE). El ramo si bien es en R, se usa muy poca librer칤a, porque el profe le gusta implementar todo desde cero, que es un approach que me gusta, porque desmenuzar el c칩digo me ayuda a entender de mejor manera c칩mo funciona el algoritmo por detr치s. Una de las cosas que m치s agradec칤 es entender en detalle el problema de la multicolinealidad (ac치 influy칩 bastante entender el problema de cuadrados m칤nimos desde el Algebra Lineal) y al menos el Profesor Bevilacqua, piensa que variables multicolineales o con un grado de multicolinealidad no es de gran gravedad, lo cual fue algo que me sorprendi칩 bastante. Otro de los mitos que rompi칩 fue el tema de la significancia de las variables. He estado en varios cursos, en los que se ense침a como m칠todo de selecci칩n de variables el deshechar las variables no significativas por p-value, algo que siempre me llam칩 la atenci칩n porque nunca he visto un algoritmo que mejores su performance predictiva por eliminar variables no significativas. 

> Bueno, 쯨ale la pena? Depende. 

En mi caso, estaba buscando aplicaciones en Ciencias de Datos que no sean t칤picos modelos de fuga, de propensi칩n y que el 칰nico objetivo que tienen es que empresas ganen m치s plata. Por otro lado, como mi rollo es el Deep Learning, he tenido la oportunidad de aprender varias cosas fuera de lo com칰n, acabo de implementar un algoritmo de Anomaly Detection llamado [DeepAnT]({{ site.baseurl }}/deepant/) y voy a estar implementando varios m치s, algunos que no tengo idea c칩mo. Si te gusta implementar cosas raras, que tienen un valor, pero no necesariamente en lo econ칩mico para una empresa (en mi caso queremos encontrar anomal칤as en el uso de terrenos como bosques ~~, humedales y turberas~~ con im치genes satelitales), entonces vale completamente la pena. Si quieres s칩lo estar m치s preparado para hacer la pega de siempre (lo cual no es malo), quiz치s es mejor un programa Profesional. 

S칩lo a modo de ejemplo, el Magister Profesional de la UAI (puede ser cualquier otro, nada en particular con este), probablemente te ense침ar치 elementos m치s aplicados, con menos teor칤a. Perfeccionarte en R y Python, c칩mo hacer buenas visualizaciones, uno que otro modelo por ah칤, y un largo etc.

En el MSDS, no ten칤amos tiempo de aprender a programar, el que sab칤a bien, y sino, doble pega (aunque se ofrece un bootcamp de nivelaci칩n en caso de necesitarlo). En mi caso, me ayud칩 mucho tener experiencia en Python y R, hizo que los ramos se me hicieran menos pesados. Pero a칰n as칤 en especial en las 칰ltimas 3 semanas fue ca칩tico, mucho que estudiar, muchas tareas, presentaciones, informes, posters, y entregas te칩ricas (todo en Latex, aunque no es obligaci칩n) y c칩digo. Lo pas칠 mal, as칤 que hay que tener ojo tambi칠n con cuanta carga quieres tener. Yo part칤 tomando el Master y mi pega (que siendo bien organizado es posible, al menos en mi opini칩n), luego me echaron, pero el segundo semestre tuve proyectos freelance, competencia, clases, bootcamps y sobreviv칤.

Espero que para los que est치n buscando alg칰n programa les sirva. Trat칠 de ser lo m치s imparcial posible. Y si me preguntan si recomendar칤a el MSDS yo dir칤a que s칤, me gust칩. Aprend칤 cosas que no est치n en Youtube, o que cuesta mucho encontrar, y que rara vez tendr치s la oportunidad de verlas en empresas tradicionales. Me gust칩 tanto que decid칤 seguir adelante y comienzo mi PhD en Ciencias de Datos en Marzo, aunque todav칤a estoy en el proceso de cerrar mi tesis de Magister que tiene fecha para Mayo. 

Nos vemos y espero que sea de utilidad.

[**Alfonso**]({{ site.baseurl }}/contact/)
