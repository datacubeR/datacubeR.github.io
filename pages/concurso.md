---
permalink: /concurso/
layout: page
title: "Desaf√≠o Ita√∫-Binnario"
subheadline: ""
teaser: "Lecciones aprendidas luego de mi primera Competencia."
---
<!-- ...and learn more at the same time. You can message me at the [contact page]({{ site.baseurl }}/contact/). -->

{% comment %} Including the two pictures is a hack, because there's no way use the Foundation Grid (needs a container with row) {% endcomment %}
![picture of me]({{ site.urlimg }}widget1-trofeo-binnario.png){: .left .show-for-large-up .hide-for-print width="500"}
![picture of me]({{ site.urlimg }}widget1-trofeo-binnario.png){: .center .hide-for-large-up width="500"}
Para los que no saben, esta fue mi primera competencia de Machine Learning, y probablemente la primera para muchos ac√° en Chile. La verdad siempre quise participar, pero no me atrev√≠a, le ten√≠a susto a no dar el ancho, y a pesar de que soy bastante seguro de lo que s√©, uno nunca piensa que puede ganar cuando est√°n compitiendo los mejores.

Finalmente en Abril del 2021 dimos por finalizado el proceso de implementaci√≥n del modelo ganador de la competencia en el Banco Ita√∫. Fue un proceso largo pero que espero prontamente d√© sus frutos. Este modelo permitir√° priorizar el contacto del banco para con sus clientes de una forma que permita optimizar los recursos del banco, pero tambi√©n contactar a clientes que efectivamente tengan una alta chance de adquirir el producto ofrecido, de manera de disminuir la tasa de molestia por clientes que no quieren ser contactados.

En Kaggle existe la *"tradici√≥n"* que al finalizar la competencia se comparte la soluci√≥n ganadora (al menos lo que se puede) por parte de los ganadores, y dado que oficialmente se cerr√≥ la implementaci√≥n del modelo y del pago del premio considero que ser√≠a un buen momento para comentar mi experiencia en la competencia. Adem√°s, uno de mis objetivos es desarrollar contenido en Ciencia de Datos en Espa√±ol, por lo que espero que contar c√≥mo fue la experiencia de participar/ganar sea de gran ayuda para que en pr√≥ximas competencias todos estemos m√°s preparados en cuanto a qu√© cosas es necesario poner atenci√≥n. Mi intenci√≥n es explicar c√≥mo fue el proceso de competencia y tratando de dar cr√©dito a todos aquellos que fueron parte de este proceso y que no pude agradecer [ac√°](https://www.linkedin.com/feed/update/urn:li:activity:6754831905763471360/).

{% include alert warning='Perd√≥n si doy detalles muy escuetos del modelo, es que, no puedo contar cu√°l fue la soluci√≥n ganadora. Pero s√≠ tratar√© de contar qu√© lecciones aprend√≠.'%}


Esto parti√≥ un d√≠a de clases en la Academia Desaf√≠o Latam, y mi ayudante [Tamara Zapata](https://www.linkedin.com/in/tamarazapatag/), me dice <q>¬øviste el concurso, deber√≠ay participar, dem√°s ganay?</q> (Demasiado optimista para mi gusto). Nunca le dije, pero cuando me dijo eso me baj√≥ el susto y la presi√≥n de que hab√≠a demasiada gente inscrita. Creo que al final fueron alrededor de 1000 equipos, y mucha gente que sabe. Aparte el premio de USD$20.000, era muy llamativo por lo que era muy probable que muchas personas quisieran participar. M√°s detalles del concurso [ac√°](https://binnario.ai/challenge/-MMDsMov6MVyOl3gDuOB).

Ese d√≠a despu√©s de la clase nos quedamos revisando la data, y lo primero que recuerdo fue: <q>no tengo idea de la m√©trica</q>. Googleando, v√≠ que era una m√©trica bastante famosa en *object detection* y en modelos de recomendaci√≥n, por lo que primero pens√© fue, quiz√°s podr√≠a probar algunos modelos de recomendaci√≥n, en particular <mark>Factorization Machines</mark>, que era algo que hab√≠a estado leyendo √∫ltimamente.

{% include alert info='Factorization Machines son un tipo de Modelos no muy conocidos y no tan populares al menos en Chile, que permiten utilizar descomposici√≥n en factores latentes, normalmente factorizando matrices para generar modelos de Filtrado Colaborativo.'%}

Luego notamos que los datos no ten√≠an estructura de modelamiento, eran datos crudos, tal cual sal√≠an de una base de datos. Por lo tanto, hab√≠a un paso previo de limpieza. Y eso fue todo lo que hicimos.

Bueno, d√≠as despu√©s me di√≥ por probar. Me puse a hacer **EDA**. Revis√© la cantidad de datos, las distintas tablas, igual era un problema grande, entre train y test eran f√°cil 35 millones de registros contando todas las tablas. Y empec√© a sacar conclusiones de la data que hab√≠a y de lo que no hab√≠a. Entonces dije: <q>voy a hacer un modelo r√°pido!</q>. Me gusta utilizar Random Forest como modelo Baseline, as√≠ que r√°pidamente entren√© un modelo y qued√© en `3er lugar`. 

> Claramente no me lo esperaba, y ah√≠ dije: *"ya, quiz√°s s√© como resolver este problema"*, y si bien la m√©trica dio bien baja, estaba tercero. Al ocurrir eso, pens√© que quiz√°s hab√≠a posibilidades de estar dentro de los 10 primeros lugares y en verdad, con presentar frente a Ita√∫ me conformaba.

Ah√≠ hubo un cambio, porque empec√© a destinar varias horas en la noche para modelar. El tema es que entremedio de este proceso me encontraba terminando de escribir mi Memoria, por lo que estaba bien cansado entre mi trabajo, las clases en la Academia, la Memoria y ahora esto. As√≠ que decid√≠ pedir vacaciones para poder relajarme, pasar tiempo con mi familia, pero tambi√©n dedicarme m√°s de lleno a esto.

Esto me permiti√≥ poner full atenci√≥n al modelo en las noches, que es mi peak de concentraci√≥n. Salieron varias ideas, y al cambiar a modelos m√°s potentes empec√© a mejorar. Ya en mi 3era submisi√≥n qued√© en el 1er lugar, y superando la barrera sicol√≥gica del 50%, que a ese nivel de la competencia estaba muuuuy dura (creo que no m√°s de 3 personas hab√≠an pasado el 50%). Ya ah√≠ me d√≠ cuenta de que hab√≠an reales posibilidades y me lo tom√© en serio. Pens√© en utilizar mi Laptop en su m√°xima capacidad aprovechando que me hab√≠a comprado un Legion 5 nuevito de paquete.


## El primer problema, 1era Lecci√≥n: Prepara tu Compu

Me qued√© corto de RAM, y varios modelos ya no pod√≠an correr, estaba creando muchas variables y mi PC no daba (a ese tiempo ten√≠a 16GB de RAM). As√≠ que tom√© la decisi√≥n de jug√°rmela, dije <q>hay que sacar al menos un podio s√≠ o s√≠ para pagar esta RAM, y sub√≠ a 32GB</q>.

El tema es que al cambiar las RAM nos dimos cuenta que mi compu ten√≠a un slot de RAM quemado y no pod√≠a aumentarse. Tuve que viajar a Santiago en `cuarentena` para cobrar la garant√≠a, fue redificil. Lamentablemente, no hab√≠an m√°s laptops de las caracter√≠sticas del m√≠o y no hab√≠a una soluci√≥n r√°pida m√°s que devolverlo. Me permitieron pedir la devoluci√≥n del dinero y en modo urgente tuve que ir al *Parque Arauco* a llevarme un computador `ya`. 

No estaba el Legion 5, y un <mark>super vendedor</mark>, (se notaba que sab√≠a) me meti√≥ un Legion 7 y me *"engrupi√≥"* con que tra√≠a una RTX 2070. Y no me pude resistir, obviamente este Laptop sali√≥ harto m√°s caro que el Legi√≥n 5. Entonces ahora s√≠ necesitaba sacar un podio para poder pagarlo. El tema es que el compu no era con retiro inmediato sino que se env√≠aba a domicilio, y bueno, saben que la reputaci√≥n de los env√≠os no es la mejor por la pandemia, no siempre llegan cuando dicen, pero este chico me *"re-contra-jur√≥"* que en 4 d√≠as llegaba. As√≠ que me la jugu√©, aprovech√© esos d√≠as para terminar mi memoria en un compu que ten√≠a y afortunadamente el Legion 7 lleg√≥ en 3 d√≠as. Reinstal√© todo, y entre la falla de mi Legion 5 hasta la puesta en marcha del Legion 7 pasaron cerca de 10 d√≠as sin poder modelar nada. Mantuve el primer lugar, lo cual me ten√≠a preocupado, pero apenas me puse a probar nuevos modelos aparecieron los pesos pesados, casi todos los finalistas empezaron a superar el 50% y me tiraron muy atr√°s en el leaderboard.

## Otro Problema: 2da Lecci√≥n

![picture of me]({{ site.urlimg }}concurso/codigo.jpeg){: .left .show-for-large-up .hide-for-print width="500"}
![picture of me]({{ site.urlimg }}concurso/codigo.jpeg){: .center .hide-for-large-up width="500"}
Un segundo problema, ya casi en la recta final del concurso fue, bueno, los modelos que gener√© fueron casi todos a la r√°pida, ¬øc√≥mo ordenarse? Y aqu√≠ viene la otra lecci√≥n: <mark>MODULARIZACI√ìN</mark>.

Comenc√© a Modularizar mi c√≥digo y definir distintas partes lo m√°s automatizadas posibles. Igual ten√≠a una parte bien al lote, pero que me dio mucho valor, que fue el an√°lisis exploratorio. Todo el resto del c√≥digo lo dej√© lo m√°s ordenado que pude.

* **Generaci√≥n de Variables**: Me preocup√© de encapsular todos los procesos de creaci√≥n de variables nuevas que requirieran gran proceso de c√°lculo en funciones sumamente flexibles. Si necesitaba generar m√°s, s√≥lo variaba par√°metros y eso me permit√≠a gran poder de experimentaci√≥n, generando muchos cambios con s√≥lo modificar algunos par√°metros.

* **C√≥digo de Entrenamiento**: Tambi√©n me preocup√© de modularizar esto, tratar de encapsular el preprocesamiento fue complejo, porque hab√≠an muchos formatos distintos dependiendo del modelo. Lo bueno fue que los modelos que fueron entregando los mejores resultados se empezaron a acotar y eso me permiti√≥ simplificar el Script.

* **Inferencia**: Esta parte se encargaba de poder generar las predicciones, pero adem√°s, generar una estrategia de ordenamiento de las predicciones que tambi√©n era parte del problema. Finalmente, transformaba la predicci√≥n final en el formato requerido por la plataforma para el env√≠o.

{% include alert success='Ac√° no descubr√≠ nada nuevo, luego siguiendo a uno de mis Youtubers favoritos hoy, Abishek Thakur, y leyendo su [libro](https://github.com/abhishekkrthakur/approachingalmost/blob/master/AAAMLP.pdf), me d√≠ cuenta que √©l propone un sistema muy similar, pero much√≠simo m√°s robusto que el m√≠o.'%}

## Otra Lecci√≥n: Aprender del error

Luego de muchos experimentos, not√© que no estaba llevando registro de mis experimientos de una manera √≥ptima. Lo peor de todo es que tengo un tutorial de MLflow, y <mark>NO LO UTILIC√â</mark>. Obviamente esto me llev√≥ a notar que hay muchas herramientas para trackear experimentos, y hay una particular que me est√° cautivando harto: [Weigths & Biases](https://wandb.ai/).

Definitivamente not√© un gran valor en llevar los resultados del mejor modelo, y eso lo hice. Pero tambi√©n not√© que hay un gran valor en llevar el registro de los experimentos no tan exitosos, porque me pas√≥ que como prob√© muchas cosas, se me olvidaba qu√© cosas ya hab√≠a probado. Eso me gener√≥ mucha inseguridad porque lleg√≥ un momento en la competencia que los puntajes se estancaron, en alrededor de un 55%, yo creo que iba 3ro y no ten√≠a muchas m√°s ideas. Y no sab√≠a cu√°les retomar y cu√°les no.

{% include alert alert='Una dificultad que ten√≠a esta competencia es que s√≥lo indicaba el puntaje si √©ste era mejor que el anterior. En caso de no serlo, uno nunca sab√≠a si hab√≠a errado por poquito o estaba muy perdido.'%}

## B√∫squeda de Hiperpar√°metros

![picture of me](https://optuna.org/assets/img/blog-multivariate-tpe.gif){: .right .show-for-large-up .hide-for-print width="500"}
![picture of me](https://optuna.org/assets/img/blog-multivariate-tpe.gif){: .center .hide-for-large-up width="500"}
Una de las cosas que para m√≠ tiene mucho valor es el tema de entender qu√© hacen los hiperpar√°metros en un modelo. En general, leo mucho la documentaci√≥n para saber qu√© significan, y tiendo a depender mucho de `GridSearch`. Voy mezclando esto con tuneo manual, para sacarle el jugo al modelo.

Esto tiene sus ventajas, tengo control total sobre la b√∫squeda de hiperpar√°metros, pero, depende de que yo est√© atento a los resultados. Adem√°s GridSearchCV en Scikit-Learn es muy ineficiente, tiende a ser lento y crashear debido al alto consumo de RAM.

Esto me ayud√≥ mucho a poner en pr√°ctica algunas cosas que aprend√≠ hace tiempo, y que nunca hab√≠a tenido que aplicar: `Downcasting` y el uso de `Matrices Sparse`, que en mi caso aplicaba. El uso de estas t√©cnicas me ayud√≥ mucho a reducir el tama√±o del dataset de train y permitir que el GridSearch funcionara.

Para el futuro, pretendo utilizar un framework de Cross Validation m√°s est√°tico, al final es el KFold lo que aumenta mucho el costo de evaluaci√≥n del modelo. Por lo tanto, pretendo aplicar estrategias m√°s robustas y organizadas como las presentadas por [Abishek](https://www.youtube.com/watch?v=ArygUBY0QXw) ac√°.

Adem√°s, nunca me hab√≠a dado el tiempo de aprender librer√≠as espec√≠ficas de optimizaci√≥n de Hiperpar√°metros, especialmente porque intent√© aprender `hyper-opt` una vez y la encontr√© muy engorrosa e innecesaria. Obviamente, modelos grandes requieren una estrategia m√°s Bayesiana para buscar hiperpar√°metros de manera m√°s inteligente. Encontr√© que `Optuna` es una tremenda herramienta y la estar√© agregando a mi arsenal.

## Soft Skills

![picture of me]({{ site.urlimg }}concurso/present.png){: .right .show-for-large-up .hide-for-print width="500"}
![picture of me]({{ site.urlimg }}concurso/present.png){: .center .hide-for-large-up width="500"}
Llegando ya a la √∫ltima semana aparecieron los contendores pesados, y yo estaba sin ideas. [Joaqu√≠n](https://www.linkedin.com/in/joaqunv/) y [Malen](https://www.linkedin.com/in/malen-antillanca/) cada vez que sub√≠an un modelo me pasaban y se instauraron r√°pidamente en el primer lugar, y aparecieron tamb√≠en el equipo de Rodrigo y [Paul](https://www.linkedin.com/in/paul-bertens-ai/) que hicieron pocas submisiones pero sub√≠an muy r√°pido. Entonces decid√≠ ocupar todo lo que se me ocurr√≠a el d√≠a Jueves antes de finalizar la competencia, qued√© en 2do lugar detr√°s de Joaqu√≠n y Malen env√≠ando mi ultima submisi√≥n. Despu√©s de esto dije: <q>estoy cansado, esto es todo, con tal de presentar estoy contento</q>. Al levantarme el viernes ya iba 5to, y al final del d√≠a qued√© 8vo, que fue mi puesto final, y estuve a punto de quedar fuera de la posibilidad de presentar.

{% include alert tip='Ac√° hay que ser muy estrat√©gico, porque no supe como generar mis √∫ltimas submisiones. De hecho Paul y Rodrigo env√≠aron su submisi√≥n final a las 23:51 pasando en √∫ltimo momento a Joaqu√≠n y Malen. Entonces realmente hay que ser estrat√©gico y pensar bien cuando quemar todos tus cartuchos.' %}

Para rematarme, ese d√≠a sali√≥ un reportaje en [`LUN`](https://www.lun.com/Pages/NewsDetail.aspx?dt=2020-12-11&PaginaId=24&bodyid=0) con los ganadores del a√±o pasado, los fundadores de Acacia, Catalina Espinoza, y Abelino Jim√©nez. Ella, Mag√≠ster de la Universidad de Chile, √©l, Doctor en Carnegie Mellon, yo... un egresado de Ingenier√≠a Civil üòî, hablaron de su soluci√≥n con Redes Neuronales y lo primero que pens√© fue... <q>uuuhhhh, no tengo oportunidad en el Pitch... a menos, que haga mi modelo interesante</q>. Y obvio, no todas las competencias se ganan as√≠, pero afortunadamente esta s√≠. La habilidad de comunicar es tan importante como la habilidad para modelar. Creo que la competencia dej√≥ en evidencia que varias personas saben hacer la pega... para m√°s remate, Catalina y Abelino estaban entre los 10 finalistas y hab√≠an Estudiantes de Doctorado en AI, Profesores de Mag√≠ster, gente de Argentina, Per√∫, etc. ¬øC√≥mo ganarles? Bueno, confiando en tu trabajo, entendiendo las fortalezas y debilidades de tu modelo y haci√©ndolo relevante. Para ello varios consejos:

* **Entendiendo el problema de Negocio**: Intuyendo para qu√© se usan estos modelos y poniendo atenci√≥n a respuestas de los organizadores. Revisar los comentarios de la competencia me ayud√≥ a entender c√≥mo se iba a consumir el modelo, y c√≥mo mi modelo pod√≠a ser de valor para las personas del banco.

* **Poniendo atenci√≥n al Slack**: Mucha de las preguntas que otros competidores hicieron me ayudaron a mejorar mi modelo y a preparar mi Pitch final, le√≠ todo el Slack. Adem√°s, leyendo sutiles pistas de los organizadores ayudaron a confiar en que mi modelo ten√≠a potencial. A pesar de quedar 8vo, pod√≠a enfocarme en c√≥mo mi modelo resolv√≠a problemas reales que ellos ten√≠an, como era el priorizar a qu√© clientes atacar.

![picture of me]({{ site.urlimg }}concurso/modelo.png){: .left .show-for-large-up .hide-for-print width="500"}
![picture of me]({{ site.urlimg }}concurso/modelo.png){: .center .hide-for-large-up width="500"}

* **Preparar el Pitch**: Son 4 minutos en los que te juegas la vida, hicimos 3... y es la peor experiencia por la que ha pasado. El coraz√≥n a mil y la verdad es que da mucho nervio. Si te trabas, no alcanzas a presentar todo en el tiempo dado y en verdad fueron super rigurosos con eso. Trat√© de incluir comentarios que se hicieron en Slack o durante la conversaci√≥n de finalistas tratando de demostrar siempre c√≥mo mi modelo supl√≠a sus necesidades. 

La preparaci√≥n de esos 4 minutos de Pitch me tomaba f√°cil 6 horas, y mucha pr√°ctica, realmente hab√≠a que escoger muy bien qu√© decir y por sobre todo qu√© no decir. Para el √∫ltimo Pitch estaba muy cansado y la verdad es que el d√≠a anterior me fui a acostar sin tenerlo tan bien preparado. 

Pero bueno, el d√≠a de la final despert√© a las 7am, y estuve 3 horas practicando el Pitch final (que era a las 10am). Despu√©s de mucho practicar no quedaba conforme, me trababa, se me olvidaban partes, no s√©, entr√© a la presentaci√≥n sin estar 100% convencido. 

Afortunadamente me fue bien, y cuando me avisaron que mi modelo era el ganador casi me da un ataque, pens√© que me estaban bromeando. Fue bueno ver que el esfuerzo de a√±os, aprendiendo por mi cuenta, no siendo considerado, o sencillamente siendo mirado en menos por la falta de mi t√≠tulo al final daba frutos.

Hay harta gente que agradecer en el camino: Mi esposa `Valentina`, que me dio permiso para acostarme tarde por m√°s de un mes, y ella es muy friolenta. Pero desde la `Tam` que me avis√≥ de la competencia, o amigos como `Lautaro`, yo creo que ni sabe, pero √©l me pas√≥ el primer Libro de Machine Learning que le√≠, el [Applied Predictive Modeling](http://appliedpredictivemodeling.com/) de Max Kuhn, o amigos como Nico, que me hablaron de Deep Learning por primera vez, o Mat√≠as (el Dragon Slayer) que siempre me dec√≠a que ten√≠a que usar Python y me present√≥ t√©cnolog√≠as como Github o Pytorch. **Gracias!**

![picture of me]({{ site.urlimg }}concurso/LogoBinarioBlanco.png){: .right .show-for-large-up .hide-for-print width="500"}
![picture of me]({{ site.urlimg }}concurso/LogoBinarioBlanco.png){: .center .hide-for-large-up width="500"}

## Algunos comentarios finales:

* Es verdad que competir toma mucho tiempo, pero menos de lo que esperaba. Organiz√°ndose bien uno puede compatibilizar trabajo, familia y hobbies como este. Incluso en Kaggle.
* El computador es importante. Tener una buena maquina ayuda, pero si uno crea un c√≥digo inteligente y flexible puede dejar entrenando en la noche y revisar resultados en el d√≠a. Esto me impact√≥ mucho y estoy trabajando en un paquete en Python para facilitar esta parte. Espero pronto tener noticias, de un BETA.
* Practicar lo que predicas... hay que usar alg√∫n sistema de logging, es la √∫nica manera de tener tus experimentos ordenados. Por otra parte, si bien estrategias como RandomSearch o Gridsearch entregan buenos resultados, es necesario moverse a estrategias de b√∫squeda Bayesiana de modo de incrementar la eficacia de encontrar un buen set de hiperpar√°metros sin depender de la atenci√≥n del modelador.
* Hay que entender bien qu√© modelos usar, y cu√°ndo desertar de una idea que no da frutos. Esto lo veo porque los 3 finalistas utilizamos modelos de Gradient Boosting. Si bien, es posible utilizar otros, yo intent√© lightFM y una red neuronal en `Keras` ninguno entr√≥ en el leaderboard. Esta parte es dificil, pero tuve que decidir que aunque los modelos se vieran prometedores, hab√≠a que renunciar a ellos y seguir con las ideas que s√≠ estaban dando resultado.
* Nunca menospreciar el poder de un buen Speech. Yo no soy bueno para hablar, ni me considero una persona buena para vender ideas. Pero s√≠ soy seguro de lo que s√© hacer. Y eso hay que trasmitirlo. Creo que la raz√≥n por lo que pude ganar es porque encontr√© la necesidad del banco, lo que ellos realmente esperaban del modelo y me aferr√© a eso y lo defend√≠ las 3 rondas de Pitch y result√≥.

# RECOMPENSAS

El premio es bueno (muuuuuuuy bueno), no se puede desmerecer. Pero la competencia signific√≥ mucho para m√≠ en t√©rminos profesionales. No s√≥lo se puede decir que, gracias al modelo, se pudo hacer un aporte super concreto para el beneficio de una empresa de bastante prestigio como lo es [Banco Ita√∫](https://banco.itau.cl/). Pero tambi√©n, esto lleg√≥ a gente que de una u otra manera apuesta por ti. El hacer las cosas bien, o el mostrar que sabes hacerlas (y esto lo digo con infinita humildad, porque s√© que a√∫n hay mucho que tengo que recorrer) tiene sus frutos. Desde **Abril 2021** estoy trabajando con la gente de [Jooycar](https://www.jooycar.com/es/inicio/) como  <mark>Head de Data Science</mark>. No s√© si estoy listo, no s√© si soy el id√≥neo, pero vamos a dar lo mejor de uno para poder generar valor a partir de los datos. Tengo hartas expectativas de lo que podemos haer y agradezco mucho a la gente de [Innspiral](https://www.linkedin.com/company/innspiral/?originalSubdomain=cl) por dar la plataforma para mostrar lo que uno hace y por crear el Desaf√≠o Binnario.

### Acerca de Jooycar

Para los que no saben, Jooycar es una Startup Insurtech que se dedica a asegurar veh√≠culos utilizando IoT para mejorar el comportamiento de conducci√≥n. Obviamente tremendos desaf√≠os se vienen ac√°. Hay harto que hacer, y mucho que armar, pero de las cosas entretenidas que se vienen:

* Trabajo con **the real** Big Data.
* Modelos entretenidos, al menos planeo uno que otro modelito de Deep Learning (No tengo idea si s√© hacerlos, muy probablemente no, pero tengo muchas ideas de lo que ya se puede venir).
* Trabajo con data geogr√°fica (Algo nuevo para m√≠).
* Integraci√≥n de Data Science con Dise√±o de Software (algo que hace rato estaba buscando).
* Y MUCHA INNOVACI√ìN...!!!

Y bueno, espero que esto pueda ser de utilidad para quienes se inician y los que ya llevamos m√°s tiempo en la Ciencia de Datos, y ojal√° cuando haya una nueva competencia de [Binnario](https://binnario.ai/) (que de seguro vamos a estar ah√≠), todos podamos ser mejores y que el ganador siga con esta idea de compartir su experiencia.

Espero poder estar constantemente compartiendo material que sea √∫til para quienes son entusiastas del Machine/Deep Learning, y si en algo les puedo apoyar no duden en contactarme.

[**Alfonso**]({{ site.baseurl }}/contact/)





